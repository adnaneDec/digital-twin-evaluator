[
    {
        "title": "A Bibliometric Analysis of Digital Twin in the Supply Chain",
        "summary": "Definitions: Digital twin is a digital representation of a physical entity that changes instantaneously with the actual object, process, or system. The digital twin concept has three components: real spaces, virtual spaces, and a linking system to transfer data and information between the real and virtual spaces. This is also known as the 'Mirrored Spaces Model'. Characteristics and requirements:Digital twins facilitate translating customer needs into product designs by conceptualizing parameters, structures, and geometry in a virtual setting. They allow for virtual manufacturing processes to identify defects before the actual process is conducted. They enhance risk assessment and development of risk mitigation plans. They incorporate financial data to adjust the cost of the entire supply chain. They streamline and optimize product designs, inventory management, material usage, transportation, and lead time for profit maximization and cost reduction. They allow designers to observe the behaviors of products and consumer interactions. They combine past, current, and future data for real-time monitoring and forecasting of future outcomes for informed decision making. Relevant Use Cases: Designing: Digital twins provide information for decision-making in various design processes and can be used for geometry assurance in manufacturing variation. Manufacturing: Digital twins allow monitoring with a virtual model, visualize the production process, and compare the physical item with the virtual model. They can also adjust the entire manufacturing process quickly to produce similar results despite unexpected events. Production Logistics: Digital twins can highlight bottlenecks in the entire transport process and allow for real-time tracking of the location and condition of cargoes during transit. They can also optimize vehicle routing and storage in industrial parks. Risk Management: Digital twins can identify areas of hazard using the virtual model, especially for events such as natural disasters during shipping and accidents in ports. Supply Chain Planning: Digital twins reduce the time between target setting, data collection, big data analytics, data processing, deriving inferences, and taking actions for future planning.Technologies and tools used: Big data, machine learning, Industrial Internet of Things, blockchain, edge computing, and cloud-based systems complement digital twin models. Virtual reality allows consumers or designers to interact with the virtual product. Sensors and actuators are equipped on the physical item to allow it to adjust itself to changes in the consumers and environment. Networking technologies and cloud computing allow information transfer between the physical and virtual models. Harzing’s Publish or Perish is used for performance analysis. VOSviewer is used to present visual graphs of the research elements. Microsoft Excel 365 is used for data processing. Special findings related to digital twin requirements or challenges: The COVID-19 pandemic drove the start of the prosperity stage of digital twin research in the supply chain. Researchers are slowly moving towards applying digital twin for human-centric systems and mass personalization to prepare to transit to Industry 5.0. The global market for digital twin is expected to exceed USD 73 billion by 2027, with a compounded annual growth rate of greater than 60%. China had the most publications, with 648 documents on digital twin in the supply chain. The strongest country collaborations existed between China and the United States. The use of technology in the supply chain is enhanced by emerging technologies such as artificial intelligence, digital twin, and big data. There are huge research gaps with the application of digital twin and deep learning, machine learning, and artificial intelligence to achieve mass personalization through intelligent transformation. Digital twin can be applied for sustainable intelligent transformation.",
        "keywords": ["digital twin", "machine learning", "Industry 4.0", "supply chain", "bibliometric analysis", "subject area"]
    },
    {
        "title": "A comprehensive review of digital twin — part 1: modeling and twinning enabling technologies",
        "summary": "This paper, the first in a two-part series, reviews digital twin trends across disciplines, focusing on modeling techniques and twinning enabling technologies. It categorizes these technologies based on the direction of data flow (physical-to-virtual and virtual-to-physical) and provides perspectives on the future of digital twin technology [1, 2].\n\n*   **(1) Definitions:**\n    *   A digital twin is a virtual representation of a complex physical asset in the digital space, closely characterizing the operations of the original physical process or system [3].\n    *   It distinguishes itself from digital models and digital shadows through bidirectional data flow between the physical and virtual spaces [4]. Digital models may have optional data flow, and digital shadows have unidirectional data flow from physical to digital [4].\n    *   A digital twin is always constructed for specific aspects relevant to the engineering problem it aims to solve [4].\n*   **(2) Characteristics and Requirements:**\n    *   **Continuous Data Synchronization:** Enabled by continuous data synchronization and information exchange between the digital twin and its physical counterpart [3].\n    *   **Five-Dimensional Model**: A five-dimensional digital twin includes the physical system (PS), digital system (DS), physical-to-virtual connection (P2V), virtual-to-physical connection (V2P), and an optimization dimension (OPT) [5, 6].\n    *   **Real-time Mirroring**: The seamless integration of the five dimensions enables digital twins to fulfill the need for a real-time mirror of the life cycle of a physical system, supporting optimal decision-making [5].\n*   **(3) Relevant Use Cases:**\n    *   **Product Lifecycle**: Benefits span the entire life cycle, including development, manufacturing, service, and disposal phases [3].\n    *   **Manufacturing**: Applications range from high-value manufacturing to production process planning and manufacturing process control [3, 7].\n    *   **Healthcare**: Personalized medicine [3].\n    *   **Energy**: Oil refinery management [3, 8].\n    *   **Urban Planning**: Risk identification and city planning [3, 8].\n    *   **Aerospace**: Fault diagnostics and prognostics of physical assets [9].\n    *   **Civil Engineering**: Implementation of digital twins in civil engineering [10].\n    *   **Architecture, Engineering, Construction, Operation, and Facility Management Industries**: Applications of digital twins [10].\n*   **(4) Technologies and Tools Used and How They Were Used:**\n    *   **Geometric Modeling**: Includes solid modeling and laser scanning to create digital replicas [11]. VR, AR, and MR technologies are also used [12].\n    *   **Physics-Based Modeling**: Covers a wide scope, including solid body structural analysis using finite element analysis (FEA) software [13].\n    *   **Data-Driven Modeling**: Includes statistical models and ML models for prediction and inference [14, 15].\n    *   **Physics-Informed ML**: Combines physics-based and data-driven approaches [16].\n    *   **Physical-to-Virtual (P2V) Twinning**: Involves physical measurements as input, probabilistic model updating, ML model updating, fault diagnostics and failure prognostics, and ontology-based reasoning [17, 18].\n    *   **Virtual-to-Physical (V2P) Twinning**: Includes model predictive control, predictive maintenance, and real-time perception [17].\n    *   **Ontology and Knowledge Graphs:** Offer a common language to refer to objects in the physical asset, enhancing flexibility in describing the evolution of digital twins [19, 20].\n*   **(5) Special Findings Related to Digital Twin Requirements or Challenges:**\n    *   **Need for Comprehensive Review**: A comprehensive review of modeling and twinning methods, as well as UQ and optimization methods enabling digital twins, is essential to guide effective, industry-scale implementations [21].\n    *   **Data Flow**: Bidirectional data flow is a key characteristic that distinguishes a digital twin from a digital model or shadow [4].\n    *   **Model Selection**: Selection of an appropriate data-driven model should follow the 'Occam's Razor' principle [22].\n    *   **Hybrid Physics-ML Modeling Approaches**: More research is needed to address practical challenges impeding industry-scale adoption of these approaches, such as a lack of large, realistic datasets and digital twin benchmark problems [16].\n",
        "keywords": ["Digital twin", "Optimization", "Machine learning", "Enabling technology", "Perspective", "Industry 4.0", "Review"]
    },
    {
        "title": "A comprehensive review of digital twin—part 2: roles of uncertainty quantification and optimization, a battery digital twin, and perspectives",
        "summary": "This paper, the second in a two-part series, reviews key enabling technologies for digital twins, focusing on uncertainty quantification and optimization methods. It includes a case study constructing and testing a battery digital twin [1].\n\n*   **(1) Definitions:**\n\n    *   Digital twin: An emerging technology in Industry 4.0 that comprehensively models the physical world as interconnected digital models to optimize process design, quality control, health monitoring, and decision-making [1, 2].\n    *   The digital twin is described as an 'integrated multiphysics, multiscale, probabilistic simulation' [3]. Probabilistic simulation is essential due to inherent variability [3].\n*   **(2) Characteristics and Requirements:**\n    *   **Five-Dimensional Digital Twin Model**: Based on data flow, this model includes modeling, P2V (physical to virtual), and V2P (virtual to physical) dimensions [4, 5]. Uncertainty quantification (UQ) and optimization are crucial for synthesizing these dimensions [5, 6].\n    *   **Uncertainty Quantification (UQ)**: UQ is essential for building accurate digital twins and making informed decisions [5]. It involves quantifying uncertainty in system outputs due to aleatory and epistemic uncertainty sources [7, 8].\n    *   **Optimization**: Optimization bridges the gap between physical and digital systems through data collection and modeling and is indispensable for tasks in the V2P dimension like system reconfiguration and process control [5].\n    *   **Real-time Requirements**: The definition of 'real-time' varies depending on the application, referring to the minimum computational speed needed for seamless optimization, prediction, and control of the system [9].\n*   **(3) Relevant Use Cases:**\n    *   **Battery Digital Twin**: Used to optimize the retirement of a battery cell from its first-life application, demonstrating predictive maintenance scheduling [6, 10].\n    *   **Predictive Maintenance Scheduling**: Digital twins enable online optimization of maintenance schedules by predicting a machine's future degradation trajectory [11].\n    *   **Real-Time Mission Planning**: Digital twins support data-driven decision automation, as shown in a UAV mission planning task, where the structural health of a UAV is considered [12].\n    *   **Automobile Industry**: Digital twins improve vehicle life cycle development and manufacturing processes [13].\n    *   **Healthcare Sector**: Applications include monitoring, digital surgery, remote surgical assistance, drug development, and medical treatment using high-fidelity digital twin models of human bodies [13].\n    *   **Smart City**: Digital twins are used to solve problems like water treatment and facility maintenance [13].\n*   **(4) Technologies and Tools Used and How They Were Used:**\n    *   **Machine Learning (ML) Models**: Used extensively in constructing digital models, but their performance is affected by data quality and quantity [14]. UQ of ML models is crucial, especially in safety-critical applications [14, 15].\n    *   **Bayesian Methods and Gaussian Process Regression Models**: Used in the Kennedy and O'Hagan (KOH) framework for model calibration, constructing a Gaussian process regression model for the computer simulation model and another as the model bias term [16].\n    *   **Particle Filters**: Used in the battery digital twin case study for estimating future capacity fade trajectory and predicting cell RUL [10, 17].\n    *   **Optimization Algorithms**: Multi-attribute utility-based optimization model to determine the optimal time to retire a cell from its first life [10].\n    *   **Open-Source Tools and Datasets**: Publicly available tools and datasets are identified for modeling, process mining, control, and data streaming [18].\n*   **(5) Special Findings Related to Digital Twin Requirements or Challenges:**\n    *   **Generalizability of ML Models**: ML models can fail unexpectedly on out-of-distribution samples, reducing user trust [14]. This can be mitigated by incorporating physics or fine-tuning models [14].\n    *   **Uncertainty in Measurements**: Measurements from the physical world and virtual model outputs are never certain [19].\n    *   **Model Validation Challenges**: Model validation is a lagging indicator of digital twin model quality, as the model can only be validated with future data [20].\n    *   **Need for Open-Source Efforts**: Collaborative, open-source efforts are needed to accelerate the industry-scale adoption of digital twins [21].\n    *   **Consideration of Sustainability**: Digital twins have the potential to make an enormous and long-lasting impact at the disposal phase [22].\n",
        "keywords": ["Digital twin", "Optimization", "Machine learning", "Enabling technology", "Perspective", "Industry 4.0", "Review"]
    },
    {
        "title": "A review of the roles of Digital Twin in CPS-based production systems",
        "summary": "This paper reviews the concept of Digital Twins (DT) within the context of Industry 4.0 and Cyber-Physical Systems (CPS), analyzing definitions, characteristics, use cases, and enabling technologies. \n\n(1) Definitions: The paper traces the definition of Digital Twin from its initial conceptualization by NASA in the aerospace field [1-4], where it was defined as a multi-physics, multi-scale, probabilistic simulation of a vehicle or system mirroring the life of its flying twin [2, 5]. The definition evolved to include a lifecycle view, mission requirement checks, and use for prognostics and diagnostics [2]. Later, the concept expanded to include generic 'products' [2, 6], paving the way for its application in manufacturing [2, 4]. The European H2020 project MAYA defines DT for Industry 4.0 manufacturing as a virtual representation of systems synchronized in real-time with the physical system via sensor data [1].\n\nA Digital Twin is considered the virtual and computerized counterpart of a physical system [7]. It can be used to simulate the system for various purposes, enabled by real-time synchronization of sensed data [7].\n\n(2) Characteristics and Requirements: Digital Twins require real-time synchronization of real-world activities with the virtual space, enabled by physical-virtual connections and networking of CPS elements [7, 8]. A proper data model is necessary for structuring information about system operations, history, behavior, and current state [8]. Semantic metadata models are proposed to ensure digital continuity of data generated across all lifecycle phases [9, 10].\n\nThe key characteristics of a DT for Industry 4.0 manufacturing systems include: a virtual representation of a production system, the ability to run different simulation disciplines, synchronization between the virtual and real system (enabled by sensed data and connected smart devices), mathematical models, and real-time data processing [11].\n\n(3) Relevant Use Cases:\n*   Health analyses for improved maintenance planning, including monitoring anomalies, fatigue, and crack paths [4, 12].\n*   Digitally mirroring the life of a physical entity to study long-term behavior, predict performance, provide information continuity along different lifecycle phases, and support virtual commissioning [12, 13].\n*   Supporting decision-making through engineering and statistical analyses, such as optimizing system behavior during the design phase and optimizing product lifecycle [13].\n*   Improving maintenance activities, such as condition-based maintenance, diagnostics, and prognostics [14].\n\n(4) Technologies and Tools Used:\n*   Cyber-Physical Systems (CPS): CPS are smart embedded and networked systems that operate at virtual and physical levels, interacting with and controlling physical devices [7, 15].\n*   Internet of Things (IoT): IoT enables the collection and exchange of data through the internet, allowing devices to be sensed and controlled remotely [15].\n*   Big Data Analytics: Big Data analytics facilitate rapid decision-making and improved productivity through smart analytics tools [15].\n*   Ontologies: Ontologies provide explicit, semantic, and formal conceptualizations of concepts in a domain, aiding in the integration and sharing of sensed data [15].\n*   Simulation Software: Various simulation tools are used, including Finite Element Methods (FEM), Computational Fluid Dynamics (CFD), Monte Carlo simulations, and Computer-Aided Engineering (CAE) applications [16]. Specific software mentioned includes DDSim, Rockstar Sim. Suite, Stick-to-Stress Real Time Dynamic Flight Simulator (S2S DFS) [17, 18], Matlab-Simulink [19], and VEROSIM [20].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n*   The increasing interest in DT is evidenced by the growing number of publications, expanding beyond aerospace to smart manufacturing [3, 4].\n*   The connection between DT and Industry 4.0 is strong, with DT often used to simulate CPS systems or products [9, 21].\n*   A key challenge is ensuring information continuity throughout the lifecycle phases, which can be addressed through semantic metadata models [9, 22].\n*   The MAYA project emphasizes the importance of a semantic metadata model, a simulation framework, and a communication layer for real-time synchronization between physical CPS and the digital world [10, 23].",
        "keywords": ["Digital Twin", "Cyber-Physical Systems", "Industry 4.0", "Production Systems"]
    },
    {
        "title": "A review of the technology standards for enabling digital twin",
        "summary": "This paper reviews the technology standards for Digital Twins (DT), emphasizing the necessity of standardization to ensure interoperability across different enterprises and domains [1, 2]. It introduces the digital twin technology based on the five-dimension model and examines the latest developments in digital twin standardization, while also addressing challenges and suggesting future directions for standardization [1, 3]. The review consolidates data from organizations including ISO, IEC, ITU, and IEEE [1, 3].\n\nKey insights include:\n\n1.  **Definitions**:\n    *   The digital twin is defined as an organic whole comprised of a physical asset and its digitized representation that communicate and co-evolve through bidirectional interactions [2].\n    *   ISO 23247-1 defines a digital twin as a digital representation of a manufacturing element that enables convergence between the element and its digital representation at an appropriate rate of synchronization [4, 5].\n    *   ITU- Y.scdt-reqts defines a digital twin as a digital representation of an object of interest [4, 6].\n\n2.  **Characteristics and Requirements**:\n    *   Digital twins require characteristics such as virtual reality integration, real-time interaction, iterative operation and optimization, and all-element/process/business data driving [2].\n    *   A digital twin system for verticals like smart manufacturing and smart cities needs systematic design, construction, operation, maintenance, and improvement [7].\n    *   The five-dimension architecture of a digital twin includes a physical entity, virtual entity, connection, DT data, and services [8, 9].\n    *   The virtual entity is the digital representation of the physical entity and the most important element [9].\n    *   'Connection' ties different parts of the DT together [9].\n    *   DT data combines data from physical and virtual aspects to provide comprehensive information through data processing [9].\n    *   'Services' enable various functions in the DT to be standardized and easily used [9].\n\n3.  **Relevant Use Cases**:\n    *   Digital twins are used in smart manufacturing, smart cities, transportation, and healthcare for mechanism description, abnormal diagnosis, risk prediction, and decision assistance [2].\n    *   Applications include satellite/space communication networks, ships, vehicles, power plants, aircraft, and complex electromechanical equipment [10].\n    *   Specific services include prognostic health management (PHM), product life cycle management (PLM), digital twin networks, smart cities, and factories [11].\n    *   Use cases in smart cities focus on energy and building monitoring, urban planning, traffic management, pollution monitoring, and healthcare [11].\n\n4.  **Technologies and Tools Used**:\n    *   Modeling methods include knowledge-based modeling (expert systems, fuzzy systems, knowledge graphs) and data-based modeling (deep learning, artificial neural networks) [12].\n    *   Data fusion methods like the entropy weight method and Bayesian method are used to improve data robustness and reliability [13].\n    *   Technologies like blockchain and federated learning are used to enhance data privacy and system reliability [14].\n    *   Connection technologies include 5G, proximity networks, OPC UA, and time-sensitive networking (TSN) [15].\n    *   Various standards such as IEEE 1451 for sensor interfaces and ITU-T Y.4473 for IoT device interconnection are utilized [16].\n\n5.  **Special Findings Related to Digital Twin Requirements or Challenges**:\n    *   Challenges include inconsistent understanding of DT across different fields and interoperability issues [7].\n    *   There is a need for unified guidance in data processing and management, including heterogeneous data conversion and multi-source data mapping rules [14].\n    *   Compatibility problems exist in connections due to fragmented interface standards and different real-time requirements between IT and OT networks [17].\n    *   Most digital twin applications are limited to the design and process stages, needing extension to monitoring, control, and optimization [18].\n    *   A general definition of digital twin is required to clarify the core concept [4].\n    *   The understanding of digital twin smart cities is not consistent among different standards [19].\n    *   Coordination between ITU-T, ISO, and IEC is needed to avoid redundant work [20].",
        "keywords": ["Digital Twin", "standard", "five-dimension model"]
    },
    {
        "title": "Decision support in productive processes through DES and ABS in the Digital Twin era: a systematic literature review",
        "summary": "This systematic literature review explores the use of simulation as a Digital Twin (DT) to support decision-making in productive processes. The study considers various nomenclatures used to refer to simulation as DT, focusing on Discrete Event Simulation (DES) and Agent-Based Simulation (ABS). It examines application areas, decision objectives, platforms, connections to physical systems, time horizons for updating simulation models, the degree of autonomy, validation methods, advantages, challenges, and opportunities associated with this approach [1, 2].\n\n**(1) Definitions:** The Digital Twin (DT) is defined as virtual copies capable of connecting to physical systems, mirroring their behavior, and guiding decision-making [3, 4]. Simulation models that connect to physical systems and constantly adapt according to their current states can be classified as DTs [5]. The study differentiates between traditional simulation models and DT approaches, emphasizing the ability to extend use over time scales where the physical system constantly changes [5].\n\n**(2) Characteristics and Requirements:**\n*   **Integration:** DTs integrate simulation models with physical systems through sensors, smart devices, databases, and management systems, creating a highly synchronized virtual copy sensitive to physical changes [4].\n*   **Nomenclatures:** Various terms are used to describe this approach, including 'Cyber-physical System', 'Symbiotic Simulation', 'Online Simulation', 'Data-driven Simulation', 'Real-time Simulation', 'Near real-time simulation', and 'Semi-physical simulation' [6].\n*   **Components:** A process DT includes a Physical System (PS), Virtual System (VS), Service System (SS), and DT Data (DTD) [5]. The VS can be represented by a simulation model [5].\n*   **Coevolution:** DTs facilitate a coevolution between physical and virtual environments, providing guidance for more efficient decision-making and adjusting to physical improvements [7].\n*   **Updating and Timing:** Simulation models can be updated in real-time (RT) or near real-time (NRT), depending on the characteristics of the decision-making [8]. NRT is more flexible and allows updating the model in longer time intervals [8].\n*   **Autonomy:** DTs can be autonomous, exercising direct command in the physical system, or non-autonomous, suggesting actions [9].\n*   **Validation:** Verification, validation, and accreditation routines are necessary to ensure correct functioning and performance [10].\n\n**(3) Relevant Use Cases:**\n*   **Manufacturing:** Includes aeronautical, automotive, and metal-mechanic segments [11].\n*   **Service:** Covers sectors such as laboratory activities and the energy sector [11].\n*   **Logistics:** Focuses on logistics operations and integrated logistics [12].\n*   **Healthcare:** Used in hospital areas such as Emergency Rooms (ER) and Intensive Care Units (ICU) [12].\n*   **Construction:** Encompasses activities directly linked to construction, support activities and smart buildings [12].\n*   **Decision-making Objectives:**\n    *   **Production Planning:** DTs provide guidelines related to process planning, scheduling, and maintenance [13].\n    *   **Process Evaluation:** DTs allow monitoring physical processes through performance indicators [13].\n    *   **Process Control:** DTs enable control of physical systems, both automated and indirect [14].\n    *   **Resource Allocation:** DTs provide guidelines related to resource allocation, including human and computational resources [14].\n    *   **Routing:** DTs offer route analysis and optimization for automated and non-automated vehicles [15].\n\n**(4) Technologies and Tools Used:**\n*   **Software and Commercial Packages:** Tecnomatix, Arena, AnyLogic, FlexSim, Quest, Simio, Simul8, Repast, Symphony, and Network Simulator [16].\n*   **Programming Languages:** Python, Java, CD++, and Stroboscope [16].\n*   **Connections to Physical Systems:** IoT devices, process management systems, databases, and sensors are used to connect simulation models with physical systems [17].\n*   **Integrating Systems:** Intermediate interfaces facilitate data flow between physical and virtual environments, ensuring data formatting and process security [18].\n\n**(5) Special Findings Related to Digital Twin Requirements or Challenges:**\n*   **Integration, Communication, and Synchronism:** Guaranteeing integration, communication, and synchronism between physical and virtual environments is a significant challenge [19].\n*   **Technological Structure:** Implementing DTs requires a technological structure composed of sensors, intelligent systems, and databases [19].\n*   **DT Reliability:** Ensuring DT reliability is crucial, as its use may be associated with high-impact decisions [10].\n*   **Model Validity:** Maintaining the validity of DT simulation models in the face of physical changes is challenging [20].\n*   **Computational Power:** High computational power can be a critical factor in certain applications [20].\n*   **Security:** Security related to DT simulation models is a critical factor, limiting autonomy and wide use [20].",
        "keywords": ["Digital Twin", "discrete event simulation", "agent-based simulation", "decision-making", "systematic literature review", "simulation models", "productive processes", "physical systems", "virtual models", "autonomy", "synchronisation", "connection"]
    },
    {
        "title": "Digital Factory Twin: A Practioner-Driven Approach for Integrated Planning of the Enterprise Architecture",
        "summary": "This paper addresses the underutilization of Digital Factory Twins (DFTs) in industrial settings and proposes an integrated planning approach using Enterprise Architecture (EA) Management to improve IT-driven feasibility and business value in production management and factory planning [1, 2]. The approach involves three phases: (1) assessing the initial situation and defining target objectives, (2) designing a company-specific DFT, and (3) planning EA changes [2]. The paper identifies key challenges in DFT implementation related to human, technological, and organizational aspects, further categorized by EA levels (strategy, business architecture, application & data architecture, and technical infrastructure) [3]. It emphasizes the importance of aligning DFT implementation with strategic goals, integrating with existing business and IT architectures (including legacy systems), and ensuring data quality and consistency [4-6]. The proposed EAM-based approach includes tools like capability maps, use case catalogs, a 150% DFT reference architecture, and fit-gap analysis to address these challenges and facilitate successful DFT adoption [7-10]. The research combines a meta-review of existing studies with expert workshops to develop a practical implementation and planning procedure for DFTs [2, 11]. The integrated planning approach is not intended to go into more technical details for concrete software development activities [12].",
        "keywords": ["digital twin", "digital factory twin", "factory planning", "factory operations", "product development", "enterprise architecture", "enterprise architecture management", "EAM", "implementation challenges", "integrated planning approach"]
    },
    {
        "title": "Digital twin - a state-of-the-art review of its enabling technologies, applications and challenges",
        "summary": "This paper provides a comprehensive review of Digital Twin (DT) technology, examining its history, definitions, models, enabling technologies, and applications across various engineering fields and product lifecycle phases [1, 2]. It highlights the importance of environmental coupling in creating high-fidelity virtual components within DT models [2, 3]. The review identifies key challenges in constructing DTs for complex engineering systems and suggests future research directions [2].\n\n(1) **Definitions:**\nThe definition of DT has evolved since Michael Grieves proposed the concept in 2003 [4, 5]. NASA defined DT as an integrated multi-physics, multi-scale, probabilistic simulation of a vehicle or system, mirroring the life of its flying twin [4]. Over time, the definition has broadened to encompass digital replicas of physical assets, processes, people, places, and systems, emphasizing the dynamics of complex systems throughout their lifecycle [6]. The basic components of DT include a physical entity, a virtual model, and a connection between them [7].\n\n(2) **Characteristics and Requirements:**\nA high-fidelity DT model should contain complete and accurate geometrical, physical, behavioral, and rule information [8-10].  It requires technologies for sensing, data construction and management, virtual modeling, service creation, and data transmission [9, 11].  A key requirement is the real-time, two-way connection between the physical and virtual spaces, enabling data-driven control and virtual-real state mapping [12, 13].  The model should consider environmental factors to ensure consistency between the physical entity and the virtual model [3, 9].\n\n(3) **Relevant Use Cases:**\n*   **Product Lifecycle Management (PLM):** DTs can be applied in product design, manufacturing, operation and maintenance (O&M), and recycling phases [2, 14].\n*   **Design:** DTs facilitate the translation of customer needs into functional requirements, map functional requirements to design parameters, and enable virtual verification and optimization of designs [15, 16].\n*   **Manufacturing:** DTs enable real-time monitoring, prediction, and production management in shop floors [17, 18]. They support reconfigurable manufacturing systems by allowing manufacturers to rapidly respond to market changes [19].\n*   **Operation and Maintenance:** DTs are used for condition monitoring, fault diagnosis and prognosis, and maintenance planning for complex equipment like aircrafts and wind turbines [20-22].\n*   **Recycling:** DTs can be used to manage the recycling process of Waste Electrical and Electronic Equipment (WEEE), determining recycling mode based on cloud data [23].\n*   **Engineering Fields:**\n    *   **Aerospace Engineering:** DTs are used to reduce aircraft weight, improve safety and reliability, and predict structural life [22, 24].\n    *   **Tunneling and Underground Engineering:** DTs aid in the design, manufacturing, operation, and maintenance of underground engineering equipment [25].\n    *   **Wind Engineering:** DTs enable real-time monitoring, predictive maintenance, and adaptive control strategies for wind turbines [26, 27].\n    *   **Internet of Things (IoT):** DTs facilitate seamless integration between IoT devices and data analytics in smart cities, healthcare, and manufacturing [28-30].\n\n(4) **Technologies and Tools Used:**\n*   **Sensing Technologies:** IoT sensing, reverse engineering, image recognition measurement, and particle sensing [31]. Sensory materials can be implemented to improve crack detection [31].\n*   **Data Construction and Management:** Technologies like bar codes, QR codes, RFID, MySQL, HBase, and NoSQL databases are used for data storage [8]. Data mining algorithms (K-means, support vector machines), predictive analytics, and data fusion methods are employed for data processing [32, 33].\n*   **Virtual Modeling:** CAD software (UG, AutoCAD, SolidWorks, Creo) is used to visualize geometrical information [10]. Physics-based models like CFD and FEM are used for behavioral modeling [34]. Data mining algorithms and semantic data analytics are used to extract rule information [35].\n*   **Service Technologies:** Service description and encapsulation technology are needed to generate a service [36]. Computer graphics processing technology is used for real-time visualization of DT services [37].\n*   **Connection and Data Transmission:** Wire (twisted pair, coaxial cable, optical fiber) and wireless (Zig-Bee, Bluetooth, Wi-fi, UWB, NFC, 5G) communication protocols are used for data exchange [12, 38]. Application Program Interfaces (APIs) are used for data transmission on the software level [38].\n*   **Environment Coupling Technologies:** Remote sensing, seismic wave method, polarization, radio navigation system, hydroacoustic positioning systems and 3D modelling are used to describe geometric and physical information about the environment [38]. Finite element analysis and computer fluid dynamics can be used to simulate the influence exerted by virtual models in the environment [38].\n\n(5) **Special Findings (Requirements or Challenges):**\n*   **Environmental Coupling:** The majority of existing DT models lack consideration of environmental coupling, which results in inaccurate representation of virtual components [2, 39].\n*   **Data Processing:** Existing data analysis algorithms need improvement in accuracy and speed [40]. The management of fleet data, considering both common characteristics and individual differences of batch products, poses a challenge [41].\n*   **High-Fidelity Modeling:** Building virtual models that faithfully replicate physical geometries, properties, behaviors, and rules is a fundamental issue [42].\n*   **Real-Time Connection:** Achieving a real-time, two-way connection between the virtual and real spaces is difficult due to data volume, network transmission delays, and model analysis time [13].\n*   **Unified Platform:** The lack of a unified development platform and tools, due to different formats, protocols, and standards, hinders the integration and application of DTs [13].",
        "keywords": ["digital twin", "enabling technologies", "virtual modeling", "environmental coupling", "cyber-physical system", "design engineering", "internet of things", "product lifecycle", "manufacturing", "aerospace engineering", "tunneling", "wind engineering", "data fusion", "big data analytics", "predictive maintenance"]
    },
    {
        "title": "Digital Twin Applications: A Survey of Recent Advances and Challenges",
        "summary": "This paper provides an overview of digital twin (DT) technology, its applications, and the challenges associated with its implementation. It contextualizes DT within the framework of Industry 4.0, emphasizing its role in integrating physical and virtual data throughout a product's lifecycle [1, 2]. The paper explores the definitions of DT, its characteristics, and the technologies that enable its functionality. It highlights the use of Industrial Cyber-Physical Systems (CPS) as the basis of Industry 4.0, combining software components with mechanical and electronic parts [3]. Data transmission in CPS is achieved through technologies like DSLs, wireless methods, and high-speed interconnections [3]. The article also discusses the architecture of DT systems, presenting a hierarchical model with layers for physical description, data representation, integration, services, and business decisions [4, 5]. It addresses the challenges of upgrading legacy systems to incorporate DT technology, including the need for retrofitting techniques to reduce production costs, increase efficiency, and improve reliability [1, 6, 7]. Furthermore, the paper identifies trends and obstacles in DT development, such as precise indoor localization, faithful virtual reality representations, and the management of unmodeled emergent events [8, 9]. The study also emphasizes the importance of data collection, storage, and analysis in creating effective DT models, and notes that AI methodologies can support essential functionalities of the system [10, 11]. The paper concludes by advocating for further research into DT architecture, Industry 4.0 applications, legacy system upgrades, and intelligent systems [12].",
        "keywords": ["industry 4.0", "industrial cyber-physical system", "industrial digital twin", "digital twin", "cyber-physical systems", "Internet of Things", "big data", "legacy systems", "retrofitting", "intelligent systems", "manufacturing", "simulation", "modeling", "data analysis", "AI", "machine learning", "virtual reality", "data integrity", "cybersecurity"]
    },
    {
        "title": "Digital Twin applications toward Industry 4.0: A Review",
        "summary": "Cet article examine en profondeur le concept de jumeau numérique (Digital Twin) dans le contexte de l'Industrie 4.0. Un jumeau numérique est défini comme une représentation virtuelle d'objets, de processus et de systèmes existant en temps réel, servant de pont entre les mondes physique et numérique [1]. L'article explore le rôle essentiel de cette technologie pour répondre aux exigences de l'Industrie 4.0, en offrant une image numérique des opérations d'une usine, des activités d'un réseau de communication ou du mouvement des articles dans un système logistique [1].\n\n**Caractéristiques et exigences :**\n\n*   **Représentation virtuelle :** Le jumeau numérique est un modèle logiciel d'un objet physique, doté d'une identité unique [2]. Il peut s'agir d'une réplique d'un moteur automobile, d'un bâtiment, d'une ferme solaire ou même d'une ville entière [2].\n*   **Collecte de données en temps réel :** Des capteurs collectent des données du monde réel, qui sont ensuite utilisées pour créer une réplique numérique [3]. Ces données comprennent des informations de conception et d'ingénierie décrivant la forme, les matériaux, les composants, le comportement et les performances de l'actif [1].\n*   **Analyse et optimisation :** Le jumeau numérique permet d'analyser, de modéliser et d'optimiser les performances d'un objet physique tout au long de son cycle de vie [3]. Il utilise des données, l'apprentissage automatique (ML) et l'Internet des objets (IoT) pour améliorer l'efficacité des systèmes et des entreprises [4].\n*   **Adaptation en temps réel :** Les jumeaux numériques nécessitent la création de représentations virtuelles haute fidélité du monde physique qui s'adaptent en temps réel lorsque l'environnement physique change [5, 6].\n*   **Culture numérique robuste :** L'efficacité du jumeau numérique est optimisée lorsque les entreprises utilisent déjà des capteurs et d'autres techniques de collecte de données [7].\n*   **Scalabilité :** Une architecture évolutive est nécessaire pour répondre rapidement aux changements des exigences quantitatives, tels que le nombre d'utilisateurs ou de points de données à traiter [8].\n\n**Cas d'utilisation pertinents :**\n\n*   **Tests de résistance des opérations :** Les jumeaux numériques peuvent être utilisés pour tester les opérations dans les hôpitaux et les établissements médicaux, simulant la meilleure façon de fonctionner en cas de catastrophes [9].\n*   **Maintenance prédictive :** Le jumeau numérique peut prévoir les problèmes et proposer des solutions à l'avance en surveillant en permanence leurs homologues physiques et en collectant des données via des capteurs [10].\n*   **Optimisation de la production :** Les données sur l'équipement, les processus et les environnements peuvent être utilisées pour optimiser la planification de la production grâce à des prédictions de temps d'arrêt [11].\n*   **Gestion des actifs :** Dans les organisations complexes, un jumeau numérique peut aider à localiser rapidement les instruments ou équipements nécessaires en cas d'urgence [8].\n*   **Analyse du comportement des consommateurs :** Les magasins de détail peuvent utiliser la technologie du jumeau numérique pour reproduire leur magasin et observer le comportement des consommateurs à l'aide de capteurs [12].\n*   **Simulation de scénarios :** Les jumeaux numériques permettent de simuler divers scénarios de production et d'utilisation, ce qui permet de confirmer et d'évaluer chaque aspect avant la fabrication [13].\n\n**Technologies et outils utilisés :**\n\n*   **IoT (Internet des objets) :** Les capteurs IoT collectent des données de l'environnement physique et les transmettent pour être recréées virtuellement [1].\n*   **AI (Intelligence Artificielle) et ML (Machine Learning) :** Ces technologies sont utilisées pour analyser les données collectées et améliorer l'efficacité des systèmes [4].\n*   **Cloud Computing :** Le maintien d'une réplique numérique des actifs dans le cloud permet aux entreprises de suivre les changements et d'apporter les modifications appropriées pour améliorer les performances [3].\n*   **Functional Mock-up Interface (FMI) :** La plupart des systèmes d'automatisation industrielle prennent en charge FMI pour intégrer une version en temps réel du jumeau numérique afin de fonctionner en parallèle avec la machine réelle [10].\n\n**Constatations spéciales, exigences ou défis :**\n\n*   **Sécurité des données :** L'un des principaux problèmes liés au jumeau numérique est la sécurité et la confidentialité des données, car le système utilise des logiciels intelligents avec un accès naturel à diverses ressources et informations sensibles sur les entreprises [14].\n*   **Investissement élevé :** La mise en place de jumeaux numériques nécessite un investissement important, que seules certaines entreprises peuvent se permettre [14].\n*   **Nécessité d'une modélisation des relations :** Une solution de jumeau numérique doit prendre en charge la modélisation des relations entre les appareils IoT, et les clients doivent être en mesure de concevoir de nouveaux modèles de jumeaux numériques personnalisés pour leur secteur ou leur cas d'utilisation [15].",
        "keywords": ["Digital Twin", "Applications", "Industry 4.0", "Virtual", "Digital representation", "Features", "IoT", "Artificial Intelligence", "Data analytics", "Manufacturing", "Simulation", "Optimization"]
    },
    {
        "title": "Digital twin for smart manufacturing, A review",
        "summary": "This paper reviews the application of digital twins in smart manufacturing systems, discussing the advantages and challenges of part production modification using digital twins [1, 2].\n\n(1) Definitions:\nA digital twin is defined as a virtual representation of a physical system or process that allows for real-time monitoring, analysis, and optimization [2]. In smart manufacturing, it simulates and optimizes production, predicts equipment failures, and improves efficiency and quality [2, 3]. It provides a detailed, accurate representation of a physical object or system, including its behavior, performance, and interactions with the environment [3].\n\n(2) Characteristics and Requirements:\nDigital twins in smart manufacturing combine real-time data from physical sensors with CAD models and simulation tools [4]. They enable real-time monitoring of manufacturing processes for quick issue resolution and allow testing and optimization before physical production, saving time and resources [5, 6]. Digital twins facilitate predictive maintenance and data-driven root-cause analysis, enhancing part manufacturing productivity [1].\n\n(3) Relevant Use Cases:\n*   **Manufacturing Optimization:** Digital twins optimize manufacturing processes, predict and prevent equipment failures, and enhance part production quality and efficiency [2].\n*   **Predictive Maintenance:** They identify issues early, increase productivity, and provide fresh perspectives in addition to process optimization [7]. They help identify the root cause of issues using a contextual model of machines during production [7].\n*   **Downtime Reduction:** Digital twins simulate scenarios to identify potential problems before they occur [8]. They also provide real-time monitoring to enable quick corrective action [9].\n*   **Safety Enhancement:** Digital twins identify hazards and risks in manufacturing processes by simulating system behavior under different conditions [10]. They can also be used for training purposes [11].\n*   **Virtual Commissioning:** Digital twins allow engineers to simulate and test control and automation systems in a virtual environment before real-world installation [12].\n*   **Collaboration Improvement:** Digital twins provide a shared understanding of the manufacturing process, enabling teams to work together more effectively [13, 14].\n*   **Assembly Simulation:** Digital twins model the assembly process and identify potential issues before they occur in the physical world [15].\n*   **Applications Across Industries:** The paper discusses the use of digital twins in aeronautical, automotive, renewable energy, and telecom industries [16].\n\n(4) Technologies and Tools Used:\nDigital twins use machine learning, data analytics, and multi-physics simulation to simulate and analyze different working conditions [3]. They combine real-time data from physical sensors with computer-aided design (CAD) models and other simulation tools [4]. Advanced Internet of Things (IoT) algorithms are used for analysis and adjustment of component manufacture [17].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n*   **Data Quality and Security:** Low-quality data can reduce a digital twin’s ability to modify manufacturing processes [18]. Managing the massive amounts of data from various endpoints poses a security vulnerability [18].\n*   **Technology Stability:** A lack of stable and sustainable technologies hinders the development of collaborative digital twin systems for smart distributed manufacturing [19, 20].\n*   **Real-time Data Communication:** Effective digital twins require accurate mirroring of real devices, necessitating real-time data communication [17].\n*   **Privacy and Security:** Ensuring data privacy and security is a significant challenge in part manufacturing modification using digital twins [21].\n",
        "keywords": ["Smart manufacturing", "Digital twin", "Manufacturing optimization", "Part production", "Simulation", "Real-time monitoring", "Predictive maintenance", "Data analytics", "Internet of Things (IoT)", "Cybersecurity", "Virtual commissioning"]
    },
    {
        "title": "Digital Twin Framework for Built Environment: A Review of Key Enablers",
        "summary": "This paper presents a comprehensive review of Digital Twin (DT) technology within the Architecture, Engineering, Construction, and Operation (AECO) sector, addressing the gap between its potential and current adoption [1, 2]. It proposes a framework integrating technologies like Building Information Modelling (BIM), Geographic Information Systems (GIS), and the Internet of Things (IoT) to optimize the built environment's lifecycle [1]. The core idea is to facilitate real-time data transfer from the physical environment to a digital counterpart, enabling monitoring, analysis, and optimization [1, 3]. The paper identifies key enablers for DT implementation, including IoT, lighting systems, computer vision, BIM, and data integration [4-8]. It also discusses the importance of GIS-BIM integration, IoT and smart cities, and lessons from other industries for the successful deployment of DTs in the built environment [9-11]. The research methodology involves a scientometric analysis using the Web of Science database to identify relevant studies and keywords [12]. Ultimately, the paper aims to provide a structured framework aligning with the multifaceted requirements of Digital Twin implementation in the built environment and beyond [13].\n\nThe paper defines Digital Twins as virtual representations of physical assets, processes, or systems, emphasizing the real-time data connection between the physical and digital realms [14-16]. Key characteristics include virtual representation, synchronization, frequency of synchronization, and fidelity [17-20]. Requirements involve robust data acquisition and integration, data analytics and machine learning, visualization, and communication interoperability [21-23].\n\nRelevant use cases span across the lifecycle of the built environment, including design optimization, construction process enhancement, predictive maintenance, improved energy efficiency, and decommissioning planning [17, 24, 25]. Technologies and tools used encompass BIM, GIS, IoT sensors, computer vision, cloud computing, and data analytics platforms [8, 26, 27]. BIM provides engineering support to digital platforms, while GIS manages spatial data [8, 9]. IoT enables real-time data collection and communication between physical and virtual environments [5, 27]. Computer vision contributes to energy conservation and intelligent lighting systems [28].\n\nSpecial findings highlight the need for a holistic approach integrating BIM, GIS, and smart city concepts, as opposed to isolated implementations [29]. Challenges include the lack of standardization, defined budgets, and a holistic perspective on DT implementation within the built environment [13, 30, 31]. The paper also emphasizes the importance of data security and privacy in the IoT context [32].",
        "keywords": ["Digital Twin", "BIM", "GIS", "IoT", "smart cities", "virtual model", "built environment", "AECO sector", "real-time monitoring", "data integration", "sustainability", "predictive maintenance"]
    },
    {
        "title": "Digital twin in manufacturing: conceptual framework and case studies",
        "summary": "This paper reviews the digital twin (DT) concept in manufacturing, investigating its development, maturity, and role in the fourth industrial revolution [1]. It addresses how the digital twin concept supports an integrated, flexible, and collaborative manufacturing environment, a goal of Industry 4.0 [1, 2]. The paper proposes a conceptual framework supporting an integrated product-process digital twin for application in digitized manufacturing, presenting its applications and benefits through three case studies [1].\n\n(1) Definitions: The paper defines a digital twin as a virtual replica of a physical asset, built mainly of structural and behavioral models for basic control, monitoring, and performance evaluation [3]. It notes the lack of a unified definition, with variations in description, classification, and application of the concept [4]. The research sees the digital twin for manufacturing as a set of integrated virtual information constructs of a potential or actual physical system detailed with all necessary minuscule and macro-level of multi-physics, multi-scale geometric and simulative probabilistic specifics, suitable for its creation [5].\n\n(2) Characteristics and Requirements: A digital twin has characteristics that differentiate it from simulation models, including real-time reflection, interaction and convergence, and self-evolution [6-8]. Real-time reflection means the virtual space is highly synchronized with the physical space [6]. Interaction and convergence occur within the physical space, between historical and real-time data, and between physical and virtual spaces [7, 8]. Self-evolution enables the digital twin to update its data in real-time, mirroring its physical twin and allowing continuous improvement of virtual models [8]. Key requirements include integrating interconnected physical elements, ultra-high synchronization of the virtual space with the physical space, and data fusion covering all elements, flows, business services, and data-driven and application-oriented services integration [9].\n\n(3) Relevant Use Cases: The digital twin concept can be applied within the manufacturing industry primarily at three levels: product, unit/systems, and system of a system (SoS)/shop-floor levels [10]. Use cases include product design, production process optimization, system performance monitoring, and service delivery [11]. The paper includes three case studies: a discrete-time cyber-physical production system based on the Festo cyber-physical smart factory, a continuous-time production system based on a pharmaceutical continuous crystallization system, and a virtual X-ray of electric motors [12-15].\n\n(4) Technologies and Tools Used: Various technologies and tools are used, including sensor data fusion, IoT, edge and cloud computing, deep learning and machine learning in AI, big data analytics, faster algorithms, and increased computational power [16]. For the Festo CP smart factory case study, Siemens NX was used to build 3D CAD models, and Tecnomatix plant simulation was used to construct the DES model of the processes [17]. The PharmaMV software was used for the pharmaceutical continuous crystallization system, supporting process monitoring and control, data visualization, optimization, and multivariant analysis [18]. Siemens developed the virtual X-ray of electric motors, utilizing thermal simulations [15].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges: The paper identifies technical limitations hampering the implementation of digital twins, including a lack of quantifiable metrics of uncertainty, unresolved uncertainties in predicting complex systems, variance in the framework of digital tools, a lack of an explicitly defined ontology, challenges in including human functionality in the virtual space, a lack of professional skill sets, and challenges in managing big data [19-25]. Proposed solutions involve using data-driven models, increasing virtual confidence through real-time data instances, encouraging software collaborations by adopting widely accepted communication protocols, defining an explicit ontology, promoting human-machine collaborations, and addressing challenges in managing big data through semantic web technology [20-23, 25, 26]. The framework supports the integration of both product and process digital twins which in extension promotes product customisation, process flexibility and a supportive decision-making system [27].",
        "keywords": ["digital twin", "manufacturing", "Industry 4.0", "cyber-physical systems", "smart manufacturing", "product lifecycle management", "digital twin framework", "product-process integration", "data analytics", "simulation", "optimization", "case studies"]
    },
    {
        "title": "Digital twin modeling",
        "summary": "This paper presents a systematic review of current research on digital twin modeling and its resulting digital twin models. It emphasizes the importance of digital twin modeling for accurately portraying physical entities, enabling digital twins to deliver functional services and meet application requirements [1, 2]. The review covers a comprehensive analysis of digital twin models from various perspectives, including application field, hierarchy, discipline, dimension, universality, and functionality [2]. It also classifies and analyzes current studies on digital twin modeling according to six modeling aspects: model construction, model assembly, model fusion, model verification, model modification, and model management [3]. Furthermore, the paper investigates and summarizes enabling technologies and tools for digital twin modeling [2]. It identifies challenges such as the need for more focused research on modeling and model attributes [4], uneven hierarchical distribution, insufficient multidisciplinary integration, and gaps between provided functions and actual needs [5]. The review also highlights the lack of a universal and coherent analysis of technologies and tools for digital twin modeling [6]. The paper concludes by offering observations and future research recommendations, such as establishing hierarchical structures for digital twin models, promoting interdisciplinary integration, and developing integrated software platforms for all modeling aspects [7].",
        "keywords": ["Digital twin", "Digital twin modeling", "Digital twin model", "Enabling technologies", "Enabling tools", "Model construction", "Model assembly", "Model fusion", "Model verification", "Model modification", "Model management", "Manufacturing systems", "Geometric model", "Physical model", "Behavioral model", "Rule model"]
    },
    {
        "title": "Digital Twin of City: Concept Overview",
        "summary": "This article introduces the concept of a digital twin for a city, addressing the complexities of the urban economy and proposing an evolutionary approach through interconnected digital twins of individual urban elements [1]. These digital twins operate on a unified platform, sharing data to enhance overall functionality [1].\n\n(1) **Definitions:** The paper defines a digital twin (DT) as an integrated, multi-physical, multi-scale probabilistic simulation of a complex object [2]. It leverages physical, mathematical, and simulative models, using data from sensor networks and other sources to accurately represent real-world counterparts [2]. A digital twin of a city is described as a network of interconnected digital twins, each representing specific aspects of urban functioning and development [2]. These twins synchronize with the real urban infrastructure using real-time data from diverse sources [2].\n\n(2) **Characteristics and Requirements:** Effective operation of a city's digital twin relies on a continuous flow of data from various sources within the smart city's digital infrastructure [2]. Key data sources include traffic flow information, physical environmental parameters from intelligent sensors, data from surveillance cameras, and open-source data [3-5]. The digital twin provides features such as monitoring the current state of the urban environment, rapid response to emergencies, efficiency assessment of design solutions, identification of potential risks, and forecasting future developments based on historical data [6, 7]. The development of a city digital twin is an intricate process that benefits from a phased implementation, integrating specific solutions to address urgent problems [7].\n\n(3) **Relevant Use Cases:** The paper outlines several examples of digital twins, including those for urban infrastructure (3D models of buildings and utilities), transport networks (monitoring traffic), urban ecology (monitoring environmental conditions), and power engineering [5, 6]. Specific applications include pollution control, microclimatic weather forecasts, waste management optimization, smart traffic management, energy consumption optimization, and smart irrigation systems [8, 9]. The digital twin of Takamatsu city, Japan, is presented as a pilot project focusing on emergency monitoring (flood prevention) and enhancing tourist engagement [9].\n\n(4) **Technologies and Tools Used:** The creation of digital twins involves various modeling approaches, including statistical and intelligent data analysis, and computational modeling methods like the finite element method [10]. Physical models utilize simulation packages such as ANSYS, employing Navier-Stokes equations and finite element methods [11]. Optimization models apply linear, mixed integer, and non-linear programming [12, 13]. Simulation modeling replaces the real system with a computer model to simulate processes [14]. Data mining models are used for discovering relationships between factors, their impact on indicators, and predicting values [15, 16]. Neural network models, including convolutional neural networks (CNNs), are applied for image analysis, object detection, and identifying complex dependencies [17-19].\n\n(5) **Special Findings Related to Digital Twin Requirements or Challenges:** A significant challenge is managing and processing the vast amount of data from diverse sources [20]. The paper emphasizes the importance of data cleansing to handle incorrect, abnormal, or missing data, using methods for outlier detection and imputation of missing values [21, 22]. Fog computing is highlighted as a solution for pre-processing data from sources like CCTV cameras, reducing the volume of data transferred to the cloud and improving the efficiency of intelligent data analysis [20, 23, 24]. The evolutionary development and integration of specific solutions are crucial due to the complexity of city digital twins [7].",
        "keywords": ["digital twin", "smart city", "urban management", "neural networks", "data mining", "sensors", "fog computing", "urban environment", "IoT", "data analysis", "simulation modeling", "urban infrastructure"]
    },
    {
        "title": "Digital twin of electric vehicle battery systems: Comprehensive review of the use cases, requirements, and platforms",
        "summary": "This review paper provides a comprehensive analysis of digital twins (DTs) for electric vehicle (EV) battery systems, covering use cases, enabling technologies, requirements, and platforms. It highlights the potential of DTs to address challenges across the battery value chain, from manufacturing to recycling. \n\n(1) **Definitions:** The paper notes the lack of a universally accepted definition for 'digital twin,' referencing various interpretations such as mega-model, avatar, mirrored system, digital shadow, and synchronized virtual prototype [1]. It distinguishes between a battery digital model, a battery digital shadow, and a battery DT [2]. Three types of battery DTs are proposed: Digital Twin Prototype (DTP) for battery manufacturing, Performance Digital Twin (PDT) for battery operation in 1st and 2nd life, and Digital Twin Instance (DTI) covering the entire battery lifecycle [3].\n\n(2) **Characteristics and Requirements:** The key requirements of battery DTs encompass software, hardware, and IoT [4]. Hardware components involve sensors measuring voltage, current, temperature (VIT), and potentially gas, pressure, and strain [5]. Software aspects include multi-scale model co-simulation, cybersecurity measures, and time-series databases [4]. IoT infrastructure ensures connectivity [4]. The DT architecture typically follows a layered approach with a connectivity layer, a twin layer for models and algorithms, and a service layer for visualization and user interfaces [4].\n\n(3) **Relevant Use Cases:** The paper extensively reviews DT use cases across the battery lifecycle [6]. These include:\n    *   SoX Estimation and Cell Balancing: Improving the accuracy of state-of-charge (SoC), state-of-health (SoH), and state-of-power (SoP) estimation using cloud-based computation [7, 8].\n    *   Fault Diagnosis and Prognosis: Utilizing advanced techniques and historical data for fault detection and prediction [9, 10].\n    *   RUL Estimation: Predicting the remaining useful life (RUL) of batteries for proactive maintenance [11, 12].\n    *   Predictive Maintenance: Scheduling maintenance based on real-time RUL monitoring [12].\n    *   Battery Repurposing, Second-Life, and Recycling: Facilitating the reuse of batteries in second-life applications by assessing their SoH and economic value [13].\n    *   Sharing (Swapping) Services: Managing shared batteries by tracking their status and degradation [14].\n    *   Design and Production Optimization: Enhancing manufacturing processes and quality assurance using DTs [15].\n    *   Energy Optimization: Improving EV performance through advanced energy management strategies [16].\n    *   Thermal Management System: Implementing predictive control strategies for battery temperature regulation [17].\n    *   Battery Passport: Managing battery data and metadata throughout its lifecycle [18].\n    *   Battery Charging and Vehicle-to-Grid (V2G) Operation: Optimizing charging protocols and V2G operation using DTs [19].\n\n(4) **Technologies and Tools Used:**\n    *   **Development Platforms:** ANSYS Twin Builder and COMSOL Multiphysics® are used for multiphysics system simulations, integrating electrical, thermal, and mechanical models [20, 21]. Siemens Simcenter Amesim is employed for system simulation and performance optimization [22].\n    *   **Integration Platforms:** Amazon Web Services (AWS) IoT Greengrass, Microsoft Azure DTs, and Eclipse Ditto are used [23]. The Asset Administration Shell (AAS) framework is also relevant [24].\n    *   **Modeling:** Multi-scale models (3D, electrochemical) and equivalent circuit models are employed [25]. Data-driven models, such as neural networks (NNs), and hybrid models are also utilized [26, 27].\n    *   **Data Storage:** Time-series databases and resource description framework (RDF) are used for data storage [28].\n    *   **Visualization:** Tools like Unity, Qt, iTwin, Gazebo, and Grafana are used for creating interactive 3D animations and dashboard interfaces [29].\n\n(5) **Special Findings Related to DT Requirements or Challenges:**\n    *   **Lack of Standards and Legislation:** The absence of standards and legislation regarding DT definitions, architecture, and data transparency poses a challenge [30].\n    *   **Cybersecurity:** Communication channels between the DT and physical twin (PT) are vulnerable to manipulation, potentially leading to safety risks [30].\n    *   **Complexity and Cost:** DT implementation requires significant design effort, expensive infrastructure, and potentially additional sensor units [31].\n    *   **Technical Barriers:** Managing and processing large volumes of real-time data from numerous cells within EV battery packs presents a challenge [32]. The survey revealed that DT costs are hard to justify for some use cases, such as SoC estimation, where the achievable results on BMS are already satisfactory [33]. Use cases related to fleet management, battery repurposing, and battery passports are considered more promising [33].",
        "keywords": ["digital twin", "electric vehicle", "battery management system", "BMS", "battery", "lithium-ion", "artificial intelligence", "machine learning", "internet-of-things", "IoT", "SoC estimation", "SoH estimation", "RUL estimation", "predictive maintenance", "battery passport", "V2G", "COMSOL", "ANSYS", "Siemens Simcenter Amesim"]
    },
    {
        "title": "Digital Twin of Wireless Systems: Overview, Taxonomy, Challenges, and Opportunities",
        "summary": "This tutorial paper provides a comprehensive overview of digital twins for wireless systems, exploring their fundamental concepts, architecture, and frameworks [1]. It categorizes the research landscape into 'twins for wireless' (how digital twins enable wireless systems) and 'wireless for twins' (efficient use of wireless resources for twin signaling) [2].\n\n(1) **Definitions:** A digital twin is defined as a virtual representation of a physical system, serving as its digital counterpart [3]. It optimizes cost and performance using technologies like virtual modeling, simulation, blockchain, edge/cloud computing, and optimization tools like machine learning, game theory, and graph theory [3]. Digital twins for 6G can manage single entities (edge servers, IoE devices), end-to-end services (resource management, network planning), and multi-services (resource slicing, service isolation, network planning) [4].\n\n(2) **Characteristics and Requirements:** Key design aspects include 'twins for wireless' and 'wireless for twins' [5]. 'Twins for wireless' focuses on enabling wireless system services using digital twins, involving players like blockchain networks, edge/cloud servers, and decoupling interfaces [5, 6]. It requires careful design to meet the diverse requirements of IoE applications [6]. 'Wireless for twins' optimizes wireless resource utilization for twinning, addressing twin object training and operation signaling [6]. This involves minimizing transmission latency by reducing twin model update size, enhancing throughput, and improving SINR [7]. A high-level architecture consists of physical devices interaction layer, twin objects layers, and services layer [7]. Effective interfaces are crucial between these layers [8]. Reliability considerations include twin reliability (operation without interruption) and twin-based service reliability (dependent on wireless channel and edge/cloud computing reliability) [9].\n\n(3) **Relevant Use Cases:** The rise of the digital twin market is fueled by demand in manufacturing monitoring, intelligent analytics-based healthcare, smart warehouses, and intelligent transportation [10]. Applications include smart healthcare, waste recycling plants, smart airports, smart parking, and road accident management [11, 12]. Digital twins can also be used for predictive maintenance of 6G systems [13].\n\n(4) **Technologies and Tools Used and How They Were Used:** The paper discusses several frameworks for implementing digital twins: Eclipse Ditto (open-source for IoT twins), Model Conductor-eXtended Framework (MCX, for co-executing digital and physical systems), and Mago3D (open-source platform for real-world objects on the web) [14-16]. Digital twins utilize virtual modeling, simulation technologies, blockchain, edge computing, cloud computing, machine learning, game theory, and graph theory [3]. Modeling techniques include mathematical models, 3D models, and data-driven models [17]. Machine learning models are trained using centralized or distributed learning [18].\n\n(5) **Special Findings Related to Digital Twin Requirements or Challenges:** Open challenges include dynamic twins (reusable twins for various devices), interoperability for twin migration (seamless service across different environments), true prototyping of physical objects (accurate modeling), incentive mechanisms for twinning (motivating participation), twinning forensics and security (investigating and countering attacks), and efficient twin objects chaining (combining twins for efficient operation) [19, 20]. A key challenge is balancing computing power and latency when deploying twin objects at the network edge or cloud [8].",
        "keywords": ["digital twin", "wireless system", "machine learning", "federated learning", "virtual modeling", "6G", "IoE", "self-sustaining wireless systems", "proactive-online-learning-enabled systems", "twin objects", "wireless resources", "security", "privacy", "incentive mechanism"]
    },
    {
        "title": "Digital twin paradigm: A systematic literature review",
        "summary": "This paper provides an up-to-date overview of digital twins (DTs), their components, features, and interaction challenges, as well as ongoing research and technical challenges in conceiving and building DTs across different application domains and related technologies [1]. The study answers key questions about digital twins based on a systematic literature review [2].\n\n(1) Definitions:\nThe paper consolidates various definitions of digital twins from industry and academia [3]. It notes that some define a digital twin as a virtual representation or model that interacts with a physical system throughout its lifecycle [3]. These definitions emphasize the exchange of information between the physical and virtual spaces, involving sensors, data, and models [3]. Others view a digital twin as the cyber part of a cyber-physical system (CPS) [3]. The paper identifies five clusters of DT definitions [4]:\n\n*   C1: Focuses on the life cycle phases of a Digital Twin [4].\n*   C2: Introduces the Cyber-Physical System (CPS) concept in DT definitions [5].\n*   C3: Involves a comprehensive representation of all data, information, and knowledge of the physical twin in the Digital Twin definitions [6].\n*   C5: Sums up the DT definitions related to the virtual system concept [7].\n\nThe paper defines a digital twin as a set of adaptive models that emulate the behavior of a physical system in a virtual system, using real-time data to update itself throughout its life cycle [8]. The digital twin replicates the physical system to predict failures and opportunities for changes and to prescribe real-time actions for optimizing or mitigating unexpected events by observing and evaluating the operating profile system [8].\n\n(2) Characteristics and Requirements:\n\nThe main characteristics of a digital twin are:\n\n*   Ability of simulation along product life cycle (C1) [8]\n*   Synchronization of the cyber system with the physical assets (C2) [8]\n*   Integration of real time data (C3) [8]\n*   Behavioral modeling of the physical space (C4) [8]\n*   Services provided by the virtual system (C5) [8]\n\n(3) Relevant Use Cases:\n\nThe review identifies several application contexts for digital twins:\n\n*   Healthcare: capturing and visualizing a hospital system to create a safe environment and predicting outcomes of specific procedures [9].\n*   Maritime and Shipping: supporting design, visualizing key components, performing analyses, and improving control of operations on ship structures [9].\n*   Manufacturing: predicting equipment failure, informing operators of non-optimal performance, and improving customer experience [10]. Digital Twins in manufacturing involve applications based on the stages across the entire lifetime of a product, such as design, production, logistics and maintenance [10].\n*   City Management: improving urban environments and quality of life by simulating people movements, modeling smart buildings, traffic, air quality, and infrastructure [10].\n*   Aerospace: reducing unplanned downtime by receiving advance warnings and preparing action plans based on simulated scenarios [10].\n\n(4) Technologies and Tools Used:\n\nThe paper mentions various software and platform providers, including IBM Watson, PTC Thing Worx, Aveva, SAP Leonardo Platform, Twin thread, DNV-GL, Dassault 3D Experience, Sight Machine, and Oracle Cloud [11].\n\nThe key components/technologies for each layer of Digital Twin architecture are [12-14]:\n\n*   Physical layer: Wireless sensor network [15]\n*   Network layer: Communication protocols such as OPC Unified Architecture (OPC UA) and MT-Connect, and AutomationML [16]\n*   Computing layer: Data-driven methods such as machine learning, neural networks, and deep learning [17, 18].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n\nThe study identifies several research challenges in implementing digital twins:\n\n*   Human interaction: Forming and designing cognitive digital twins able to interoperate with other digital twins and humans in a seamless way [19].\n*   Sustainability: Application of a digital twin for improving the sustainability performances in each application context [20].\n*   Interoperability: Defining standards and communication protocols to ensure interoperability of multiple digital twins with each other [21].\n*   Reference architecture: Developing Standard Digital Twin solutions to provide design criteria and design constraints where reference architectural aspects, reference information model and communication protocols are clearly defined [22].\n*   Modularity: Exploring the modularization design principle needs to be explored to improve the modelling efficiency [22].",
        "keywords": ["digital twin", "Industry 4.0", "cyber-physical systems", "predictive manufacturing", "manufacturing", "simulation", "modeling", "smart manufacturing", "internet of things", "data analysis", "systematic literature review"]
    },
    {
        "title": "Digital Twins: A Survey on Enabling Technologies, Challenges, Trends and Future Prospects",
        "summary": "This survey paper provides a comprehensive overview of Digital Twins (DTs), examining their definitions, characteristics, use cases, enabling technologies, and challenges. It consolidates various perspectives on DTs from existing literature to offer a structured understanding of this evolving technology [1-3].\n\n(1) Definitions: The paper begins by tracing the evolution of the DT concept, noting its emergence in 2002 and its conceptualization around three main components: the real space, the virtual space, and the data link serving as the communication medium between the two [4]. It addresses the variety of DT definitions in the literature, grouping them into five categories: (1) those that define DT as a general, popular concept; (2) those that consider its components; (3) those that focus on bi-directional communication; (4) those that emphasize functionalities; and (5) those that highlight services [5].\n\n(2) Characteristics and Requirements: The paper identifies key characteristics of DTs, including their self-awareness, self-prediction, self-comparison, and self-configuration capabilities [5, 6]. A DT should be capable of adapting to changes in its real twin's environment and continuously improving its performance [5]. Essential requirements involve low-latency communication, high processing power, and the capacity for real-time, high-fidelity rendering of data and environments [5].\n\n(3) Relevant Use Cases: The survey highlights DT applications across various sectors such as manufacturing, smart cities, infrastructure, and healthcare [7]. In manufacturing, DTs are used for anomaly detection, predictive maintenance, and optimizing production processes [6-8]. For infrastructure, DTs aid in monitoring, maintenance, and extending the lifecycle of assets [9, 10]. In healthcare, they facilitate remote monitoring and personalized medicine [11].\n\n(4) Technologies and Tools: The paper discusses enabling technologies like Machine Learning (ML), cloud computing,Cyber-Physical Systems (CPS), Virtual Reality (VR)/Augmented Reality (AR), and the Internet of Things (IoT) [7, 11-13]. ML is used for data analysis and prediction [14]. Cloud and edge computing provide the infrastructure for data processing and storage [12]. CPS integrates physical and computational elements [13]. VR/AR provides visualization and interaction capabilities [11]. IoT enables real-time data collection from sensors [12]. For example, Deep Convolutional Neural Networks (DCNNs) are utilized to generate material images and classify their pixels accurately [15].\n\n(5) Special Findings, Requirements, and Challenges: The study identifies standardization, data ownership, and data security as major challenges in DT implementation [16, 17]. It also points out the need for addressing human and social impacts, ensuring data veracity, and improving the fidelity and synchronization of DT models [16]. Addressing these challenges is critical to leveraging the technology's benefits across diverse applications [18].",
        "keywords": ["Digital Twin", "Digital Transformation", "Smart Manufacturing", "Industry 4.0", "Structural Health Monitoring", "Machine Learning", "Cyber-Physical Systems", "Virtual Reality", "Augmented Reality", "Internet of Things", "Anomaly Detection", "Predictive Maintenance"]
    },
    {
        "title": "Digital Twins: State of the art theory and practice, challenges, and open research questions",
        "summary": "This paper provides a comprehensive review of Digital Twin (DT) technology, examining its theoretical underpinnings, practical implementations, challenges, and future research directions [1, 2]. It addresses the gap between the ideal DT concept and its actual implementation, emphasizing the role of machine learning and big data in advancing DT technology [3-5]. The review covers various domains and identifies factors that impede the widespread adoption of DT, such as the lack of universal standards, domain-specific requirements, and security concerns [2, 6]. The paper defines a conceptualization of DT, including its components and properties, and validates the uniqueness of DT compared to similar concepts like simulation and autonomous systems [2]. Real-life case studies illustrate the application of this conceptualization [2].\n\n**(1) Definitions:**\nThe paper acknowledges the ongoing debate regarding a universally accepted definition of DT [6, 7]. It references Grieves and Vickers' definition of a Digital Twin as a set of virtual information constructs fully describing a potential or actual physical manufactured product [8]. The review highlights the divergence in views, with some considering the DT as the final product, while others see it as encompassing the entire product lifecycle [7]. The paper adopts the term 'asset' for consistency, referring to the 'product' within the DT context [9].\n\n**(2) Characteristics and Requirements:**\nThe key characteristics of a DT include twinning, simulation, real-time monitoring, analytics, and optimization [8]. The essential components are the physical asset, the digital asset, and the information flow between them [9, 10]. Imperative components include IoT devices for data collection, data analytics and storage tools, machine learning for predictions and feedback, security measures, and DT performance evaluation metrics [11, 12]. Properties of a DT are self-evolution, domain dependence, autonomy, and synchronization [13-15]. High-fidelity two-way synchronization, interoperability with existing software, and cybersecurity are noted as major challenges [16, 17].\n\n**(3) Relevant Use Cases:**\nThe paper discusses DT applications across various domains, including manufacturing, aerospace, cyber-physical systems, prognostics, and health management [18]. Aerospace benefits from DT's ability to replicate extreme conditions and consider specific materials [19]. The maritime industry utilizes DT to combine information across devices [20]. Prognostics and health management benefit from DT's ultrafidelity and data merging capabilities [21]. Specific examples include Signify Philips using DT for lighting, IBM transforming the Port of Rotterdam, and DHL implementing a supply chain digital twin [22-24].\n\n**(4) Technologies and Tools Used:**\nDT relies on technologies like IoT for real-time data collection, big data analytics, machine learning for predictions, and cloud computing for storage and processing [6, 25]. Specific tools mentioned include Unity3d open source engine [26], BIM methodology [27], and software from companies like Dassault System’s 3DEXPERIENCE, AnyLogic, Ansys, PwC, Bosch, SAP, and Azure [23]. Machine learning algorithms such as random forest, AdaBoost, XGBoost, gradient boosting decision tree (GBDT), LightGBM, and neural networks are also used [28].\n\n**(5) Special Findings Related to Digital Twin Requirements or Challenges:**\nThe paper identifies several challenges, including the gap between the ideal DT and practical implementations, the need for domain knowledge, and the lack of universal standards [6, 29, 30]. It emphasizes the importance of high-fidelity two-way synchronization, interoperability with existing software, and addressing cybersecurity concerns [16, 17]. The review also points out the need for quantitative metrics to evaluate DT performance and the importance of the self-evolving nature of DT through machine learning [31, 32].",
        "keywords": ["Digital Twin", "Internet of Things", "Autonomous systems", "Big data", "Machine learning", "Real-time monitoring", "Simulation", "Optimization", "Forecasting", "Reference framework", "Data security", "Domain-dependence", "Cyber-physical systems", "Product Lifecycle Management"]
    },
    {
        "title": "Enabling technologies and tools for digital twin",
        "summary": "This paper explores the enabling technologies and tools for Digital Twins (DT), using a five-dimension model (physical entities, virtual models, services, DT data, and connections) as a framework. It discusses the evolution of digitalization leading to cyber-physical integration, where DT plays a crucial role. DTs are defined as a combination of physical assets and their digital representations that communicate and co-evolve through bidirectional interactions [1]. The paper emphasizes that while DT has gained attention, its full potential is yet to be realized due to its complexity. The authors aim to provide a reference for technologies and tools needed for DT implementation [2].\n\nDefinitions:\nThe paper highlights two widely accepted definitions of DT, one by NASA and the other by Grieves [3]. NASA defines a DT as an integrated multi-physics, multi-scale, probabilistic simulation of a vehicle or system that uses the best available physical models, sensor updates, and fleet history to mirror the life of its physical counterpart [3, 4]. Grieves's model consists of physical products in real space, virtual products in virtual space, and the connections of data and information tying them together [3]. The paper also introduces a five-dimension DT model (MDT = (PE, VM, Ss, DD, CN)), where PE represents physical entities, VM represents virtual models, Ss represents services, DD represents DT data, and CN represents connections [5].\n\nCharacteristics and Requirements:\nA high-fidelity virtual model is the core of any DT, requiring a thorough understanding of the physical world [6]. The virtual models need to be highly standardized, modularized, lightweight, and robust [2, 7]. Data is crucial for driving models and services, requiring restructuring based on DT characteristics [7]. The ultimate goal is to provide value-adding services like monitoring, simulation, and optimization, delivered through mobile apps and third-party services [7-9]. Physical entities, virtual models, data, and services must interact through connections for collective evolution [7].\n\nRelevant Use Cases:\nDT applications span across various fields [10]. In civil engineering, Dassault used the 3D Experience Platform to build a “Digital Twin Singapore” [10, 11]. In healthcare, Sim&Cure developed patient-based DTs for treating aneurysms, and Dassault conducted a “Living Heart Project (LHP)” [10, 12, 13]. DNV GL established a “virtual sister ship” to increase reliability and reduce operational costs [10, 14]. Tesla aimed to develop a DT for each electric car for data transfer between car and plant [10, 15]. GE built a digital wind farm using DTs for every wind turbine to optimize maintenance and increase energy production [10, 16]. Manufacturing applications include SAP and Dassault using DT to reduce deviations between functional requirements and actual performance [9].\n\nTechnologies and Tools Used:\nEnabling technologies include those for cognizing and controlling the physical world (measurement technologies, real-time data collection, control systems) [11, 17], digital twin modeling (geometric, physical, behavioral, and rule modeling) [14], digital twin data management (data collection, transmission, storage, processing, fusion, and visualization) [18], digital twin services (application software, platform architecture, service-oriented architecture) [15, 17], and connections (Internet technologies, interaction technologies, cybersecurity technologies) [15]. Tools include ANSYS Twin Builder for modeling [19], various software for geometric modeling (SolidWorks, 3D Max) [20], physical modeling (ANSYS, Simulink) [21], behavior modeling (CoDeSys, MWorks) [22], rule modeling (PTC’s Thingworx) [23], data management (DHDAS, Aspera, HBase, Spark, Spyder, Echarts) [24-28], and service applications (Thingworx, MindSphere, ANSYS) [29, 30].\n\nSpecial Findings:\nThe paper emphasizes the need for high-fidelity virtual models, standardization, modularization, and robustness in DT modeling [2, 6, 7]. It also points out the importance of data lifecycle management and the delivery of value-adding services [7-9]. A key challenge is the inconsistency of interfaces, protocols, and standards, which hinders DT connection [31]. Future research should focus on universal design and development platforms, infrastructure suitable for industrial practices, and standardization of data and models [32, 33].",
        "keywords": ["digital twin", "five-dimension model", "enabling technologies", "enabling tools", "cyber-physical integration", "virtual models", "physical entities", "data management", "service-oriented architecture", "digitalization", "smart manufacturing"]
    },
    {
        "title": "From building information modeling to construction digital twin: a conceptual framework",
        "summary": "This article investigates the transition from Building Information Modeling (BIM) to Digital Twin (DT) technologies in building construction and facility management [1]. It aims to identify key trends, challenges, and opportunities for research and Industry 4.0 associated with the adoption and implementation of DT as an extension of BIM [1]. The research uses a systematic literature review (SLR) to evaluate published research within the scientific domain [2]. \n\n(1) Definitions:\n*   **BIM:** A digital representation that captures the physical and functional attributes of a facility, serving as an approach to design that fosters shared knowledge among all stakeholders [3]. It encompasses seven dimensions: geometric (3D), scheduling (4D), cost analysis (5D), environmental sustainability (6D), and management/maintenance (7D) [3].\n*   **DT:** A virtual replica of a physical asset (e.g., a building) that incorporates real-time data from sensors, systems, and other sources [4]. It enables monitoring, analysis, and bi-directional simulation of the asset’s performance throughout its lifecycle [4].\n\n(2) Characteristics and Requirements:\n*   **BIM:** Characterized as a process, a model, and a collaboration tool [5]. It relies on standardized formats like IFC and COBie for interoperability [6, 7]. Limitations include static data, lack of real-time updates, and challenges in integrating with IoT devices [4, 8].\n*   **DT:** Requires real-time data integration, connectivity, and advanced analytics to augment static BIM data [9]. It leverages IoT sensors, cloud computing, and data analytics [4, 10]. Aims for a holistic approach to modeling, simulation, analysis, and optimization throughout the entire lifecycle of a construction project [11].\n\n(3) Relevant Use Cases:\n*   **BIM:** Primarily used in the design and construction phases for improved collaboration, enhanced visualization, clash detection, and accurate quantity takeoffs [12].\n*   **DT:** Used for predictive maintenance, energy management, resource optimization, risk mitigation, and enhancing overall operational performance [4, 10]. It enables stakeholders to visualize projects, analyze behavior, detect potential issues, and make informed adjustments [4]. Specific use cases include monitoring bridges and roads, with potential expansion to complex building systems [9, 13].\n\n(4) Technologies and Tools Used:\n*   **BIM:** Utilizes software for 3D modeling, data management, and collaboration [3]. Relies on IFC and COBie formats for data exchange [6].\n*   **DT:** Integrates BIM with IoT devices, cloud computing, and data analytics platforms [4, 10]. Employs visualization tools and analytics platforms for data interpretation and performance assessment [14]. Extended Reality (XR) technologies like Augmented Reality (AR) and Mixed Reality (MR) can be leveraged for on-site data utilization [15].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n*   **Limitations of BIM:** Include incomplete, outdated, or fragmented data; lack of support for real-time updates; and limited interoperability among different BIM software [7, 8]. BIM's reliance on a static database restricts its adaptability to changing maintenance requirements [16].\n*   **Gaps for Transitioning to DT:** Lack of established standards and protocols for BIM and DT integration [17]. The absence of a robust connection between the 3D model derived from BIM and the integration of Internet of Things (IoT) sensors in the DT [17]. Shortage of trained personnel, network stability, data loss during transfer, and heterogeneity of data collected by different IoT sensors are also challenges [17, 18].\n*   **Framework for BIM to DT:** The article proposes a minimal framework to extend BIM into a DT, including constructing the BIM model, creating a semantic middleware, and implementing a fully semantic DT [19]. This involves using specific classes and property sets, integrating IoT sensors, and employing AI for data analytics and predictive simulations [19].",
        "keywords": ["building information modeling", "digital twin", "construction industry 4.0", "operations & maintenance", "systematic literature review", "real-time data", "BIM limitations", "data interoperability", "predictive maintenance", "IoT sensors", "construction execution", "facility management"]
    },
    {
        "title": "Industry application of digital twin: from concept to implementation",
        "summary": "This paper reviews the current state of digital twin (DT) technology across various industries, focusing on its development from initial concepts to practical implementations [1]. It highlights the increasing attention DT has gained due to advancements in AI, big data, and IoT technologies [1, 2]. The core idea is constructing a digital model in cyberspace that mirrors a physical entity, enhancing real-world perception and prediction [1]. The review emphasizes that different industries exhibit unique characteristics in their DT modeling strategies and usage methods due to variations in composition, service conditions, and application scenarios [1].\n\n**(1) Definitions:**\n*   A digital twin is a virtual model of a physical entity, created digitally and updated with real-world monitoring data to simulate the physical entity's behavior [3].\n*   It enables state prediction and decision optimization, reflecting the full lifecycle of physical equipment [3].\n*   Initially proposed in 2003, the term 'digital twin' gained widespread acceptance by 2016 [3].\n\n**(2) Characteristics and Requirements:**\n*   **Consistency:** Maintaining consistency between the physical entity and the virtual model is crucial, including geometric appearance, material properties, and change mechanisms [4].\n*   **Two-way data flow:**  Real-time data collection and synchronization between virtual and physical models are important features, enabling closed-loop operation [5, 6].\n*   **Data Fluidity:** The ability to transfer data between the physical entity and the virtual model is essential [6].\n*   **Individuality, high fidelity, real time, and controllability** are also noted as characteristics of DT [7].\n\n**(3) Relevant Use Cases:**\n*   **Manufacturing:**  DTs are used in product design to identify and solve problems early, optimize production lines, manage orders, and improve assembly efficiency [8-11]. They also facilitate predictive maintenance of manufacturing equipment and efficient workshop management [12, 13].\n*   **Aerospace:** DTs support data management and health state prediction for aircraft structures, enabling closed-loop optimization of design, manufacturing, and maintenance [14].\n*   **Smart Cities:** DTs are applied to urban planning and management, using BIM and 3D geographic information to create virtual city models for smoother traffic, efficient management, and convenient services [15].\n*   **Battery Technology:** DTs focus on predicting battery performance and making maintenance decisions in electric vehicles [16].\n*   **Robotics:** DTs enhance robot reliability and intelligence by enabling real-time environment modeling and adaptation [17].\n*   **AR/VR:** DTs leverage augmented and virtual reality for service development and 3D visualization, enhancing human-computer interaction [18].\n\n**(4) Technologies and Tools Used:**\n*   **Basic Technologies:** Sensor technology, IoT, data storage and management, data transmission, and DT visualization [19-24].\n*   **Core Technologies:** Modeling and simulation, data analysis, and virtual-physical data fusion [19, 25, 26]. Physics-based modeling, semantic-based modeling, and simulation tools like ANSYS and Simulink are used [25, 27, 28]. Data fusion methods include Kalman filter, particle filter, and Bayesian inference [29].\n*   **Advanced Technologies:** Cloud computing, edge computing, big data analytics, machine learning, mobile internet, and blockchain [19, 30-33].\n\n**(5) Special Findings (Requirements/Challenges):**\n*   **Data Processing:**  A key challenge is managing and processing the large amounts of heterogeneous data from various sources [34, 35]. Standardizing data formats and using cloud management can improve data analysis [36].\n*   **Model Accuracy:**  Ensuring the accuracy and real-time consistency of the virtual model with the physical entity is critical. This requires effective data fusion techniques and consideration of uncertainty factors [37, 38].\n*   **Computational Efficiency:** Balancing model complexity with computational efficiency is a challenge, particularly for real-time applications. Edge computing and reduced-order modeling can help address this [39, 40].\n*   **Interoperability:** Achieving interoperability between different DT models and systems is important for broader adoption and data sharing [41].\n*   **Security:** Protecting data collected from the physical world is critical, and blockchain technology can provide a security approach for DT in asset management [33].",
        "keywords": ["Digital twin", "Literature review", "Industry applications", "Modeling method", "virtual model", "physical entity", "data fusion", "smart manufacturing", "aerospace", "smart cities", "internet of things", "artificial intelligence", "big data", "cloud computing", "edge computing", "blockchain", "simulation"]
    },
    {
        "title": "On the requirements of digital twin-driven autonomous maintenance",
        "summary": "This article explores autonomous maintenance, emphasizing digital twins as decision-making tools and the role of AI in this process [1, 2]. It presents recent autonomous maintenance trends and explores a framework for integrating digital twin strategies within maintenance models [2]. \n\n(1) Definitions:\n*   **Autonomous Maintenance:** A preventative strategy where the system is self-governing, using cooperation between personnel and operators to eliminate factors affecting system availability [3]. It aims to reduce system breakdown and maintenance costs [3].\n*   **Autonomy:** The capability that enables a system to function with uncertainty, adaptation, reasoning, and robustness [4]. It involves independence and self-governing capabilities [5].\n*   **Digital Twin:** Regarded as a simulation-of-simulations, described by representations like process graphs, space-time environments or statistical models [6]. It is a model or simulation of a system, process, or service inside a computer with support for technologies like cloud computing, IoT, or machine learning [7].\n\n(2) Characteristics and Requirements:\n*   **Autonomous Maintenance Aims:** Understanding system functions, recognizing quality issues, and timely abnormality detection for self-healing [3, 8].\n*   **System Health Management Requirements:** Fault detection, classification, and prediction [9]. Requires tools based on statistics, reliability, and models, including data-centric and adaptive model-based approaches [9].\n*   **Digital Twin Requirements** Data-driven, incorporating construction, product/service, and performance aspects [10, 11]. It forecasts system health and remaining useful life using sensor data, maintenance history, and data mining [12].\n\n(3) Relevant Use Cases:\n*   **Aerospace:** Reducing maintenance downtime for engines by generating action plans based on simulated scenarios [13]. Mirroring flights, performing in-situ forensics, serving as a learning platform, and flying future missions before launch [14-16].\n\n(4) Technologies and Tools Used:\n*   **AI and Machine Learning:** Used for data analytics, optimization, and building multi-agent systems [4]. Specific techniques include neural networks (NN), genetic algorithms (GA), deep learning, reinforcement learning and generative adversarial networks (GAN) [17-19].\n*   **Digital Twins:** Employed for prognostics and health management, predicting structural life, and damage detection [20].\n*   **Other Technologies:** Cloud computing, IoT, data mining, semantic sensor networks, and ontologies [7, 12, 21, 22].\n\n(5) Special Findings (Requirements/Challenges):\n*   **Data Quality and Availability:** The need for high-quality, accessible data and standardized formats [23]. The article recognizes that required data will not always be available, accessible or of good quality [23]. It recognizes the need to improve data quality [24].\n*   **Real-Time Response:** Maintenance support operations require near real-time response capabilities [25].\n*   **Model Accuracy:** The digital twin's multi-physics model must be accurate [26]. Model uncertainties exist with simulations, optimization, control, and hardware/software limitations [6].\n*   **Integration and Complexity:** Integration of anomaly, diagnostic, and prognostic technologies is needed [27]. There are challenges in scaling technology to complex scenarios [28]. Increasing system complexities and process uncertainties necessitate data-based solutions [17].\n*   **Autonomy Levels:** Defining the level of target autonomy is important [28].\n*   **Technology Readiness:** Assessing the technology readiness level for autonomous maintenance is difficult [29].",
        "keywords": [
        "digital twin", "autonomous systems", "maintenance", "fault detection", "isolation", "reinforcement learning", "machine learning", "system health management", "prognostics", "diagnostics", "data-driven", "AI","cyber-physical systems"]
    },
    {
        "title": "Production logistics digital twins - Research profiling, application, challenges and opportunities",
        "summary": "This study reviews the application of Digital Twins (DTs) in Production Logistics (PL), analyzing research trends, keywords, application scenarios, and basic functions of Production Logistic Digital Twins (PLDTs) [1]. It examines the functional characteristics of PLDTs and summarizes their advantages and limitations across various application scenarios like transportation, packaging, warehousing, material distribution, and information processing [1, 2]. The paper also discusses the roles of smart technologies such as the Internet of Things (IoT) in PLDTs systems [1]. It identifies challenges and future directions for PLDTs in industrial applications [1].\n\n1.  **Definitions:**\n *   Production Logistics (PL) is an essential link between shop-floor supply and production processes, accounting for approximately 95% of the entire production life cycle [3]. It involves scientifically planning, allocating, and controlling material flow within production processes [4]. With Industry 4.0, the emphasis has shifted towards information flow management, demanding flexibility, agility, and consistency in real and virtual interactions within the Production Logistics System (PLS) [4].\n *   Digital Twins (DTs) represent and optimize physical objects through virtual models driven by data and models [5].\n *   Production Logistic Digital Twins (PLDTs) and Logistics Digital Twins (LDT) aim to improve logistics performance [5]. LDT research covers branches like PL, general logistics, e-logistics, cold chain logistics, and military logistics [6]. PL, also known as shop-floor or plant logistics, spans from raw material input to finished goods storage, divided into material distribution, work-in-process transportation, and finished goods warehousing [6].\n\n2.  **Characteristics and Requirements:**\n *   PL management requires effective connection between virtual and physical worlds, seamless integration, and real-time interaction [4]. It also needs systematic integration of heterogeneous systems and data platforms under big data environments, and optimal utilization of computational resources for precise synchronous control in dynamically disturbed environments [7].\n *   DTs facilitate virtual simulation, evaluation, prediction, and autonomous decision-making, enabling integration, interaction, and intelligent interconnection of production and logistics processes [5]. They act as a fundamental theoretical system to realize Cyber-Physical Logistics Systems (CPLS) through cyber-physical fusion, data integration, and virtual-real co-control [8].\n\n3.  **Relevant Use Cases:**\n *   **Transportation:** Transporting materials between production stages using logistics facilities like AGVs and AMRs [9]. DTs enable real-time monitoring, route planning, and synchronous decision-making during transportation [10].\n *   **Packaging:** Protecting products during production, storage, and transportation [11]. DTs support collaborative optimization of packaging and warehousing [12].\n *   **Warehousing:** Controlling, classifying, and managing inventory in storage warehouses [13]. DTs enhance intelligence and flexibility in warehouse management systems [14].\n *   **Material Distribution:** Planning and scheduling raw materials and work-in-progress [13]. DTs facilitate visual tracking and real-time location of PL resources [15].\n *   **Information Processing:** Collecting and processing dynamic information to make forecasts, plans, and decisions related to PL [13]. DTs offer better decision-making support for PL information processing [16].\n *   **Functions:** Decision support, simulation, planning, monitoring, evaluation, design, prediction, and tracking/positioning in PL scenarios [17]. Decision support is the most common function, particularly in information processing [18].\n\n4.  **Technologies and Tools Used:**\n *   **Internet of Things (IoT):** Enables sensing and control of PL resources using RFID tags, WSN, and actuators [19].\n *   **Cloud Computing (CC):** Provides a platform for data storage, processing, and application deployment for PLDTs [20].\n *   **Big Data:** Supports data visualization, virtual model construction, and PL process reproduction [21].\n *   **Artificial Intelligence (AI):** Enhances data analysis and enables intelligent transportation, packaging management, warehousing management, material distribution, and information processing [22-25]. Common AI algorithms include Machine Learning (ML), Reinforcement Learning (RL), and Deep Learning (DL) [22].\n *   **Simulation Technology (ST):**  Fundamental to DTs, enabling virtual simulation for PL processes [26]. Discrete Event Simulation (DES) is used for modeling and achieving periodic decisions in digital supply chain twins [27].\n *   **Cyber-Physical Systems (CPS):** Facilitate storage, analysis, processing, and communication in PLDTs [28].\n\n5.  **Special Findings Related to Digital Twin Requirements or Challenges:**\n *   **Challenges:**\n *   Relatively few cases of PLDTs deployed in industrial scenarios [29].\n *   Asynchronous characteristics of the virtual and physical worlds when random events occur [30].\n *   Limited attention to Production Logistics Equipment (PLE) health management [30].\n *   **Future Directions:**\n *   Focusing on construction methods of PLDTs models with multi-system integration and multi-physical property fusion [31].\n *   Focusing on multi-technology integration like IoT, CC, and CPS [32].\n *   Focusing on health management of PLE driven by digital-analog integration [33]. *   Focus on digital twin lean intralogistics [34]",
        "keywords": [ "Digital Twins","Production Logistics","Production Logistics Digital Twins (PLDTs)","Logistics Digital Twin (LDT)","Industry 4.0","Internet of Things (IoT)","Cyber-Physical Systems (CPS)","Automation","Digitalization","Virtual Simulation","Material Distribution","Warehousing","Transportation","Information Processing","Big Data","Cloud Computing (CC)","Artificial Intelligence (AI)","Machine Learning (ML)","Reinforcement Learning (RL)","Deep Learning (DL)", "Discrete Event Simulation (DES)"]
    },
    {
        "title": "Review of digital twin about concepts, technologies, and industrial applications",
        "summary": "This paper presents a comprehensive review of digital twin (DT) technology, analyzing its concepts, enabling technologies, and industrial applications based on 240 academic publications [1, 2]. \n\n(1) Definitions: The review traces the evolution of the digital twin concept, from its origins in NASA's Apollo program to its modern interpretations [3]. Early definitions focused on high-fidelity models and multidisciplinary simulation [4]. However, more recent definitions emphasize real-time connections with physical objects and bidirectional data mapping [4]. The paper concludes that a digital twin is a digital entity that reflects a physical entity's behavior and updates throughout its lifecycle [5].\n\n(2) Characteristics and Requirements: Digital twins should be individualized, high-fidelity, real-time, and controllable [6]. Individualized means a digital twin is one-to-one with its physical twin, mirroring its design, manufacturing, usage, and maintenance [6]. High-fidelity means the digital twin accurately simulates the physical twin's behavior using multi-physics modeling and continuous updates [6]. Real-time means the digital twin responds to the physical twin with low latency, enabled by mobile communication and IoT [6]. Controllable means changes to either the digital twin or physical twin control the other, closing the loop between the digital and physical [7].\n\n(3) Use Cases: The paper classifies digital twin applications across different lifecycle phases:\n\n*   Design Phase: Digital twins enable iterative optimization, provide data integrity, and facilitate virtual evaluation and verification [8-11]. They can track design footprints, support decision-making, and allow virtual prototyping [9-11].\n*   Manufacturing Phase: Applications include real-time monitoring, production control, workpiece performance prediction, human-robot collaboration, process evaluation and optimization, asset management, and production planning [12-17]. Digital twins enable intelligent control, predict performance, and optimize processes [13, 14, 18].\n*   Service Phase: Digital twins support predictive maintenance, fault detection and diagnosis, state monitoring, performance prediction, and virtual testing [19-23]. They help understand degradation, foresee events, and optimize usage strategies [19, 20, 24].\n*   Retire Phase: Digital twins retain lifecycle information for remanufacturing and recycling [25].\n\n(4) Technologies and Tools: Key technologies include:\n\n*   Data-related technologies: Sensors, RFID, cameras, and scanners for data collection [26]. Edge computing and 5G for data processing and transmission [26]. XML for data mapping [26].\n*   High-fidelity modeling technologies: Multi-physics modeling (e.g., Modelica), flexible modeling in a modular way, and methods incorporating black-box modules and varying modeling levels [27, 28].\n*   Model-based simulation technologies: AutomationML for data exchange, Anchor-Point method for consistency, and real-time data from IoT for simulation [29-32].\n\n(5) Special Findings and Challenges:\n\n*   The review finds that most implementations of digital twins are actually digital models or digital shadows, with limited bidirectional data flow [33, 34].\n*   A lack of universal definitions, implementation frameworks, and protocols hinders development [35].\n*   Challenges remain in data integration, complex phenomena modeling, and human factors [36, 37].\n*   Future research should focus on clarity and specificity in different industry fields, addressing data integration challenges, and developing comprehensive models [5, 37, 38].",
        "keywords": ["digital twin","product lifecycle","simulation","industrial application","literature review","digital manufacturing","cyber-physical systems","data fusion","multi-physics modeling","predictive maintenance","real-time monitoring","virtual verification","manufacturing systems"]
    },
    {
        "title": "State of the Art and Future Directions of Digital Twins for Production Logistics: A Systematic Literature Review",
        "summary": "This paper systematically reviews the application of Digital Twins (DTs) in production logistics, addressing the lack of a unified understanding of DT constitution and usage within these systems [1]. It discusses common definitions, characteristics, and functionalities of DTs, outlining current developments and implications from state-of-the-art implementation approaches [1]. The review identifies research gaps, barriers, and potential directions for future research initiatives in manufacturing enterprises, focusing on implementation concepts and enablers [2].\n\n(1) Definitions: The paper analyzes three commonly used DT definitions:\n\n*   Grieves' three-dimensional model: Focuses on real space, virtual space(s), and a linking mechanism [3].\n*   Glaessgen and Stargel's definition: Centers on an integrated multiphysics, multiscale, probabilistic simulation mirroring a flying twin, emphasizing real-time mirroring for evaluating parameter modifications [4].\n*   Tao et al.'s five-dimensional definition: Includes physical entity, virtual model (VM), service system, DT data, and the connection among these elements, adapted for shop-floor systems [5].\n\nThe review highlights that all definitions describe a VM mirroring the functions, behavior, and state of a physical entity in near real-time, used for predicting future states, evaluating scenarios, adapting to situations, and optimizing the physical entity [6].\n\n(2) Characteristics and Requirements: Key characteristics and requirements identified in the review include:\n\n*   Convergence between physical and virtual spaces: Mandatory, enhanced by bidirectional communication and real-time data integration [2].\n*   Virtual Models (VMs): Essential for mirroring the physical entity, with Discrete Event Simulation (DES) being the most used simulation technique [7, 8]. Frameworks and approaches exist to speed up VM creation by matching real entities with predefined simulation objects [7].\n*   Bidirectional connection to enterprise information systems: Necessary for successful DT implementation, including PLM, ERP, MES, and CRM systems [9].\n\n(3) Relevant Use Cases: The paper identifies several use cases for DTs in production logistics, including:\n\n*   Distribution centers and production facilities: Activities such as receiving, storing, order-picking, cross-docking, line feeding, and line-side presentation [7, 10].\n*   Manufacturing processes: Real-time production monitoring and production schedule verification [11].\n*   Warehouse logistics: Routing, scheduling, resource allocation, waste and energy reduction, storage and transport reduction, space utilization, KPI presentation, decision support, forecasting, and prediction [12].\n*   Machinery prognostics and maintenance management: Predicting machine failures, enabling predictive maintenance, and optimizing parameter settings [13].\n\n(4) Technologies and Tools Used:\n\n*   Simulation software: DES, Multidisciplinary Design Optimization (MDO), Game Engines (GE) like Unity, Physical Simulations (PS), Analytical Models (AM), Agent-Based Simulations (ABS) [14].\n*   Data acquisition and transfer: 3D scanning methods (photogrammetry, LIDAR), XML, OPC UA, MTConnect, MQTT, TSN [11, 13, 15].\n*   Enterprise system integration: PLM, ERP, MES, SCADA, MDC, MDA, PDM, CAD, CAM [9].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n\n*   Lack of universal frameworks: Absence of standardized approaches for DT model building [16].\n*   Limited real-time capabilities: Most DES software solutions lack real-time capabilities, essential for DT technology [17].\n*   Data integration challenges: The connection between and consistency of data in different enterprise information systems vary widely [17].\n*   Need for comprehensive implementation: Only a few fully implemented DTs exist in industrial environments for production logistics processes [17].\n*   SME implementation barriers: Small and medium-sized enterprises (SMEs) face difficulties in implementing DTs due to low automation, insufficient data acquisition, and interlinking of production [18].",
        "keywords": ["Digital Twin", "production logistics", "modeling", "virtual model", "simulation", "systematic literature review", "Industry 4.0", "Cyber-Physical Systems", "manufacturing", "supply chain management", "real-time data integration", "物流"]
    },
    {
        "title": "Technologies for digital twin applications in construction",
        "summary": "This paper systematically reviews the technologies used in developing digital twins for construction, identifies research gaps, and suggests future research areas [1, 2]. It adopts Grieve's early definition of digital twins, which includes a physical product, a virtual product, and a data connection between them [3, 4]. The paper differentiates digital twins from Building Information Modeling (BIM), clarifying that BIM is a starting point for digital twin development, enhanced by real-time data exchange and advanced data analytics [5].\n\nThe paper identifies five key layers in digital twin system architecture: data acquisition, data transmission, digital modeling, data/model integration, and service [6]. Data acquisition involves IoT sensors for collecting real-time data [7]. Data transmission focuses on wired and wireless technologies like Wi-Fi, MQTT, and HTTP protocols [8, 9]. Digital modeling uses 3D models, often BIM models created with software like Autodesk Revit [10]. Data/model integration includes data storage, fusion, processing, analysis, and visualization, using cloud-based platforms and AI techniques [11, 12]. The service layer provides functionalities like real-time monitoring, anomaly detection, and predictive maintenance [13, 14].\n\nThe review identifies research gaps in data transmission, such as the need for long-distance wireless technologies and secure transmission protocols [15, 16]. Interoperability and data integration challenges are highlighted, emphasizing the need for semantic data modeling and standardized data structures [17, 18]. The paper also points out the need for advanced AI techniques for data processing and the exploration of VR/AR technologies for data visualization [19, 20]. The study acknowledges the nascent stage of digital twin applications in construction, calling for more mature practical applications and research into organizational factors affecting implementation [21].\n\nThe components of digital twins in construction applications consist of various physical entities [22]. Most studies used buildings and associated building spaces [22]. Some studies focused on specific building components and systems such as lighting and surveillance systems, air handling units, and building facades [22]. Other studies considered the construction and assembling sites for buildings and road construction sites [22]. All the studies contained a 3D model of the physical entity, with the BIM model being the most common virtual model [23]. The (IoT) Internet of Things sensors were the most used devices for creating a data connection between the physical entities and their corresponding virtual models [23].\n\nData transmission involves the processing and transporting of raw data from the data acquisition layer [8]. The collected data is generally transmitted through wire and wireless transmission technologies [8]. The Wi-Fi wireless short-range technology was used in several applications [8].\n\nThis layer involves the development of the corresponding virtual model of the physical entity [24]. This process is generally done by modelling the digital model [24]. Most of the studies used a 3D model (BIM model) to represent the virtual equivalent of the physical entity [10]. Autodesk Revit was the most used software for 3D modelling of buildings [10].\n\nIn the data/model integration layer, the digital twin data undergoes a series of stages that include data storage, data/model integration and fusion, data processing and analysis and data visualisation to produce useful information [11]. Digital twin data is multi-source and of high volume requiring big data storage technologies [11]. The studies mostly used cloud-based computing platforms for data storage [25].\n\nThe last layer represents the service that digital twin offers to the users [13]. Digital twin offers a diverse range of services depending on the context within which it is applied [13]. The most common service offered in the studies was real-time monitoring of assets and activities [13]. Another functionality of the digital twin involved early detection [14]. Moreover, digital twins were applied for the prediction of faults in building systems, the condition of a chiller system, and comfort and CO2 levels in spaces [14].",
        "keywords": ["Digital twin","Digital construction technologies","Building information modelling (BIM)","Internet of Things","System architecture","Systematic literature review","Data acquisition","Data transmission","Digital modelling","Data/model integration","Data processing","Data visualization","Real-time monitoring","Anomaly detection","Predictive maintenance"]
    },
    {
        "title": "A Comprehensive Review of Digital Twin from the Perspective of Total Process: Data, Models, Networks and Applications",
        "summary": "This review paper provides a comprehensive overview of digital twin (DT) technology, examining it from the perspective of the total process: data, models, networks, and applications [1]. It emphasizes the increasing importance of information interaction between physical and virtual spaces due to industrial digitalization, informatization, and intelligence [2]. The paper addresses the need for accurately depicting the physical world in digital space to regulate and optimize physical entities based on extensive data collection and analysis [1]. It explores the current research, challenges, and future directions in the field, aiming to provide a systematic understanding of DT development [1].\n\n**(1) Definitions:**\nThe paper acknowledges the ongoing debate and multiple perspectives on the definition of a digital twin [3]. It references several definitions:\n*   Kritzinger et al. [2] define a digital twin as a digital representation of a physical entity with a fully integrated and automated bi-directional data flow [3].\n*   Wu et al. [3] divide the digital twin into the physical entity, its virtual counterpart, and the mapping between them, allowing co-evolution [3].\n*   Tao et al. [4] define it as a PLM component using physical, virtual, and interactive data from the product lifecycle for real-time mapping [3].\n*   Zhuang et al. [5] define a digital twin as a virtual dynamic model in a virtual environment that replicates a physical entity [3].\n*   Barricelli et al. [6] consider it a living, intelligent, and evolving model serving as the virtual counterpart of a physical entity or process [3].\n\nThe paper also distinguishes digital twins from digital shadows, emphasizing the bi-directional data flow and autonomous evolution of digital twins, unlike the primarily representational focus of digital shadows [4]. Digital shadows are seen as a potential precursor to digital twins, focusing on historical data analysis, while digital twins are real-time virtual duplicates capable of seamless data synchronization [4].\n\n**(2) Characteristics and Requirements:**\nThe key characteristics and requirements of digital twins, as highlighted in the paper, include:\n*   **Real-time information interaction:**  A foundation for accurate mapping between physical and virtual entities [7].\n*   **High-fidelity:** Twin entity modeling must meet high fidelity criteria, ensuring accuracy and real-time performance to represent the physical entity's true state [8].\n*   **Bi-directional data flow:** Fully integrated and automated data flow between physical entities and their digital counterparts [4].\n*   **Data Reliability:** Accurate data collection, fusion, and analysis are crucial, along with data security, privacy, and trustworthiness [7].\n*   **State Synchronization:** Maintaining synchronized states between physical entities and virtual models through real-time data interaction [5, 9].\n*   **Continuous Updating:** Regular updates of the twin model are needed to reduce deviations from the physical entity [10].\n*   **Computational Resources**: Digital Twin Networks require hardware for computational tasks and data exchange [11].\n\n**(3) Relevant Use Cases:**\nThe paper discusses digital twin applications across various scenarios:\n*   **Industrial Environment Monitoring and Prediction:** Determining optimal maintenance strategies for equipment [12].\n*   **Healthcare Monitoring and Forecasting:** Medical diagnosis, personal health monitoring, and prediction [13].\n*   **Battery Health Management:** Improving the safety, reliability, and performance of battery systems [14].\n*   **Building Information Management:** Development and maintenance phases of construction projects [15].\n*   **Traffic Monitoring and Forecasting:** Traffic monitoring and prediction for urban management [16].\n\n**(4) Technologies and Tools Used:**\nThe enabling technologies and tools mentioned in the paper include:\n*   **Internet of Things (IoT):** For data acquisition from physical systems [2].\n*   **Artificial Intelligence (AI):** For data analysis, prediction, and autonomous evolution of twin networks [2].\n*   **Next-generation mobile communications (6G):**  For data communication [2].\n*   **Big Data (BD):** For data collection and analysis [2].\n*   **Virtual Reality (VR) and Augmented Reality (AR):**  For visualization [2].\n*   **Mobile Edge Computing (MEC):** For distributed and low latency computing [17].\n*   **Blockchain:** For data security, integrity, and trustworthiness [18, 19].\n*   **Federated Learning:**  For distributed data processing and privacy preservation [20].\n*   **Deep Learning:** For processing large amounts of data to improve data quality and ensure model accuracy [21].\n*   **Digital Twin Networks (DTN):** A many-to-many mapping network comprised of numerous digital twins (DTs), in which physical entities and virtual counterparts can communicate with each other and cooperate to perform complex tasks [5].\n\n Specific examples of how these technologies are used:\n*   **Sensors:** Used to collect data in physical systems [22].\n*   **Mobile Edge Computing (MEC):**  Used to perform processing operations at the endpoint to reduce computational load and data transmission delay [17].\n*   **Blockchain:** Used to regulate the behavior of participants and to secure data transmission and transactions [19].\n*   **Federated learning:** Used to build digital twin models of devices and avoid raw data transmission to enhance privacy protection [20].\n\n**(5) Special Findings Related to Digital Twin Requirements or Challenges:**\nThe paper highlights several challenges and areas for future research:\n*   **Data Filtering:** Processing massive real-time data requires optimizing computing offloading strategies or filtering high-value data [23].\n*   **Reconstructing Digital Twins:** Quick reconstruction of digital twins is needed for timely deployment, but the reusability of twin models and the costs and accuracy of deployment pose challenges [23].\n*   **Migration of Twin Entities:** Maintaining physical-virtual state synchronization during model migration needs improvement by enhancing model migration efficiency and accuracy [24].\n*   **Splitting Digital Twins:**  Splitting digital twins into sub-digital twins and distributing them to resource-rich areas might be considered to ensure normal operation [25].\n*   **Evolution of the Digital Twin:** Improving the overall performance of digital twin systems through information interaction and self-learning requires further research in computing, communication, security, privacy, and AI technologies [25].\n*   **Data Management Challenges:** Ensuring data security, privacy, and trustworthiness in distributed data management scenarios [26].\n*   **Model Construction and Update:** Addressing slow modeling speeds, simulation lags, and the lack of a universal model construction method [27]. Balancing model accuracy with update frequency [10].\n*   **State Synchronization:**  Addressing data synchronization during data transfer, and model state update latency [28].\n",
        "keywords": ["digital twin", "twin data", "twin model", "twin network", "twin deployment", "data collection", "data processing", "data management", "model construction", "model updating", "state synchronization", "computational offloading"]
    },
    {
        "title": "A comprehensive survey of digital twins: Applications, technologies and security challenges",
        "summary": "This survey paper provides a comprehensive overview of digital twin (DT) technology, focusing on applications, architectural layers, and security aspects [1]. It addresses the lack of a systematic review of DT security literature across various domains and architectural layers [1]. The paper identifies DT categories and definitions, application domains, and relevant software and tools for DT creation/modeling [2]. It proposes a detailed digital twin security framework consolidating prior research, using a taxonomy of threats, attacks, controls, and vulnerabilities to analyze DT security issues [3]. The study surveys and analyzes various attack methods on digital twins, including manipulating normal behavior and exploiting real-time conditions [3]. It also provides approaches to secure DTs from identified attacks, illustrating this with a blockchain-based case scenario, and identifies ways DT can solve security challenges across different application domains [4]. The paper offers recommendations and best practices to improve DT security and identifies unsolved issues and challenges [4].\n\n(1) Definitions: The paper notes that a universally agreed-upon definition of a digital twin does not exist, but it is commonly understood as a virtual representation of a physical object (PO) capable of simulating and analyzing the PO's performance in the real world [5, 6]. The concept involves using mathematical models, APIs, and specification-based technologies to characterize physical assets [5]. The paper categorizes DTs into Product Digital Twins, System Digital Twins, Process Digital Twins, IoT-Enabled Digital Twins, Human Digital Twins, and Service Digital Twins, each serving different purposes across various industries [7-11].\n\n(2) Characteristics and Requirements: DTs comprise a physical object, a virtual model, and a data connection linking the two [12]. Key components include digital representations, sensors, software platforms, user interfaces, communication channels, data storage and processing, statistical and AI algorithms, and security and access control components [13-16]. Functional layers include data acquisition, data synchronization, data modeling, and data visualization [16-20]. Operational requirements emphasize security (confidentiality, integrity, availability), interoperability (composability, heterogeneity), dependability, predictability, reliability (robustness), and sustainability (efficiency, reconfigurability) [21-29].\n\n(3) Use Cases: Digital twins are deployed across various sectors, including oil and gas, transportation, automated guided vehicles (AGVs), water management, electrical energy, chemical and petrochemical, manufacturing, automotive, and healthcare [30, 31]. They are used to monitor and optimize operations, predict equipment failure, simulate traffic flow, optimize logistics, enhance safety protocols, model water distribution networks, control power generation, simulate chemical reactions, optimize production processes, simulate vehicle performance, test new features, and model patient anatomy for personalized treatments [30, 31].\n\n(4) Technologies and Tools: The enabling technologies include IoT, AI, VR/AR, big data, and cloud computing [32-34]. Tools range from CAD software and simulation software like Simio, Arena, and AnyLogic to data analytics platforms like TensorFlow and Keras [35, 36]. Data processing utilizes edge, fog, and cloud computing [37]. Software for DT creation includes commercial options like Azure DT (Microsoft), AWS IoT TwinMaker (Amazon), and Siemens NX software, as well as open-source platforms like Eclipse Ditto (Bosch) and iTwin.js (Bentley) [36, 38].\n\n(5) Special Findings: The study identifies security vulnerabilities arising from increased connectivity, isolation assumptions, and heterogeneity within DT systems [39-41]. It highlights the importance of addressing both generic and layer-specific vulnerabilities to develop effective security strategies [42, 43]. The research also explores how DTs can be used to enhance cybersecurity through risk management, active cyber defense, autonomy, and predictive analytics [44-46]. Key challenges include high development costs, interoperability issues, data management complexities, and the need for user-friendly interfaces [47-49]. Insider threats and intellectual property theft are also significant concerns [50, 51].",
        "keywords": ["digital twin", "virtual twin", "digital twin security", "digital twin network", "digital twin modeling", "DT enabling technologies", "security challenges", "applications", "architectural layers", "cybersecurity", "IoT", "AI", "threats", "vulnerabilities", "countermeasures"]
    },
    {
        "title": "A comprehensive survey on digital twin for future networks and emerging Internet of Things industry",
        "summary": "This survey paper provides a comprehensive overview of digital twins (DTs) within the context of future networks and the Internet of Things (IoT). It explores definitions, characteristics, use cases, technologies, and challenges associated with digital twins. The paper highlights the transformative potential of DTs in various industries while also addressing the hurdles to their widespread adoption.\n\n(1) Definitions:\nThe paper defines a digital twin as a virtual representation of a physical entity or system, enabling communication between the physical and information worlds [1]. It utilizes data collected from the physical world to create a virtual model [1]. Digital twins can be discrete or composite, depending on the use case and scale, with component/part twins representing individual parts and discrete DTs representing lower levels of abstraction [2]. Typologies of DTs include imaginary, monitoring, predictive, prescriptive, autonomous, and recollection DTs [3].\n\n(2) Characteristics and Requirements:\nKey characteristics of a DT include network connectivity, a physical entity/asset, and a physical environment [4]. Effective DTs should exhibit representativeness, contextualization, reflection and replication, persistency, and composability [5]. Representativeness involves effective behavioral representation, virtual replica construction, and state synchronization [5]. Context-awareness is crucial [5]. Data and models within a DT exist in digital formats like JSON and XML [6]. Time series data is used to collect and analyze historical data [6].\n\n(3) Relevant Use Cases:\nDigital twins find applications across multiple industries, including smart cities, smart agriculture, healthcare, energy, network management, building management, transportation, and manufacturing [7, 8].\n*   **Smart Cities:** DTs facilitate urban planning, construction, and sustainable development by combining metaverse and AI tools [7]. They improve urban operational mechanisms and simplify upgrades [7].\n*   **Smart Agriculture:** DTs enhance the digitalization of agricultural production by offering data processing techniques for farm management, remote sensing, and smart water management [9, 10].\n*   **Healthcare:** DTs enable health monitoring, personalized medicine, and improved healthcare supply chains [11, 12]. They can model patients, process data using NLP, and assist in surgery planning [12].\n*   **Manufacturing:** DTs aid in design verification, layout planning, predictive maintenance, production planning, and process optimization [13].\n*   **Cultural Heritage:** Heritage Digital Twins (HDT) digitalize Heritage Assets (HA) to improve the digital transformation of cultural heritage [14].\n\n(4) Technologies and Tools Used:\nThe paper discusses various software implementations and platforms for building digital twins:\n*   **ScaleOut DT:** A cloud and on-premises service with tools for building real-time DT models, using an in-memory data grid and machine learning [15].\n*   **Davra Platform:** A full-stack open-source IIoT platform for defining, building, and prototyping DTs [16].\n*   **Cyber-Physical Systems (CPS) Twinning:** An open-source framework for developing and executing DTs for CPS, using Automation ML (AML) for data exchange [17].\n*   **Twinbase:** Contributes to the development of DT Web (DTW), utilizing YAML for DT document creation and integrating standards like Industry 4.0 Asset Administration Shell [18].\n*   **Azure DT:** A Microsoft service for creating digital representations of physical assets and environments [19].\n*   **AWS IoT TwinMaker:** A service for creating DT applications on top of the AWS platform, integrating with services like Amazon Device Shadow [19, 20].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\nThe paper identifies several challenges and research directions for digital twins:\n*   **Security and Vulnerability:** Security and privacy are major concerns, with data in DT networks vulnerable to cyberattacks [21]. Data leakage risks arise from data aggregation and synchronization [21].\n*   **Ethics:** Ethical considerations are essential, including responsibility, data sovereignty, and the psychological effects of DTs in healthcare [22].\n*   **Scalability and Complexity:** Building DTs for large-scale projects requires sophisticated data acquisition and storage, with both software and hardware components becoming more constrained [23].\n*   **Data Coherence and Model Revision:** Ensuring high data fidelity is challenging due to the huge volumes of data [24]. Integrating blockchain and IPFS for data distribution is suggested [24].\n*   **Unclear Access to Quality Data:** Data quality is paramount for prediction accuracy, but variability and heterogeneity of data pose a significant burden [25].\n*   **Need for Standardization:** Interoperability between different industrial applications requires a unified framework and standardized APIs [26, 27].\n\nThe paper concludes by emphasizing the need for further research to address these challenges and promote the widespread adoption of digital twins across various industries [26, 27]. It calls for open, standardized APIs and a focus on composability, distributed intelligence, and security by design frameworks [27].",
        "keywords": ["Digital Twin", "Internet of Things", "Interoperability", "Standardization", "Frameworks", "Prototypes", "Security", "Industrial IoT", "Smart Cities", "Smart Agriculture", "Healthcare", "Manufacturing", "Cybersecurity", "Data Quality", "Ethics"]
    },
    {
        "title": "A new quantitative digital twin maturity model for high-end equipment",
        "summary": "This paper introduces a digital twin (DT) maturity model designed for high-end equipment, emphasizing both qualitative and quantitative evaluation methods. The model aims to assess the maturity level of DTs and guide their advancement. \n\n(1) **Definitions:** The paper defines a DT maturity model as a multi-level framework describing the progression of DT development for high-end equipment throughout its lifecycle [1]. Each level incorporates specific criteria or characteristics that must be met [2]. The paper also defines high-end equipment as valuable equipment in advanced products, including industrial manufacturing, energy transmission, and underground engineering equipment [3].\n\n(2) **Characteristics and Requirements:** The qualitative analysis framework consists of three dimensions: value, function, and reliability [4]. \n* Value assesses the benefits derived from DT utilization throughout the equipment's lifecycle, including economic advantages and potential future developments [5]. Key aspects involve enhancing operational efficiency, reducing maintenance costs, and utilizing DT data to improve the design of subsequent equipment generations [5].\n* Function evaluates how well the DT development aligns with the intended purpose for high-end equipment while addressing specific user needs [6]. Model updating processes, data storage, exchange, sharing capabilities, and data visualization are crucial for mirroring physical entity functions [7].\n* Reliability ensures the DT system's stable and accurate operation, even amidst external disturbances [8]. High security and openness standards are essential, with a focus on ensuring the integrity and accuracy of the digital thread model and data resources [8].\n\nThe model includes 27 rubrics distributed across these dimensions [9]. Six maturity levels are defined for each rubric, providing a scoring guide [10].\n\n(3) **Relevant Use Cases:** The DT maturity model was applied to three types of high-end equipment:\n* Underground engineering equipment: Focuses on high-fidelity simulation to mitigate risks in complex environments [11].\n* Large-scale wind turbine: Integrates performance attributes (load, stress, strain, fatigue) into simulations for condition monitoring [12].\n* Industrial shop-floor: Aims to achieve personalized customization and service extension through intelligent production and lean management [13].\n\n(4) **Technologies and Tools Used:**\n* Analytic Hierarchy Process (AHP): Used for weighting the dimensions and rubrics based on pairwise comparisons by experts [10, 14, 15]. AHP determines the relative importance of each criterion [14].\n* Matter-element extension method: Employed to assess the improvement difficulty of each rubric and prioritize areas for future development [10, 16, 17]. This method uses a closeness function to identify which rubrics should be improved [17].\n\n(5) **Special Findings and Challenges:**\n* The DT maturity levels for the underground engineering equipment, wind turbine, and shop-floor were evaluated as Level 5, Level 4, and Level 4, respectively [18].\n* The underground engineering equipment DT had the highest total maturity score and the lowest standard deviation, indicating a more robust evaluation [18].\n*  The weights of the value, function, and reliability dimensions were calculated as 0.43, 0.42, and 0.15, respectively, demonstrating their relative importance in the maturity model [19].\n* Improvement priorities for each DT were determined based on rubric significance, current level, and improvement difficulty. For instance, for underground engineering equipment, rubrics R4, R9, R2, and R3 were identified for improvement [20].",
        "keywords": ["digital twin", "high-end equipment", "maturity model", "analytic hierarchy process", "matter-element extension method", "qualitative analysis", "quantitative analysis", "performance evaluation", "reliability", "value", "function", "underground engineering equipment", "wind turbine", "shop-floor"]
    },
    {
        "title": "A Requirements Driven Digital Twin Framework: Specification and Opportunities",
        "summary": "This paper presents a baseline framework for Digital Twin (DT) technology, emphasizing its increasing importance in Smart Manufacturing (SM) or Industry 4.0 (I4.0). The framework is derived from an analysis of existing DT definitions, current uses, expected applications, future trends, and the overall vision for DTs in SM. \n\n(1) Definitions: The paper highlights the lack of a consistent DT definition in manufacturing, noting that the term is often broadly applied. The authors propose a DT definition as a 'purpose-driven dynamic digital replica of a physical asset, process, system, or product' [1]. This definition emphasizes that a DT is not a complete replica but rather an aspect of a manufacturing system designed to improve the manufacturing environment and provide value to DT clients [1].\n\n(2) Characteristics and Requirements: The paper identifies several key requirements for a DT framework, including:\n* Re-usability: DT solutions should be portable and re-usable to maximize leverage [2-4].\n* Interoperability: DTs must be able to interact with other DT instances, classes, and non-DT capabilities [2, 3, 5].\n* Interchangeability: DTs should be modular for easy assessment, updating, or replacement [2, 3, 5, 6].\n* Maintainability: DTs must be maintainable over a useful period, including on-line tuning and off-line rebuilding [2, 6, 7].\n* Extensibility: DTs should be extensible across the entire manufacturing ecosystem [2, 8, 9].\n* Autonomy: increasing levels of automation in DT creation, validation, and maintenance [2, 10].\n\nThe characteristics of a DT include:\n* Being a digital replica of a real thing [11].\n* Existing as a software entity in the cyber world [11].\n* Having a purpose of positively impacting the environment of its real counterpart [11].\n* Using models and incorporating subject-matter expertise (SME) [11].\n* Using data to maintain synchronization with its real counterpart [12].\n\n(3) Relevant Use Cases: The paper discusses various existing DT applications, such as Model-Based Process Control (MBPC), predictive maintenance (PdM), virtual metrology, and sensor fusion [12, 13]. It also presents a case study on process-capability-aware real-time scheduling and dispatch in semiconductor wafer fabrication, demonstrating how different DT classes can be combined to optimize production schedules and improve profit [14, 15].\n\n(4) Technologies and Tools Used: DTs utilize a wide variety of models and analytics, chosen based on their purpose and the availability of SME and analytical resources [16]. The modeling approaches provide intelligence, enabling each DT to perform its intended function [16]. The paper emphasizes the complementary use of analytics and SME for quality and robustness [16]. Object-oriented (O-O) technology is employed to define the structure, behavior, and relationships between DT types, using constructs like objects, classes, instances, inheritance, generalization, and aggregation [17-20].\n\n(5) Special Findings Related to DT Requirements or Challenges: The paper identifies several gaps in current DT approaches, including the lack of mechanisms to convey prediction quality and the lack of commonality in structure and behavior among DT types [21]. It emphasizes the need for a unified framework to support DT creation, extension, exchange, reuse, and integration [22]. Key challenges include automating DT maintenance, creating and validating DTs, incorporating analytics and SME, and ensuring data sharing while protecting intellectual property [23, 24]. The paper also points out the importance of addressing security concerns related to DT data, models, and computational approaches, especially in heterogeneous environments [9, 25].",
        "keywords": ["digital twin", "industry 4.0", "smart manufacturing", "modeling", "prediction", "re-usability", "interoperability", "interchangeability", "maintainability", "extensibility", "autonomy", "object-oriented architecture"]
    },
    {
        "title": "A review of digital twin capabilities, technologies, and applications based on the maturity model",
        "summary": "This review paper addresses the issues of formulating objectives, assessing development levels, and evaluating the effectiveness of Digital Twins (DT) in practical implementations [1]. It introduces a five-level Digital Twin Maturity Model (DTMM) to align DT capabilities, objectives, and technical requirements [1]. The paper catalogs supporting tools for developers and examines the application status across six DT vertical sectors to confirm the efficacy of the DTMM [1].\n\n(1) **Definitions:** A Digital Twin (DT) is a virtual representation of a physical entity that evolves through data exchanges, maintaining congruence throughout its lifecycle [2]. It autonomously engages in analysis, simulation, deduction, forecasting, and diagnostics, channeling the outcomes back to the physical entity [2]. Multiple DTs can be integrated for larger-scale deductions and policy decisions [2].\n\n(2) **Characteristics and Requirements:** DTs should possess enhanced intelligence and capabilities for large-scale integration, constructing multi-twin integrated platforms across domains and systems to achieve autonomous reasoning, prediction, decision-making, and optimization [3]. DTs require capabilities like virtual modeling, simulation, two-way communication, human–machine interaction, intelligence, and integration, along with functional characteristics of full lifecycle management and closed-loop control [4]. Data management is also a crucial capability [5].\n\n(3) **Relevant Use Cases:**\n\n*   **Aerospace:** Predictive maintenance, structural health assessment, and extending aircraft service life [6, 7].\n*   **Smart Manufacturing:** Product lifecycle management, virtual commissioning, and optimizing complex manufacturing processes [8, 9].\n*   **Smart Grid:** Monitoring, early warning, simulation, analysis, testing, and control functionalities for the grid [10].\n*   **Smart City:** Urban planning, building management, traffic optimization, and disaster management [11, 12].\n*   **Healthcare:** Personalized medicine, constructing virtual models of the human body or organs for precise treatment plans [13].\n*   **Digital Twin Earth:** Integration of models and observational data for analyzing Earth system dynamics and enhancing decision-making in areas like air traffic management and flood forecasting [14, 15].\n\n(4) **Technologies and Tools Used:**\n\n*   **Data Management:** IoT infrastructure, cloud-edge computing, 5G, and advanced data transmission and exchange protocols [16].\n*   **Modeling and Simulation:** Model-driven and data-driven approaches, Discrete Event Simulation (DES), and Agent-Based Modeling (ABM) [17].\n*   **Intelligence:** Machine learning and deep learning algorithms [18].\n*   **Human-Machine Interaction (HMI):** Virtual Reality (VR) and Augmented Reality (AR) [19].\n*   **Integration:** DT integration platforms for data, model, and API integration [20].\n*   **Security:** Blockchain technology [21].\n\n(5) **Special Findings Related to Digital Twin Requirements or Challenges:**\n\n*   **Data Management Challenges:** Stringent requirements for real-time computing, communication, and control pose challenges [22].\n*   **Modeling and Simulation Challenges:** Achieving high-accuracy, high-fidelity virtual models remains difficult [23].\n*   **Intelligent Challenges:** Augmenting the intelligence quotient of DT and embodying cognitive attributes is an ongoing effort [24]. The rise of Large Language Models (LLMs) and AI Agents may brighten the future outlook [24].\n*   **HMI and Integration Challenges:** Melding theories such as Human in the Loop and ergonomics to fully leverage human subjective agency [25].\n*   **Security and Privacy Challenges:** Addressing cyber threats, data integrity, and privacy-sensitive data requires a security and privacy reference framework [26].",
        "keywords": ["Digital Twin","DT","Maturity Model","Digital Twin Maturity Model","DTMM","capabilities","technologies","applications","virtual modeling","simulation","two-way communication","human-machine interaction","intelligence","integration","data management","cyber-physical systems"]
    },
    {
        "title": "A Survey on Digital Twin: Definitions, Characteristics, Applications, and Design Implications",
        "summary": "This survey paper provides a comprehensive analysis of Digital Twin (DT) technology, exploring its definitions, characteristics, applications, and design implications. It begins by tracing the evolution of AI and related technologies like IoT, big data, and cloud computing, which have collectively enabled the creation of DTs [1, 2]. The paper highlights that while DTs are gaining traction across various sectors, a detailed description of a generic DT is lacking in the literature [3]. The study addresses this gap by answering three key research questions: defining DTs, identifying their main characteristics, and exploring their application domains [4, 5].\n\n**Definitions:** The paper presents a synthesis of DT definitions found in the literature, emphasizing that DTs are more than just models or simulations; they are living, intelligent, and evolving virtual counterparts of physical entities [6]. These entities can be objects, processes, humans, or human-related features. A crucial aspect is the unique key linking each DT to its physical twin, enabling a bijective relationship [6]. The DT continuously interacts, communicates, and synchronizes with its physical twin and the surrounding environment, facilitated by real-time data exchange and big data storage [6, 7]. AI algorithms are then applied for descriptive, predictive, and prescriptive analytics, enabling capabilities like predictive maintenance and self-healing mechanisms [7]. The concept of a 'Product Avatar' (PA) is also discussed, highlighting its similarities and differences with DTs [8]. While both are digital counterparts, DTs possess the intelligence to trigger actions on their physical twins, whereas PAs are limited to being perfect virtual replicas [8].\n\n**Characteristics and Requirements:** The core characteristics of DTs revolve around seamless connectivity, continuous data exchange, and AI-driven intelligence [9-11]. Both physical and digital twins require networking devices for constant data flow, either directly or through cloud-based connections [9]. The DT continuously receives dynamic data reflecting the physical twin's status and the surrounding environment, and sends back predictions and prescriptions for system maintenance and optimization [10]. A data storage system is essential, housing both dynamic data and historical static data, including descriptive information and the physical twin's memory [12]. Ontologies are crucial for data comprehension and formalization, enabling information exchange between heterogeneous agents [13]. Furthermore, DTs must be capable of processing high-dimensional data using effective analysis techniques and data fusion algorithms [13]. AI, continuously refined by incoming data, is integral for descriptive, predictive, and prescriptive tasks [11]. Feature selection and extraction are used to reduce data dimensionality and extract salient information, enabling real-time cyber-physical synchronization and closed-loop optimization [11]. Self-adaptation and self-parameterization allow the DT to resemble its physical twin throughout its lifecycle, facilitated by modular and parameterized architectures [14]. The DT also employs predictive analytics to forecast future states and prescriptive analytics to make informed decisions, leveraging optimization algorithms to achieve the best outcomes [15].\n\n**Relevant Use Cases:** The study identifies three primary application domains for DTs: manufacturing, aviation, and healthcare [16]. In manufacturing, DTs are used to optimize the entire product lifecycle, with a modular approach enabling autonomous modules to execute tasks without human intervention [16]. They facilitate continuous communication between the system and the physical asset, integrating knowledge from human experts and historical data [17]. The Data-Driven Smart Manufacturing (BDD-SM) approach leverages DTs, sensors, and IoT to process big data through AI and cloud analytics for monitoring processes, identifying failures, and optimizing solutions [18]. The concept of a Digital Twin shop floor emphasizes intelligent applications and fused data from various sources, integrating a service system (SS) and Digital Twin Data (DTD) for comprehensive information [19]. In aviation, DTs are primarily used for predictive maintenance, decision support, optimization, and diagnostics [20]. Examples include assessing prediction confidence, tracking crack growth in aircraft materials, and modeling the impact of multi-physical environments on structural performance [20, 21]. Digital Twins can also monitor the state of aircraft wings using dynamic Bayesian networks and analyze guided wave responses for real-time damage prediction [21]. In healthcare, DTs are used for predictive maintenance of medical devices, hospital lifecycle optimization, and, most notably, the creation of human DTs [22, 23]. These human DTs aim to predict illnesses by analyzing an individual's history and current context, enabling personalized treatments [23]. The Virtual Physiological Human (VPH) is highlighted as a precursor to the human DT, facilitating in-silico clinical trials and testing [24]. Examples include DTs of organs like the heart and airway system, aiding physicians in making predictions and evaluating treatment effectiveness [25-27].\n\n**Technologies and Tools:** The technologies underpinning DTs include AI algorithms (supervised/unsupervised learning, pattern recognition, statistical applications) [11, 14], Big Data analytics, cloud computing, IoT sensors, and data fusion techniques [2, 7, 18, 28]. Specific tools mentioned are ANSYS for computational fluid dynamics simulations in airway DTs [27] and software like Sim&Cure for virtualizing aneurysms [29]. The Living Heart software by Dassault Systèmes is also highlighted as a DT of the heart [26].\n\n**Special Findings, Requirements and Challenges:** The paper emphasizes the importance of a sociotechnical and collaborative approach to DT design, involving domain experts and stakeholders to address evolving needs [30]. End-User Development (EUD) methods and tools are suggested to empower domain experts in modifying and extending DT systems [31]. Two distinct lifecycles for DTs are described: one where the DT is designed concurrently with the physical object, and another where the DT is retrofitted to an existing object [32]. Ethical issues, security and privacy concerns, and the high cost of development are identified as significant challenges [33-35]. The need for open repositories and distributed development environments to avoid an industrial oligopoly is also highlighted [35]. Furthermore, the paper discusses the limitations in seamless connectivity for human DTs and the need for advancements in data visualization [36, 37]. Government regulations for medical DTs and the importance of Human Work Interaction Design (HWID) are also crucial for the success of Digital Twin technology [38, 39].",
        "keywords": ["digital twin", "artificial intelligence", "human-computer interaction", "Internet of Things", "machine learning", "sensor systems", "manufacturing", "aviation", "healthcare", "big data analytics", "cyber-physical systems", "predictive maintenance"]
    },
    {
        "title": "A systematic review of digital twin about physical entities, virtual models, twin data, and applications",
        "summary": "This paper provides a comprehensive review of digital twin (DT) technology, focusing on its fundamental components, application areas, and future research directions. The review analyzes 117 articles published between 2017 and 2022, offering insights into the definition, characteristics, and applications of DTs across various domains. It clarifies the relationship between DTs and cyber-physical systems (CPS), emphasizing their differences in definition, core elements, virtual-reality mapping methods, and application scenarios. The paper also examines the research methodologies related to the core components of DTs: physical entities, virtual models, and twin data. It categorizes and analyzes popular application areas of DTs, such as manufacturing, smart cities, and healthcare, and explores potential application areas like food, agriculture, and oil and gas. Furthermore, the review identifies key challenges and future research directions, including the need for more detailed and general DT definitions, accelerated modeling techniques, and the integration of machine learning (ML) and deep learning (DL) to enhance DT capabilities. The study concludes by highlighting the importance of establishing a common software platform for multi-domain DTs to facilitate model construction, testing, and implementation.\n\n---\n### Explanation of Summary Points\n\n**Definitions**: The paper clarifies the definition of a digital twin by comparing it with cyber-physical systems (CPS). It highlights that while both DTs and CPS facilitate interaction between the virtual and physical worlds, they differ in their implementation. DTs optimize physical entities through virtual model simulation, while CPS controls physical equipment using sensor data and computer-generated instructions. The core components of a DT are physical entities, virtual models, and twin data, whereas CPS comprises a perception layer, a network layer, and a control layer. A key distinction is that DTs necessitate a virtual model, which is not a requirement for CPS.\n\n**Characteristics and Requirements**: Digital twins should have characteristics of accuracy and dynamic consistency. In the operational process phase, digital twin models should be evolvable and reconfigurable. In the dynamic interaction phase, interoperability and visualization are important.\n\n**Relevant Use Cases**: The paper categorizes DT applications into three phases: the design phase, the operation process phase, and the dynamic interaction phase.\n- **Design Phase**: DTs are used to simulate and verify product designs or optimize the structure of physical entities, with applications in product and structural design.\n- **Operation Process Phase**: DTs are used to predict the future working state of physical entities and are applied in fault diagnosis, predictive operations, medical领域 (medical field), and quality control.\n- **Dynamic Interaction Phase**: DTs enable visualization and dynamic interaction with physical entities, with applications in shop floors, cities, monitoring, manufacturing systems, and power plants. The paper also explores emerging applications in food, agriculture, oil and gas, indoor safety management, personality prediction, supply chain management, computational efficiency offloading, LED design, and mineral resource acquisition.\n\n**Technologies and Tools Used**: Various technologies and tools support DT implementation: sensors for data acquisition, 3D modeling software for constructing virtual models, and data exchange protocols for virtual-real data interaction. The paper also mentions dynamic Bayesian networks for updating virtual models and ML/DL techniques for iterative evolution of these models. Specific data conversion protocols (e.g., TCP/IP and OPC UA) enable effective communication between physical and virtual environments.\n\n**Special Findings Related to Digital Twin Requirements or Challenges**: The review identifies several challenges and future research directions:\n- **Need for more detailed and general DT definitions**: Many existing definitions are not universal and may not apply across all scenarios.\n- **Accelerating modeling techniques**: Speeding up modeling processes and reducing model weight are crucial for resource efficiency.\n- **Combination of DT and ML/DL**: Integrating these technologies can enhance the iterative evolution of virtual models and automate training data generation.\n- **Use of 3D point clouds**: Leveraging 3D point cloud data can enable dynamic updates of structural dimensions.\n- **Lack of industry consensus**: The absence of a common software platform for multi-domain DTs hinders systematic research.\n- **Conceptual application stage**: Many application areas remain largely theoretical, with a gap between concept and practical optimization/prediction in real-world systems.\n- **Criteria for judging suitability**: There is no clear standard for determining whether a given field is appropriate for digital twin adoption.",
        "keywords": ["Digital Twin","Physical entity","Virtual model","Twin data","Applications","Cyber-physical system","Smart manufacturing","Digital transformation","Virtual-real interaction","Modeling methods","Data acquisition","Data exchange protocols","Application areas","Future research directions","Machine Learning","Deep Learning"]
    },
    {
        "title": "Autonomous, context-aware, adaptive Digital Twins—State of the art and roadmap",
        "summary": "This paper explores the evolution of Digital Twins (DTs) towards becoming autonomous, context-aware, and adaptive entities, essential for future Digital Factories. It provides a working definition of DTs, examines the state-of-the-art in context-awareness, autonomy, and adaptivity in relation to DTs, and identifies research gaps and a roadmap for realizing these advanced DTs.\n\n(1) Definitions:\nThe paper defines Digital Twins as comprehensive digital representations of physical assets, comprising their design and configuration, state, and behavior [1]. These components are:\n*   System Design and Configuration: Static information and models, including product models, design models (CAx, STEP), bills of materials, and layout data [2]. DTs represent specific instances of products, evolving dynamically over their lifecycle [2, 3].\n*   System State: A (real-time) reflection of a physical counterpart's condition based on sensor data, IT systems, and execution systems [4]. This component may include data from testing or manufacturing systems, even before the physical asset is complete [4, 5].\n*   System Behavior: Integrated models describing the physical counterpart's behavior, including multi-physics simulations, numerical modeling, and data-driven analytics using machine learning and AI [3].\n\n(2) Characteristics and Requirements:\n*   Context-Awareness: The ability to customize behavior based on the environment, accessing and processing information about the context [6]. Context can be classified as primary (time, identity, location, activity) or secondary, and as external (places, people) or internal (goals, tasks) [6, 7]. Context models organize context information, enabling reasoning and consistency [8].\n*   Autonomy: The ability to act with independence and responsibility [9]. Autonomy helps handle disturbances and changing demands by shifting decision-making to smaller units [10]. Autonomous systems require linking the physical world to a virtual DT capable of decision-making, often modeled on biological systems [11].\n*   Adaptivity: The capability to modify a system's behavior in unforeseen situations to achieve goals [12]. Adaptivity involves monitoring the system's state and environment, using decision-making mechanisms to enact changes [13].\n\nFuture DTs should be context-aware, autonomous and adaptive, sensing and processing their environment, proactively communicating, making decisions, and adapting themselves and their physical counterparts [14, 15].\n\n(3) Relevant Use Cases:\n*   Smart Manufacturing: Energy management, failure management, manufacturing cycle time optimization, shop-floor management, and manufacturing system reconfiguration [16, 17].\n*   Human-Robot Collaboration (HRC): Considering a robot’s position in relation to humans [18].\n*   Predictive Maintenance: DTs autonomously make decisions about maintenance, affecting the physical asset's configuration [19].\n*   Supply Chain Management: Collaboration between businesses and suppliers using DTs [15]. Dynamic organization of supply chains to optimize production [20].\n\n(4) Technologies and Tools Used:\n*   Sensors and Embedded Systems: Provide environmental parameters [8].\n*   RFID, BLE, NFC, IoT, CPS: Used to generate and communicate context information [8].\n*   Manufacturing Execution Systems (MES) and Enterprise Resource Planning (ERP): Provide information about manufacturing processes [21].\n*   Machine Learning and Artificial Intelligence: Development of data-driven models for predicting system behavior [3].\n*   Cloud Manufacturing: Used in combination with IoT for dynamic logistics synchronization [20].\n*   Graph-Based Models: Represent components in smart manufacturing processes [22].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n*   Interoperability: A comprehensive approach is needed for inter- and intra-factory, supply chain, and lifecycle-wide interoperability [23]. Standards and protocols for DT information exchange are crucial but challenging due to heterogeneity [24].\n*   Modeling: Context models need to be integrated to use context in combination with other models on the level of system behavior [25]. Understanding how individual DTs may connect and collaborate is required [25].\n*   Human Interaction: Borders between DT and human autonomy must be investigated, considering workplace safety and psychological factors [26, 27].\n*   Data Processing: Real-time acquisition of context information and methods for time-constrained near-optimal decisions are necessary [28]. Handling and analyzing massive volumes of data in real-time to forecast events require new methods [28].\n*   Lack of Reference Models: A comprehensive framework is required to facilitate full-stack solutions and avoid fragmentation [29, 30]. The full integration of the DT concept with RAMI 4.0 and its convergence with CPS must progress [26, 31].",
        "keywords": ["Digital Twins", "Digital Factories", "Context-awareness", "Autonomy", "Adaptivity", "Manufacturing", "Cyber-Physical Systems", "Smart Manufacturing", "Industry 4.0", "Real-time", "Simulation", "Modeling"]
    },
    {
        "title": "Characterising the Digital Twin: A systematic literature review",
        "summary": "This paper provides a comprehensive characterization of the Digital Twin (DT) through a systematic literature review of 92 publications from the last ten years. It identifies key terminology, associated processes, and knowledge gaps to maintain a common understanding and ensure solid foundations for future research [1, 2].\n\n(1) Definitions:\nThe DT is typically described as consisting of a physical entity, a virtual counterpart, and the data connections between them [3]. It is explored as a means of improving the performance of physical entities through computational techniques enabled by the virtual counterpart [3]. The origin of the Digital Twin is attributed to Michael Grieves and his work with John Vickers of NASA [4]. Grieves described the Digital Twin as consisting of three components: a physical product, a virtual representation of that product, and the bi-directional data connections that feed data from the physical to the virtual representation, and information and processes from the virtual representation to the physical [5].\nGrieves further aligned the Digital Twin to the product life-cycle through the expansion of the concept via the introduction of the Digital Twin Prototype, Digital Twin Instance, Digital Twin Aggregate, and Digital Twin Environment [6].\n\n(2) Characteristics and Requirements:\nThe paper consolidates the characteristics of the Digital Twin to produce 13 key characteristics [2]:\n* Physical Entity/Twin: A 'real-world' artifact [7, 8].\n* Virtual Entity/Twin: A computer-generated representation of the physical artifact [7, 9].\n* Physical Environment: The measurable 'real-world' environment in which the physical entity exists [7, 10].\n* Virtual Environment: Any number of virtual 'worlds' or simulations that replicate the state of the physical environment and are designed for specific use-cases [7, 10, 11].\n* State: The current value of all parameters of either the physical or virtual entity/environment [12, 13].\n* Parameters: The types of data, information, and processes transferred between entities [12, 14].\n* Physical-to-Virtual Connection: The connection from the physical to the virtual environment [12, 15].\n* Virtual-to-Physical Connection: The connection from the virtual to the physical environment [12, 16].\n* Twinning and Twinning Rate: The act of synchronization between the two entities and the rate with which synchronization occurs [12, 17, 18].\n* Physical Processes: The physical purposes and processes within which the physical entity engages [12, 19].\n* Virtual Processes: The computational techniques employed within the virtual-world [20, 21].\n* Metrology: The act of measuring the state of the physical/virtual entity/twin and its environment [22, 23].\n* Realisation: The act of changing the state of the physical/virtual entity/twin [22, 23].\nThe twinning process involves change → metrology → realize, running in both directions from virtual-to-physical and physical-to-virtual [23].\n\n(3) Relevant Use Cases:\nThe majority of identified use-cases are manufacturing related [24]. Specific examples are related to Industry 4.0, smart factories/manufacturing, and learning [24]. Other use-cases include: product design, model-based engineering, 5G communication for factories, air-frame health monitoring, composite optimization, smart cars, farming, and human health and the agriculture supply chain [24, 25].\n\n(4) Technologies and Tools Used:\nResearch into technical solutions to the Digital Twin is largely focused on leveraging existing technologies [26]. These include: 5G, Internet-of-Things, Industrial Internet-of-Things, wireless, RFID, Ethernet, actuators and the cloud [26].\nSensors (including RFIDs) are being used for data capture, and actuators are being used to realize change in the physical environment [27].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\nThe paper identifies seven knowledge gaps and topics for future research focus [2]:\n* Perceived Benefits: There are very few examples of validation and quantification of perceived benefits against existing processes and systems [2, 28].\n* Digital Twin across the Product Life-Cycle: Research is largely focused on the Realise and Support/Use phases of the life-cycle, with relatively few papers focusing on the core concept of the Digital Twin or considering the digital twin across the entire life-cycle [2, 29].\n* Use-Cases: The vast majority of identified use-cases are manufacturing related [2, 24].\n* Technical Implementations: There is a need to ensure future standards are suitable for Digital Twin purposes and if this is not possible, to develop those standards [2, 27].\n* Levels of Fidelity: Literature is yet to present an exhaustive high-fidelity implementation, where parameters for every aspect of the physical twin are captured [2, 30].\n* Data Ownership: Determining how information is shared between organizations and individuals poses a major challenge [2, 31].\n* Integration between Virtual Entities: Standardisation and interoperability such that virtual entities can communicate is key to realising this aspect of the Digital twin [2, 32].",
        "keywords": ["Digital Twin", "Virtual Twin", "Physical Entity", "Virtual Entity", "Physical Environment", "Virtual Environment", "State", "Realisation", "Metrology", "Twinning", "Twinning Rate", "Product Life-Cycle", "Use-Cases", "Technical Implementations", "Levels of Fidelity", "Data Ownership", "Integration between Virtual Entities", "Manufacturing", "Simulation", "Modelling"]
    },
    {
        "title": "Digital twin: Data exploration, architecture, implementation and future",
        "summary": "This paper provides an overview of the data level within digital twin (DT) systems, encompassing data at various stages, and offers a comparative study across different fields where digital twins are applied [1]. It explores data organization, storage, linking, and integration, which are essential for building virtual models, establishing cyber-physical connections, and enabling intelligent operations [1].\n\n(1) **Definitions:** A Digital Twin (DT) is defined as a digital copy or virtual representation of a real-world object, process, service, or system [1]. It facilitates a bidirectional data flow between physical and virtual entities, enabling continuous upgrading of the physical counterpart [1]. A DT is a virtual representation of a physical system that replicates, simulates, predicts, and provides prognostic data analysis throughout the entire life cycle of the physical entity [2].\n\n(2) **Characteristics and Requirements:** A basic DT system consists of a physical object and a virtual model connected through bidirectional data flow [3]. DT technology depends on collecting and processing a lot of data [3]. The data includes the present condition, actions, and efficacy of the tangible entity and can be numerical, categorical, or time series [4]. Models within a digital twin system serve as virtual representations of physical elements using mathematical abstractions or simulations [4]. Key requirements include data collection, data storage, data association, data fusion, data sorting, and data coordination [5-9].\n\n(3) **Relevant Use Cases:** The paper outlines DT applications in manufacturing, urban planning, agriculture, medicine, robotics, and the military/aviation industry [1]. In manufacturing, DTs are used to improve supply chain and product performance [10]. In urban planning, they address complex city problems through cloud/edge computing and extensive data analysis [11]. In agriculture, DTs help manage resources and meet food demand [11]. In medicine, they aid in diagnosis and treatment [11]. In robotics and aerospace, simulations imitate system behavior for prediction and maintenance [12].\n\n(4) **Technologies and Tools Used and How They Were Used:** DT systems integrate various technologies such as Cyber-Physical Systems (CPS), Internet of Things (IoT), Machine Learning (ML), and Artificial Intelligence (AI) [3]. Modeling tools include SysML, Modelica, SolidWorks, 3DMAX, and AutoCAD [12]. Data is collected using sensors, IoT devices, and mobile devices, processed using cloud and fog computing, and analyzed with big data analytics [13]. Data fusion employs Bayesian methods and neural networks to enhance accuracy [8]. Data coordination uses Euclidean distance to ensure consistency between physical and virtual entities [9]. Cloud services from tech giants like Amazon AWS, Microsoft Azure, Google Cloud, Oracle Cloud, and Alibaba Cloud are used for data analysis, storage, and other functions [14].\n\n(5) **Special Findings Related to Digital Twin Requirements or Challenges:** The paper identifies several challenges, including data processing difficulties and the need for sector-specific data analysis approaches [15, 16]. Data integration from various sources and ensuring data quality are critical challenges [15]. Security concerns and the need for robust data ethics and governance policies are also highlighted [17]. The paper emphasizes the importance of interoperability standards to enable inter-operation among various businesses and fields [18]. It also addresses the challenge of ensuring data accuracy and reducing fuzziness [19].",
        "keywords": ["digital twin", "data analysis", "manufacturing", "urbanization", "medical", "agriculture", "robotics", "military", "aviation", "data collection", "data storage", "data fusion", "cyber-physical systems", "machine learning", "artificial intelligence"]
    },
    {
        "title": "Digital Twin: Enabling Technologies, Challenges and Open Research",
        "summary": "This paper provides a comprehensive review of Digital Twin technology, its enabling technologies, challenges, and open research areas across healthcare, manufacturing, and smart city environments [1, 2]. The paper investigates the definitions, applications, challenges, and enabling technologies associated with Digital Twins, IoT/IIoT, and data analytics [3]. It explores the link between IoT, IIoT, data analytics, and Digital Twin technology, and identifies open research areas and challenges [3].\n\n(1) Definitions: The term Digital Twin was first given by Grieves in 2003 [4]. NASA defined a Digital Twin in 2012 as an integrated multiphysics, multiscale, probabilistic simulation of a vehicle or system that uses the best available physical models, sensor updates, and fleet history to mirror the life of its corresponding flying twin [4, 5]. Other definitions emphasize the computerized model of a physical device or system representing all functional features and links with working elements, a living model that adapts to operational changes based on collected online data, and a set of virtual information fully describing a physical production [5, 6]. A Digital Twin is also described as a digital representation of a physical item or assembly using integrated simulations and service data, continuously updated and visualized to predict current and future conditions [6]. A Digital Twin is a virtual instance of a physical system continually updated with performance, maintenance, and health status data throughout its life cycle [7]. The paper distinguishes Digital Twins from digital models and digital shadows, noting that a Digital Twin involves a fully integrated, bi-directional data flow between the physical and digital objects [8, 9].\n\n(2) Characteristics and Requirements: A Digital Twin requires a seamless integration of data between a physical and virtual machine in either direction [1]. It necessitates high-quality, noise-free data with a constant, uninterrupted data stream [10]. The technology also requires robust IT infrastructure, including up-to-date hardware and software to execute complex algorithms [11, 12]. Standardized modeling approaches are needed for the design and simulation of Digital Twins [13].\n\n(3) Relevant Use Cases:\n*   Smart Cities: Digital Twins can be used for planning and development, energy saving, testing scenarios, data analytics, and monitoring within smart cities [14, 15].\n*   Manufacturing: Digital Twins can track and monitor products, provide real-time status on machine performance, predict issues, and improve reliability and performance in manufacturing settings [16, 17]. They can also be used in the automotive and construction industries for simulation and data analytics [18].\n*   Healthcare: Digital Twins can provide real-time analysis of the human body, simulate the effects of drugs, and assist in planning and performing surgical procedures [19]. They can also be used for bed management, ward management, and hospital management [20].\n\n(4) Technologies and Tools Used:\n*   IoT/IIoT: IoT devices and sensors are used to collect data from physical objects and environments, enabling real-time monitoring and analysis [2, 14]. Industrial IoT (IIoT) enhances industrial processes by allowing tasks to be evaluated with greater knowledge and real-time responses through connected devices [21, 22].\n*   Data Analytics: Machine learning and deep learning algorithms are used for predictive maintenance, fault detection, anomaly detection, and performance analysis [2, 17]. Data visualization tools are used to present data and results in a graphical format [23].\n*   Platforms: Various platforms are used for developing Digital Twins, including Predix (GE), MindSphere (Siemens), ThingWorx (PTC), and Watson IoT Platform (IBM) [24, 25]. Open-source projects like Eclipse Ditto and imodel.js (Bentley Systems) also facilitate the creation and management of Digital Twins [26].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n*   Challenges: The challenges associated with Digital Twins include IT infrastructure limitations, data quality and security concerns, privacy issues, lack of trust, and high expectations [10-12, 27-33]. Standardized modeling approaches are lacking, and domain knowledge transfer is crucial for successful Digital Twin implementation [13, 34].\n*   Open Research: Open research areas include developing generic models for complete Digital Twins, incorporating data fusion, and using Digital Twins for prognostics and health management (PHM) in industrial settings [35-37]. In healthcare, open research focuses on modeling the human body, data fusion, remote surgery, and ensuring data privacy [38-40]. For smart cities, standardized Digital Twins and the application of predictive analytics are key areas for future research [41, 42].",
        "keywords": ["Digital Twins", "enabling technologies", "Industrial IoT", "IIoT", "Internet of Things", "IoT", "machine learning", "deep learning", "smart cities", "manufacturing", "healthcare", "data analytics", "applications", "challenges", "open research"]
    },
    {
        "title": "Digital Twin maturity model",
        "summary": "This paper presents a survey and development of a Digital Twin maturity model, aiming to provide an assessment tool for understanding the levels of Digital Twin implementations and their functionalities [1]. It addresses the miscommunications arising from different technical viewpoints in Digital Twin discussions and proposes a structural hierarchy to facilitate focused discussions [2, 3]. The paper emphasizes that maturity models serve as common frameworks for stakeholders, fostering unified understanding and effective communication [1]. It distinguishes between evolution and maturity models, clarifying that lower maturity levels are not necessarily inferior but serve different purposes [4, 5]. The paper reviews existing Digital Twin maturity models, including those from Atkins/IET, Gartner, Rainer, IDC, IoT Analytics, Di-Phy Innovations, DAPA, Unity and ETRI, and categorizes them based on their primary focus: general usage, domain-specific usage, organizational and business development perspective, and capability and feature perspective [6-15]. It introduces ETRI’s proposed Digital Twin maturity model with five levels: Mirroring, Monitoring and control, Modeling and simulation, Federated, and Autonomous [16, 17]. The model considers human engagement types (Human-off-the-Loop, Human-on-the-Loop, Human-in-the-Loop), personality, data integration levels, and autonomous levels [10, 12, 16, 18]. The paper also discusses the design principles and market situations considered when modeling specific maturity levels [19]. It introduces a 3D-type maturity model based on hierarchical aggregation levels, functionality and usage levels, and time-phased process flow [20, 21]. Finally, it addresses the importance of data interfaces (synchronization, federation, threading, and augmentation interfaces) for Digital Twin systems and the consideration of real-time characteristics [22-24].",
        "keywords": ["digital twin", "maturity model", "assessment tool", "implementation levels", "functionalities", "communication framework", "evolution model", "ETRI model", "human engagement", "data integration", "autonomous levels", "design principles", "market situations", "3D-type maturity model", "data interfaces", "synchronization", "federation", "threading", "augmentation", "real-time characteristics"]
    },
    {
        "title": "Digital Twin Platforms: Requirements, Capabilities, and Future Prospects",
        "summary": "This article provides an analysis of digital twin (DT) platforms, focusing on their requirements, capabilities, and future prospects [1, 2]. It investigates the benefits of Amazon Web Services (AWS), Eclipse (EC), and Microsoft Azure (AZ) DT platforms, assessing the extent to which they meet standard requirements [3].\n\n(1) **Definitions:** A digital twin is defined as a virtual representation of a system that facilitates bidirectional communication between the physical system and its digital counterpart [1]. This communication involves defining the data produced by the system, augmenting it with information about system entities, and realizing value-adding services on top of this data-driven definition [1].\n\n(2) **Characteristics and Requirements:** The paper elicits requirements for DT platforms based on the ISO23247 standard and the authors' expertise [4, 5]. These requirements include:\n\n*   **Bidirectional Synchronization (Bx):** Enables DTs and their physical counterparts to remain in sync, allowing DTs to receive data from the system and vice versa [5].\n*   **Convergence:** Realized between physical and digital spaces, identifying potential differences for adjustment and optimization [6].\n*   **Verification and Validation (V&V):** The platform should provide V&V, potentially based on historical data, before DTs are deployed, especially when DTs control critical parts of physical processes [6].\n*   **Real-Time Behavior:** Considers hard constraints between a system and DT on the edge and soft real-time communication with a DT through the cloud [7].\n*   **Automation Protocols:** General-purpose procedures of automated systems that are directly integrated into the software stack of control apparatus [7].\n*   **Platform Interoperability:** Involves the extension of an existing DT by using value-adding services like machine learning, simulation, and visualization [8].\n*   **System Interoperability:** Enables communication and interaction between DTs of different physical devices [8].\n*   **Domain Expert Involvement:** A platform should enable specialists to develop/operate a DT without requiring extensive technical knowledge [9].\n*   **Connection and Data Security:** Demands protected links and information exchanges to prevent unsafe interactions and unauthorized access [10].\n*   **Modifiability:** The recurring possibility of changing DTs, especially when a physical device is altered [11].\n*   **Reusability:** The reusability of a DT and its components is crucial for software engineers, particularly in companies with constantly changing product lines [11].\n*   **Continuous Integration and Continuous Deployment (CI/CD):** Includes the ongoing incorporation of changes into a DT, with changes deployed after positive validation by quality assurance [12].\n*   **Provisioning:** Oriented toward the deployment areas of cloud and edge computing, allowing a platform to operate as a cloud-native or on-premise variant [12].\n\n(3) **Relevant Use Cases:** The paper employs a DT of a “smart room” as a running example [3]. In this use case, indoor air quality properties, such as carbon dioxide levels and temperature, are measured by sensors and sent to the system’s DT [3]. The DT can then activate an alarm if any action is necessary to improve the air quality [4]. DTs of various rooms can exchange data, recommending that people move to areas with better air quality [9].\n\n(4) **Technologies and Tools Used:** The paper investigates DT solutions provided by:\n\n*   **Microsoft Azure (AZ):** Commercial cloud provider [13]\n*   **Amazon Web Services (AWS):** Commercial cloud provider [13]\n*   **Eclipse (EC):** Open-source alternative [13]\n\nThe paper mentions the use of Raspberry Pi for sending sensor data to the DT [4].\n\n(5) **Special Findings Related to Digital Twin Requirements or Challenges:**\n\n*   Two-thirds (8/13) of the requirements are fully satisfied by at least one DT platform [8, 14].\n*   All investigated platforms perform well regarding interoperability, security, and reusability [14].\n*   Convergence and automation protocols are mostly neglected by all the platforms [15]. Providing a generalized solution for convergence is challenging because current tools depend on the type of system the DTs are developed for [15].\n*   Future work includes employing standardized languages for cyber-physical systems to improve interoperability and reusability [16]. Also, dynamic composition of different DTs could be enabled by providing rich interface descriptions [16].",
        "keywords": ["digital twin", "digital twin platforms", "bidirectional synchronization", "convergence", "verification and validation", "real-time behavior", "automation protocols", "platform interoperability", "system interoperability", "domain expert involvement", "connection and data security", "modifiability", "reusability", "continuous integration", "continuous deployment", "cloud computing", "edge computing"]
    },
    {
        "title": "Digital Twin Requirements in the Context of Industry 4.0",
        "summary": "This paper explores the requirements for Digital Twins (DT) within the context of Industry 4.0. It addresses the gap in the established definition and requirements of DTs, aiming to synthesize these requirements based on a literature review and industry interviews [1, 2]. The research combines quantitative and qualitative strategies, using bibliometrics and content analysis of articles published between 2010 and 2018, indexed in the ISI Web of Science database, alongside interviews with industry representatives in Brazil [3-5].\n\n(1) Definitions:\nThe paper defines a Digital Twin as a realistic model of a process's current state and behavior in interaction with its real-world environment, used not only for representation but also for predicting product behavior and enabling real-time optimization [6]. It emphasizes the role of DTs in uniting large-scale production advantages with individualization, shortening time to market, and creating lifecycle benefits [6]. The study highlights the convergence of physical and virtual spaces, facilitated by DTs, which are fueled by virtual product models [6].\n\n(2) Characteristics and Requirements:\nThe most frequent requirements for Digital Twins are real-time data, integration, and fidelity [7]. Real-time data is crucial for optimizing products and processes [4, 7-9]. Integration is seen as essential for creating valuable data by connecting different subgraphs of nodes and edges [8, 10-12]. Fidelity is vital for mirroring physical entities and enabling various applications like virtual machine training and increasing machine self-awareness [2, 10, 13]. Additional characteristics include scalability, interoperability, expansibility, communication, convergence, automatic updating, autonomy, connectivity, data acquisition, data capture, data quality, data security, data warehousing, and efficiency [14].\n\n(3) Relevant Use Cases:\nDigital Twins are used to increase manufacturing flexibility, improve product design, map products throughout their lifecycle, and enhance manufacturing quality [15]. One company uses DT to simulate manufacturing lines before factory implementation, later feeding the system with real data [8]. Other companies use DT as part of their business model, offering solutions that incorporate DT [8]. The anticipation of the industry involves implementing integration platforms for collecting physical data and creating high-fidelity abstraction models for real-time manufacturing line control [8].\n\n(4) Technologies and Tools Used:\nThe research methodology combines bibliometrics and content analysis to study the research topic [4, 16]. The ISI Web of Science database was used to gather articles, and industry interviews were conducted to understand real-world implications and requirements [3, 5]. Technologies such as Artificial Intelligence and the Internet of Things are enablers for creating a dynamic environment within intelligent factories [17]. Cyber-Physical Production Systems (CPPS) enrich Digital Twin models through production and operation data, integrating digital models with real-time information from the physical product using sensing and information technologies [18].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\nThe main obstacles to DT implementation are robust data integration for high-fidelity representation and real-time control [11]. Industry understands DT as both an academic vision of digital and physical world coexistence and a practical simulation model for improving physical manufacturing lines [19]. Companies are shifting their focus toward actual real-time control implementation rather than just simulation [19]. Recent literature emphasizes system independence and implementation-related topics, suggesting a growing focus on practical application over design requirements [9, 13, 20].",
        "keywords": ["Digital Twin", "Industry 4.0", "Product Lifecycle Management", "Real-time Data", "Integration", "Fidelity", "Manufacturing", "Simulation", "Cyber-Physical Systems", "Data Acquisition", "Interoperability", "Scalability"]
    },
    {
        "title": "Digital Twin-driven smart manufacturing: Connotation, reference model, applications and research issues",
        "summary": "This paper reviews the development of Digital Twin (DT) technologies in manufacturing, analyzing the concept, applications, and research challenges within the context of Industry 4.0 [1]. It defines DT as a mirror of the real world, enabling simulation, prediction, and optimization of manufacturing systems [2]. The paper addresses the lack of understanding of DT concepts, frameworks, and development methods in current implementations [3]. A DT reference model is detailed, covering information models, communication mechanisms, and data processing modules required for DT development [4]. The review of applications focuses on alignment with the reference model. The paper identifies research issues for developing DTs for smart manufacturing [1, 3].\n\nKey aspects covered in the paper include:\n\n1.  **Definitions and Concept Clarification:**\n\n*   Digital Twin (DT) is defined as a virtual representation of manufacturing elements, continuously updated to reflect the status and conditions of its physical counterpart [5].\n*   The concept evolved from predicting aircraft structural behavior using digital models to a broader application in manufacturing [5, 6].\n*   DT is distinct from simulation, Cyber-Physical Systems (CPS), and Internet of Things (IoT), although related [7]. DT provides a high-fidelity representation of operational dynamics, enabled by near real-time synchronization between cyber and physical spaces, unlike simulation which focuses on 'what-if' scenarios [7]. DT can be used for monitoring, control, diagnostics, and prediction [7]. A CPS is characterized by a physical asset and its Digital Twin, while a DT is limited to the digital model [8]. IoT provides the infrastructure for connecting physical assets, but lacks the digital models present in DT [9].\n\n2.  **Characteristics and Requirements:**\n\n*   A DT requires an information model to abstract specifications of a physical object, a communication mechanism for bidirectional data transfer, and a data processing module to construct a live representation [4].\n*   The reference model emphasizes the need for these components to work together [4].\n*   Data synchronization must be near real-time to maintain the connection between the physical and information models [7, 10].\n*   Big Data processing is essential for handling the volume, variety, and velocity of data, considering hidden meanings, timeliness, and data quality [11, 12].\n\n3.  **Relevant Use Cases:**\n\n*   The primary application area is manufacturing assets, with fewer applications for factories, and limited applications for humans or production networks [13].\n*   Applications include monitoring, prediction, and decision-making support [13].\n*   Examples include real-time quality inspection of machining, fault diagnosis for rotor systems, and cyber-physical machine tools [14-16].\n*   The STEP Tools Inc. Digital Twin Machining application utilizes STEP, STEP-NC, MTConnect, and QIF standards for real-time quality inspection [14].\n*   A Digital Twin application for rotating machinery fault diagnosis uses a finite element model and vibration signals for fault quantification and localization [15].\n*   Cyber-Physical Machine Tools (CPMT) use MTConnect for data collection and improved interoperability [16].\n\n4.  **Technologies and Tools Used:**\n\n*   **Information Models:** Standards like ISO 10303 (STEP), ISO 14649, ISO 13399, MTConnect, and OPC UA are used to describe physical objects in the manufacturing domain [10, 17-19].\n*   **Communication Protocols:** Industrial communication protocols such as PROFIBUS, Modbus, and Ethernet-based systems are used for data communication [20-22]. Wireless technologies like WiFi, Bluetooth, and Zigbee are also being adopted [23].\n*   **Data Processing:** Big Data processing techniques including data acquisition and cleansing, statistical methods, and noise filters are used [24, 25]. Data storage options include relational and non-relational databases like key-value, document, graph, and column stores [26]. Time-sensitive data processing uses parallel computing technologies like MapReduce, Apache Spark, Apache Flink, and Apache Storm [27].\n\n5.  **Special Findings (Requirements and Challenges):**\n\n*   Inadequate understanding of the Digital Twin concept, focus on product operation and maintenance, and lack of reference models are major limitations [28].\n*   Research issues include architecture patterns (server-based vs. edge-based), communication latency requirements, data capture mechanisms, and the need for standards [29-31].\n*   The need for version management of Digital Twin models and the integration of humans in Digital Twin applications are highlighted as critical areas for future research [32, 33].\n*   The development of autonomous feedback control from the Digital Twin to the physical object is an area needing more development [34].",
        "keywords": ["Smart manufacturing", "Digital Twin", "Industry 4.0", "Cyber-physical System", "Big Data", "Reference model", "Information model", "Industrial communication", "Data processing", "Manufacturing assets", "Smart production network", "Mass personalization"]
    },
    {
        "title": "Digital twin-enabled synchronized construction management: A roadmap from construction 4.0 towards future prospect",
        "summary": "This paper presents a strategic roadmap for synchronized construction management, stemming from an analysis of Construction 4.0's fundamental elements, to advance current construction management practices [1]. It introduces an Orthogonally Synchronized Digital Twin (SDT) model with regular expression for a reshaped construction management [1]. The study aims to guide decision-making on digital twin adoption in construction, enhance efficiency, improve outcomes, and offer a roadmap for industry advancement towards human-centrality, sustainability, and resilience [1]. The core concept involves digital twin-enabled orthogonal synchronization, encompassing vertical-dimensional cyber-physical synchronization and horizontal-dimensional domain synchronization [2, 3]. Vertical synchronization focuses on real-time bidirectional interoperation between physical and digital spaces, while horizontal synchronization coordinates interactions among different construction resources, operations, humans, and energy [3].\n\nKey aspects of Construction 4.0, including digitization, automation, and intelligence, are examined, with Digital Twin/Cyber-Physical Systems identified as the core element [4, 5]. The research identifies gaps in Construction 4.0, such as the obscurity of refined key factors on associated domain problems and the absence of concrete descriptive models for achieving a closed-loop synchronized environment using digital twins [6, 7].\n\nThe proposed roadmap consists of six steps and an orthogonally synchronized digital twin model for the future of construction, emphasizing human centricity, sustainability, and resilience [8]. The SDT model incorporates horizontal synchronization (H-Sync) and vertical synchronization (V-Sync) to illustrate the core mechanism of construction management [9]. V-Sync involves real-time bidirectional synchronization between physical space and cyber space, while H-Sync involves coordinated interactions among diverse construction resources, operations, human elements, and energy [10].\n\nInformation and automation technologies, including IoT, computer vision, industrial wearables, big data, AI, and robotics, lay the groundwork for digital twin-based intelligent management in future construction [11]. The paper also discusses a digital twin-based systematic framework for smart construction management, consisting of five layers from infrastructure to service-oriented modules [12].\n\nThe paper concludes by emphasizing the need for real-world validation of the proposed roadmap and SDT model, further exploration of synergies between AI and digital twins, and investigation of advanced technologies for holistic smart cities management [13, 14].",
        "keywords": ["Digital twin", "Construction management", "Construction 4.0", "Synchronization", "Roadmap", "Cyber-physical integration", "Orthogonally Synchronized Digital Twin (SDT)", "Digitalization", "Automation", "Intelligence", "Human-centricity", "Sustainability", "Resilience", "Information and automation technologies", "Horizontal synchronization", "Vertical synchronization"]
    },
    {
        "title": "Digital Twin—A Review of the Evolution from Concept to Technology and Its Analytical Perspectives on Applications in Various Fields",
        "summary": "This review paper comprehensively examines the evolution, definitions, classifications, architectures, and applications of Digital Twin (DT) technology across various sectors, with a focus on medicine and manufacturing. It highlights the transformative potential of DTs, enhanced by the integration of AI and machine learning, in improving operational efficiency and enabling real-time simulation, monitoring, and analysis of real-world behavior. \n\n(1) Definitions: The paper traces the DT concept from its origins in Product Lifecycle Management and NASA's early efforts to its contemporary understanding as virtual replicas of physical entities [1-3]. It emphasizes the role of DTs in improving information processing and management within both physical and virtual environments [2]. Key definitions from prominent researchers like Grieves et al. (2016) [4], who conceptualized the Digital Twin as comprising physical products, virtual products, and the data connections between them, and Negri et al. (2017) [4], who defined it as a virtual representation of a production system synchronized with the real system through data and mathematical models, are presented. The paper consolidates these definitions to highlight the breadth and potential of the DT concept [5].\n\n(2) Characteristics and Requirements: The study identifies several key characteristics of Digital Twins, including a high degree of accuracy, dynamic communication, self-evolving capabilities, and unique identifiability [6, 7]. Accuracy is crucial for reliable simulations, while dynamic bidirectional communication ensures that changes in the physical or virtual environment are mirrored in its counterpart [6]. Self-evolving DTs adapt and optimize using real-time data, and each physical product must have a unique DT for precise tracking throughout its lifecycle [7].\n\n(3) Relevant Use Cases: The review delves into the application of DT technology in diverse sectors, particularly medicine and manufacturing [1]. In manufacturing, DTs facilitate process optimization, asset management, and human-robot interaction [8]. They are used in product design to pre-identify customer requirements and in production to validate processes and simulate scenarios [9, 10]. In medicine, DTs enable personalized healthcare through real-time patient monitoring, early pathology detection, and simulation of treatment options [11, 12]. Examples include using DTs for heart rhythm classification via ECG data and for predicting the effects of anticancer drugs [13, 14].\n\n(4) Technologies and Tools Used: The paper identifies several enabling technologies for DT implementation. These include IoT sensors for data acquisition, cloud computing for deployment and simulation, virtual and augmented reality for information modeling, and cybersecurity measures for data protection [15, 16]. Data analytics, AI, and machine learning algorithms are used for predictive maintenance, risk assessment, and process optimization [17, 18]. Specific tools and platforms mentioned include ThingWorx and Vuforia [19]. Discrete Event Dynamic Systems formalism is noted for modeling and simulation by setting thresholds that trigger events to change the model [20].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges: The review highlights several challenges and requirements for effective DT implementation [21, 22]. Interoperability and data management are critical, as many use cases rely on interactions between DTs from different companies [23]. Security capabilities are essential for data acquisition, exchange, control, and management [23]. The complexity of modeling processes and the need for collaboration among stakeholders pose significant hurdles [21]. Ethical considerations, such as data privacy and security, are particularly relevant in the medical field [24]. The paper also addresses the importance of organizational culture and the need for change management to ensure the successful adoption of DT technologies [22].",
        "keywords": ["Digital Twin","Digital Twin in medicine","product–service systems","medicine","evolution","ethical aspects","manufacturing","Cyber-Physical Systems (CPSs)","Product Lifecycle Management","Internet of Things (IoT)","Artificial Intelligence","Machine Learning","smart cities","energy production","oil industry","education"]
    },
    {
        "title": "Digital Twins: A Maturity Model for Their Classification and Evaluation",
        "summary": "This paper introduces a maturity model (MM) for evaluating Digital Twins (DTs) across their lifecycle, aiming to formalize and standardize their description [1, 2]. It addresses the increasing importance of DT development and usage, particularly in production and logistics, where it's often unclear how DTs can be effectively used [3]. The research involved a systematic literature review (SLR) following PRISMA guidelines to identify relevant functionalities and properties, which were then ranked and categorized to form the core of the maturity model [2, 4]. The model was validated using five use cases (UCs) from different domains in production and logistics [2].\n\n(1) Definitions:\nThe paper acknowledges the diverse definitions of DTs depending on the research domain, highlighting the lack of standardization that leads to misconceptions [5]. It references early definitions, such as Glaessgen's, and CIRP's definition that includes a service perspective and lifecycle-wide applicability [5-7]. The paper emphasizes that DTs are more than just virtual models; they integrate operational data, simulation models, and are suitable for their intended purpose, evolving throughout the product lifecycle [6, 8].\n\n(2) Characteristics and Requirements:\nThe maturity model assesses DTs in seven categories: context, data, computing capabilities, model, integration, control, and human-machine interface (HMI), with 31 ranked characteristics [2, 9]. Key dimensions include [8, 10]:\n\n*   Benefits: How the DT generates value, either by enhancing established services or enabling new ones [11, 12].\n*   Application Domain: The specific area in which the DT is applied, such as manufacturing, aerospace, automotive, or healthcare [12, 13].\n*   Tangible Product Lifecycle Phases: The stages of the product lifecycle that the DT affects, including beginning of life, mid of life, and end of life [14, 15].\n*   Connection Mode: The integration of the physical and virtual worlds, considering the direction and automation level of data exchange [15].\n*   Modularity (System Level): The hierarchical arrangement of system levels, such as unit, system, and system of systems, and the DT's ability to traverse these levels [16, 17].\n*   Model Authenticity: How closely the DT conforms to its physical twin, considering factors like entity models and the richness of mirrored features [18, 19].\n*   Levels of Autonomy: The DT's independence from external control, its ability to react to changes, and its proactive actions [20, 21].\n*   Digital Model Types: The types of models used within the DT, such as conceptual, physics-based, machine-learning-based, or hybrid models [22].\n*   Modelled Characteristics: The specific characteristics of the reference object that are modelled within the DT [23].\n*   Update Frequency and Computing Capability: The DT's ability to process information and update its state, reflecting how timely and accurate the virtual counterpart is [24].\n*   Data Sources: The variety and structure of data sources contributing to the DT, including sensor data, simulation data, and external data [25, 26].\n*   Types of Interaction Devices: The user interfaces that provide insights into the DT's status and functionality, including tailored hardware, VR/AR interfaces, and adaptive assistance systems [27, 28].\n*   User Focus & Interorganizational Integration & Collaboration: The stakeholders considered as DT users and the integration of the DT into cross-company networks [28].\n\n(3) Relevant Use Cases:\nThe paper validates the maturity model using five use cases (UCs) [2, 29]:\n\n*   UC1: A product avatar for leisure boats, focusing on interoperability and integrating design systems, CRM, ERP, and service/maintenance systems [30, 31].\n*   UC2: Configuration of a manufacturing process chain using DTs, employing cause-effect networks for real-time predictions [32, 33].\n*   UC3: A gamified DT of warehousing activities for educational purposes, teaching the use of IoT technologies [34, 35].\n*   UC4: A DT for production planning and control, using discrete-event simulation to represent a production system [36, 37].\n*   UC5: Human-machine interaction in container unloading using the DT, improving system accessibility and enabling operator interaction [38, 39].\n\n(4) Technologies and Tools Used:\n\n*   CAD models and computational fluid dynamics (CFD) simulations are used in the leisure boat DT for virtual prototyping [30, 40].\n*   Universal sensor gateway (USG) is used to collect data from maritime data standard networks (NMEA 2000) and sensors [30].\n*   Cause-effect networks, combined with machine learning, are used for real-time predictions in manufacturing processes [33, 41].\n*   Unity is used to model 3D data from sensed data in the warehousing activities DT [42].\n*   Discrete-event simulation, utilizing the jasima library (Java Simulator for Manufacturing and Logistics), is employed in the production planning and control DT [43].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n\n*   The paper identifies that the relevance of each dimension in the maturity model depends on the specific application [44, 45].\n*   It discusses the challenge of balancing the weighting of different categories and dimensions to align with user needs [46].\n*   The analysis of existing DTs indicates that their nature and application area vary, requiring a flexible and re-usable approach to DT development [47].\n*   A primary challenge in developing DTs is related to changing system requirements and the precise specification of future needs [48].\n*   The framework can be used as both an analysis and design tool, supporting the re-usage of DT components and knowledge transfer from one domain to another [49].",
        "keywords": ["digital twin", "maturity model", "characteristics", "dimensions", "literature review", "use cases", "product development", "systematization", "digital twin application", "production", "logistics", "industry 4.0", "cyber-physical systems", "simulation", "modeling"]
    },
    {
        "title": "Digital twins: An analysis framework and open issues",
        "summary": "This paper addresses the lack of a consolidated and consistent view of what constitutes a digital twin by proposing an analysis framework. This framework enables the characterization and comparison of digital twins based on their functional characteristics, aiming to reduce the confusion caused by the proliferation of digital twin definitions. The analysis focuses on functionality rather than non-functional requirements, allowing comparison of different physical and logical instantiations of digital twins.\n\n(1) Definitions:\nThe paper highlights the absence of a universal definition of a digital twin, noting that the multitude of definitions presents a challenge for those seeking to characterize or compare digital twins [1, 2]. It cites examples of the increasing number of definitions, from 17 in 2017 to at least 46 in 2019 [2]. The paper adopts a generic definition: “A live digital coupling of the state of a physical asset or process to a virtual representation with a functional output” [3]. This definition is chosen for its sector and application independence, avoiding assumptions about the digital twin's purpose, the nature of the physical entity, or the sector in which it is used [3]. The definition's nuanced wording covers key concepts without requiring a virtual-to-physical connection, making it more universal [3].\n\n(2) Characteristics and Requirements:\nThe paper proposes an analysis framework based on four functional categories: digital coupling, tools, digital representation, and functional output [4]. These categories contain sixteen complex functional components [4].\n\n*   **Digital Coupling:** This category includes components that effect the transfer of operational state data from the physical entity to the digital representation [5]. It consists of five functional components: physical entity state, communication, state data handling, twinning, and protocols & standards [6-10].\n*   **Digital Representation:** This category stores data and represents a physical entity using logical, relationship, and functional models [11]. It includes data model, operational data storage, master & reference data, physical entity model(s), and temporal functionality [12-14].\n*   **Tools:** This category supports decision-making about a physical entity and includes analysis, simulation, and presentation tools [15]. The analysis tools are used to analyze the behavior, performance, and operation of the physical entity [16]. Simulation tools simulate the behavior, performance, and operation of the physical entity [17]. Presentation tools provide the processing necessary for visualization of analysis and simulation results [18].\n*   **Functional Output:** This category provides information transmitted to a system or human observer that is actionable to deliver value [19]. It comprises digital twin output, digital twin configuration & control, and user interface [20-22].\n\nThe paper emphasizes that the characteristics of the digital coupling are influenced by the nature, volume, and timeliness of the state data being transferred [5]. Adaptability is a key requirement, enabling users to record changes to the physical entity, environmental aspects, spatial aspects, and modifications to operational use [23, 24].\n\n(3) Relevant Use Cases:\nThe paper illustrates the use of the framework with the characterization of a digital coupling between a semi-autonomous vehicle and its digital twin [25, 26]. It provides a table summarizing the functionality for the connection between this specific physical entity and its digital twin, including the status of sensors, actuators, control system data, communication mode, state data handling, twinning initiation, and protocols & standards [26-28].\n\n(4) Technologies and Tools Used:\nThe paper does not focus specifically on the technologies and tools used but identifies several functional components and characteristics related to data processing, analysis, simulation, and visualization [15, 29, 30]. It mentions the use of computational and logical models, parametric digital models, and graph-based models in digital representation [15, 31]. Communication technologies and application layer protocols are referenced in the context of the digital coupling [10].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\nThe paper identifies several misconceptions regarding digital twins, including unlimited use cases, federation of digital twins, the necessity of 3D models, and the idea of direct control of a physical entity by its digital twin [32-35]. It highlights the limited research on digital twin architectures and design, as well as safety and security [36, 37]. The role of information management in digital twins is also identified as an area that is barely addressed in the literature [35]. The paper emphasizes the need for clarifying the nature and structure of a digital twin lifecycle, with a focus on understanding how digital twin requirements are elicited and managed over the life of a digital twin [38].",
        "keywords": ["digital twin", "analysis framework", "cyber-physical systems", "smart systems", "industrial automation & control systems (IACS)", "functional components", "digital coupling", "digital representation", "functional output", "architecture models", "design methodology", "lifecycle", "safety", "security", "information management"]
    },
    {
        "title": "Digital twins: State-of-the-art and future directions for modelling and simulation in engineering dynamics applications",
        "summary": "This paper reviews the current state of digital twins in engineering dynamics, focusing on modeling and simulation, and identifies open research problems and technological challenges [1-3]. It emphasizes the transformative potential of digital twins in enhancing predictive capabilities by integrating computational models with data, addressing both technical and organizational challenges in engineering [4, 5].\n\n(1) Definitions:\nThe paper defines a digital twin as a virtual duplicate of a system, constructed from a fusion of models and data [6]. This is enabled through the use of advanced algorithms, expert knowledge, and digital connectivity [6]. The key benefit of a digital twin lies in its capacity to significantly improve predictive accuracy compared to existing technologies [6, 7]. The physical counterpart of the digital twin is referred to as the physical twin [8, 9].\n\n(2) Characteristics and Requirements:\nThe primary function of a digital twin is to provide comprehensive information regarding the current state and future behavior of its physical counterpart, facilitating optimized decision-making [10]. Key characteristics and requirements include:\n\n*   **Predictive Capability:** The ability to forecast future outcomes is crucial [4, 6]. A simulation digital twin should offer quantitative assessments of trust through uncertainty quantification for each simulation [11].\n*   **Data Augmentation:** Digital twins enhance computational models with real-time data, addressing limitations in physics-based modeling [4, 8, 12]. Data from the physical twin or laboratory tests are vital, making the digital twin bespoke to its corresponding structure [8, 9, 13].\n*   **Hierarchical Format:** A hierarchical structure enables the incorporation of multi-scale and multi-physics processes [8, 14].\n*   **Connectivity:** The digital twin fosters a highly connected organizational framework, breaking down organizational silos and improving connectivity by providing a logical interface between different computational models [8, 15-17].\n*   **Time Evolution:** Digital twins are time-evolving, requiring frequent updates to maintain accuracy and relevance [18-20].\n*   **Verification & Validation (V&V):** Robust V&V methods are essential for building trust in the subsystems before assembling them into a full system digital twin [15, 21].\n\n(3) Relevant Use Cases:\nThe paper includes the following use cases:\n\n*   **Structural Life Prediction:** Digital twins can predict the life of an aircraft by including the effects of manufacturing anomalies and material microstructure details [7, 22-24].\n*   **Asset Management:** For wind turbines, digital twins facilitate tasks like damage detection and structural health/condition monitoring [25-27].\n*   **Design and Manufacturing:** Digital twins can manage the performance of an engineering application after its design and manufacture [28-30]. Ideally, a digital twin is implemented during the design phase and persists throughout the operational life of the product [31, 32].\n\n(4) Technologies and Tools Used:\n\n*   **Physics-based Modeling:** Essential for constructing mathematical representations of the system of interest [17]. Techniques include finite element analysis (FEA), computational fluid dynamics (CFD), and multi-body physics models [21].\n*   **Data-based Approaches:** These are combined with model-based approaches to create a virtual prediction tool that evolves over time [5, 33, 34].\n*   **Machine Learning:** Used for condition monitoring and bespoke targeting of consumer behavior [35-39].\n*   **Sensor Technology:** Advances in sensor technology enable the gathering and processing of large amounts of data [35, 40].\n*   **Computer-Aided Design (CAD):** Integrated CAD allows for incorporating and updating the geometry of the digital twin [10, 41, 42].\n*   **Workflow Management:** Delivers and coordinates all the required processes that the digital twin is expected to perform [16].\n*   **Verification and Validation (V&V):** Techniques for V&V in engineering dynamics, such as modal analysis and testing, are well-established [43-46].\n*   **Uncertainty Quantification (UQ):** Provides a measure of the sources of uncertainty to reflect the overall level of uncertainty in model predictions and data [11, 47].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n\n*   **Multi-Scale Modeling:** The difficulty of modeling physical phenomena with radically different behaviors at different length scales [48-50].\n*   **Hardware/Software Gap:** The gap between hardware capability and software performance limits the ability to harness the full benefit of increasing computing power [51-53].\n*   **Organizational Silos:** The tendency for teams to work in silos, preventing the unification of subsystem models into a complete application model [54-56].\n*   **Uncertainty Management:** Challenges in quantifying and propagating uncertainties through a digital twin to assess the confidence level in predictions [8].\n*   **Joint Modeling:** Difficulties in accurately modeling mechanical joints due to the different physical processes and uncertainties at different length scales [57-59].",
        "keywords": ["digital twin", "engineering dynamics", "modeling", "simulation", "predictive capability", "data augmentation", "uncertainty quantification", "verification and validation", "asset management", "structural life prediction", "multi-scale modeling", "machine learning", "sensor technology", "workflow", "mechanical joints"]
    },
    {
        "title": "Methodology for the Development of Virtual Representations within the Process Development Framework of Energy Plants: From Digital Model to Digital Predictive Twin—A Review",
        "summary": "This review paper introduces a novel virtual representation framework designed for the process development environment within the energy sector. It addresses the absence of a structured approach for evolving virtual representations throughout the process development lifecycle. The methodology aims to synchronize virtual representation and physical facility development using a novel 'model readiness level.' The paper covers key aspects, including definitions of virtual representations, challenges, properties, applications, and sustainability indicators, to standardize process evaluation. A digital twin of a Bio-SNG production route is presented as a use case, demonstrating the framework's benefits in accelerating and monitoring energy technology developments through early implementation of virtual representations [1].\n\n(1) Definitions: The paper defines 'virtual representation' as the overall expression of virtual objects mirroring a physical process using advanced digital methods [2]. It acknowledges the synonymous use of terms like 'digital twin,' 'digital shadow,' and 'digital model' in the literature [2]. The level of integration, as defined by Kritzinger et al., is used to classify virtual representations based on data exchange capabilities, differentiating between digital models, digital shadows, digital twins, and digital predictive twins [3, 4]. The paper introduces a novel definition of virtual representations in process development of energy technologies as digital reflections of physical facilities, where the virtual component contains an abstracted model fitted as closely as necessary to the physical component through the integration of measured values and domain knowledge [5].\n\n(2) Characteristics and Requirements: The essential characteristics include scalability, interoperability, expansibility, and functional safety [6]. The paper emphasizes the importance of defining virtual representation properties based on the Gemini principles, which provide high-level guidelines for purpose, trust, and function [7, 8]. Challenges include time-, safety-, and mission-critical aspects, requiring decoupling of the control system from the virtual representation, robust cybersecurity measures, and careful synchronization of data resolution, quality, and latency [9]. A unified framework should determine the required granularity, accuracy, and complexity in every process development phase [10].\n\n(3) Relevant Use Cases: The paper discusses various applications of virtual representations across the plant lifecycle phases, including conceptual design and engineering, construction and commissioning, operation, maintenance, optimization, and decommissioning [11]. These applications are categorized into nine groups: collaboration, documentation, simulation and monitoring, evaluation and verification, visualization, planning and decision-making, emulation, orchestration, and prediction [12]. A specific use case of a Bio-SNG production route is presented, highlighting the implementation of a digital twin for operation optimization of a 100 kW Bio-SNG pilot plant [1, 13].\n\n(4) Technologies and Tools Used: The Bio-SNG pilot plant utilizes the APROL control system for monitoring and control [13]. Real-time sensor data is processed in the cloud, with process simulation models in IPSEpro 8.0 and model predictive control units in MATLAB R2021b [13]. These tools enable the determination of the process's present state and prediction of plant behavior as a function of manipulated variables [13]. A web application is used for real-time data visualization [13].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges: The paper emphasizes the necessity of the Modeling Readiness Level (MRL) to be one step ahead of the Technology Readiness Level (TRL) to enable forward planning and anticipate future behavior [14, 15]. It highlights the importance of preserving knowledge gained from test runs within the virtual representation to avoid recurring technology issues [15]. The 5D virtual representation framework, consisting of physical and virtual components, data management, service, and connection dimensions, is proposed to guide the development of virtual representations throughout the process development lifecycle [8].",
        "keywords": ["virtual representation", "digital twin", "process simulation", "sustainability", "process development", "energy plants", "digital model", "digital shadow", "digital predictive twin", "modeling framework", "energy sector", "model readiness level"]
    },
    {
        "title": "Properties and Characteristics of Digital Twins: Review of Industrial Definitions",
        "summary": "This paper reviews and analyzes the properties and characteristics of Digital Twins (DTs) as defined in both academic literature and industrial practice. The study aims to bridge the gap between theoretical research and practical application by examining how companies define and utilize DTs. The research involves a systematic review of 90 definitions from companies, using a taxonomy developed by the authors to code and analyze these definitions through both supervised and unsupervised methods. \n\n(1) Definitions: The paper identifies a lack of a unified definition of DTs in both academic and industrial contexts [1]. Academic definitions tend to focus on technological requirements, whereas company definitions emphasize value-based properties [2]. The authors propose an application-oriented definition to reconcile these perspectives, stating that a DT is a 'sufficiently authentic digital representation of a distinct real-world entity that exists as a prototype from which instances to accompany those real-world entities are derived. It has interfaces to communicate with users bidirectionally and receives raw and preprocessed data to provide data, information, and services to create value within a specific use case' [3]. This definition underscores the importance of authenticity, real-world relevance, bidirectional communication, and value creation within specific applications [4].\n\n(2) Characteristics and Requirements: The authors develop a taxonomy comprising ten properties, each with multiple characteristics, to systematically represent DT-defining elements [5]. These properties include: \n    - Counterpart: Whether the DT represents only physical objects, non-physical objects (processes and services), or any distinct entity [6, 7].\n    - Data Sources: The types of data used by the DT, such as sensors, internal systems, and external systems [8, 9].\n    - Data Link: Whether the data link between the physical and virtual object is uni-directional or bi-directional [10, 11].\n    - Interface: The gateways used to access data, distinguishing between human-to-machine (H2M) and machine-to-machine (M2M) interfaces [12, 13].\n    - Fidelity: The degree to which the DT authentically represents the real world, categorized as one-to-one fidelity or sufficient fidelity for the use case [14, 15].\n    - Synchronization: The frequency of data synchronization between the DT and its real-world counterpart, including real-time, near-real-time, and periodic [16].\n    - Capabilities: The functions the DT can perform, such as simulation, optimization, prediction, detection, prevention, and automation [17, 18].\n    - Purpose: The fundamental purposes served by the DT, categorized as performance, availability, or quality [19, 20].\n    - Life Cycle: The stage of the product life cycle in which the DT is applied, including beginning of life (BoL), middle of life (MoL), and end of life (EoL) [21, 22].\n    - Creation: The timing and method of DT creation, distinguishing between DT types and instances and whether creation is independent of the real-world counterpart [23].\n\n(3) Relevant Use Cases: The paper does not focus on specific use cases but rather on the properties and characteristics that enable various applications across different industries. The analysis suggests that companies prioritize use cases that enhance performance, quality, and availability, aligning with the overall equipment effectiveness (OEE) concept [20]. The study also notes a strong focus on BoL and MoL phases, with less emphasis on EoL, though this is expected to change with increasing focus on sustainability [21, 22, 24].\n\n(4) Technologies and Tools Used: The paper does not detail specific technologies and tools but mentions the use of web crawlers for data collection [25], word2vec neural network algorithm for unsupervised text analysis [26], and scikit-learn for multidimensional scaling (MDS) [26, 27]. These tools were used to analyze the definitions of DTs, compare the properties and characteristics, and identify potential clusters among different company definitions [28].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n    - The study finds that only a small percentage of companies (7.5%) publicly define DTs on their websites, suggesting that DT is not merely a marketing buzzword but a strategic tool with specific applications [29, 30].\n    - There is a significant difference between academic and industrial definitions, with companies focusing more on value-based properties (capabilities and purpose) and less on technical aspects (data links and interfaces) [2, 31, 32].\n    - The research identifies a lack of consensus on DT definitions within industries, indicating that companies tailor DT concepts to their specific needs and use cases [33, 34].\n    - The authors emphasize the need for companies to develop use case-specific definitions and provide a taxonomy and application-oriented definition to facilitate this process [4, 35].",
        "keywords": ["digital twin", "definition", "taxonomy", "industry", "systematic review", "properties", "characteristics", "industrial applications", "value creation", "data sources", "bidirectional connection", "real-world entity"]
    },
    {
        "title": "Properties and Characteristics of Digital Twins: Review of Industrial Definitions",
        "summary": "This paper reviews and analyzes the properties and characteristics of Digital Twins (DTs) as defined in both academic literature and industrial practice. The study aims to bridge the gap between theoretical research and practical application by examining how companies define and utilize DTs. The research involves a systematic review of 90 definitions from companies, using a taxonomy developed by the authors to code and analyze these definitions through both supervised and unsupervised methods. \n\n(1) Definitions: The paper identifies a lack of a unified definition of DTs in both academic and industrial contexts [1]. Academic definitions tend to focus on technological requirements, whereas company definitions emphasize value-based properties [2]. The authors propose an application-oriented definition to reconcile these perspectives, stating that a DT is a 'sufficiently authentic digital representation of a distinct real-world entity that exists as a prototype from which instances to accompany those real-world entities are derived. It has interfaces to communicate with users bidirectionally and receives raw and preprocessed data to provide data, information, and services to create value within a specific use case' [3]. This definition underscores the importance of authenticity, real-world relevance, bidirectional communication, and value creation within specific applications [4].\n\n(2) Characteristics and Requirements: The authors develop a taxonomy comprising ten properties, each with multiple characteristics, to systematically represent DT-defining elements [5]. These properties include: \n    - Counterpart: Whether the DT represents only physical objects, non-physical objects (processes and services), or any distinct entity [6, 7].\n    - Data Sources: The types of data used by the DT, such as sensors, internal systems, and external systems [8, 9].\n    - Data Link: Whether the data link between the physical and virtual object is uni-directional or bi-directional [10, 11].\n    - Interface: The gateways used to access data, distinguishing between human-to-machine (H2M) and machine-to-machine (M2M) interfaces [12, 13].\n    - Fidelity: The degree to which the DT authentically represents the real world, categorized as one-to-one fidelity or sufficient fidelity for the use case [14, 15].\n    - Synchronization: The frequency of data synchronization between the DT and its real-world counterpart, including real-time, near-real-time, and periodic [16].\n    - Capabilities: The functions the DT can perform, such as simulation, optimization, prediction, detection, prevention, and automation [17, 18].\n    - Purpose: The fundamental purposes served by the DT, categorized as performance, availability, or quality [19, 20].\n    - Life Cycle: The stage of the product life cycle in which the DT is applied, including beginning of life (BoL), middle of life (MoL), and end of life (EoL) [21, 22].\n    - Creation: The timing and method of DT creation, distinguishing between DT types and instances and whether creation is independent of the real-world counterpart [23].\n\n(3) Relevant Use Cases: The paper does not focus on specific use cases but rather on the properties and characteristics that enable various applications across different industries. The analysis suggests that companies prioritize use cases that enhance performance, quality, and availability, aligning with the overall equipment effectiveness (OEE) concept [20]. The study also notes a strong focus on BoL and MoL phases, with less emphasis on EoL, though this is expected to change with increasing focus on sustainability [21, 22, 24].\n\n(4) Technologies and Tools Used: The paper does not detail specific technologies and tools but mentions the use of web crawlers for data collection [25], word2vec neural network algorithm for unsupervised text analysis [26], and scikit-learn for multidimensional scaling (MDS) [26, 27]. These tools were used to analyze the definitions of DTs, compare the properties and characteristics, and identify potential clusters among different company definitions [28].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n    - The study finds that only a small percentage of companies (7.5%) publicly define DTs on their websites, suggesting that DT is not merely a marketing buzzword but a strategic tool with specific applications [29, 30].\n    - There is a significant difference between academic and industrial definitions, with companies focusing more on value-based properties (capabilities and purpose) and less on technical aspects (data links and interfaces) [2, 31, 32].\n    - The research identifies a lack of consensus on DT definitions within industries, indicating that companies tailor DT concepts to their specific needs and use cases [33, 34].\n    - The authors emphasize the need for companies to develop use case-specific definitions and provide a taxonomy and application-oriented definition to facilitate this process [4, 35].",
        "keywords": ["digital twin", "definition", "taxonomy", "industry", "systematic review", "properties", "characteristics", "industrial applications", "value creation", "data sources", "bidirectional connection", "real-world entity"]
    },
    {
        "title": "Requirements and design patterns for adaptive, autonomous, and context-aware digital twins in industry 4.0 digital factories",
        "summary": "This paper addresses the design, implementation, and management of adaptive, autonomous, and context-aware Digital Twins (DTs) in Industry 4.0 [1]. It emphasizes enriching current DT requirements to support adaptivity, autonomy, and context-awareness [1, 2]. The study explores reusable design patterns, particularly from the micro-services field, to meet demanding requirements while controlling complexity and management costs [2]. A working prototype, based on orchestrated micro-services and the identified design patterns, demonstrates the feasibility of the proposed solution and quantifies its networking and computational overhead [2].\n\n(1) **Definitions:**\n*   Digital Twins (DTs) are comprehensive, actionable, digital representations of physical systems (POs), reflecting their properties, behaviors, and relationships within the operational context [3].\n*   DTs enable features like device control, simulation, analytics, and enhancement of PO functionalities through cooperation and co-evolution of physical and software counterparts [3].\n\n(2) **Characteristics and Requirements:**\nThe paper emphasizes the need for DTs to evolve into active software entities capable of extending PO capabilities, sensing their environment, communicating proactively, and making decisions towards cooperative goals [4]. Key requirements include:\n*   **Reflection:** DTs must mirror the behavior and status of the PO, adapting communication protocols and managing external requests based on internal or environmental conditions [5, 6].\n*   **(R1)** DTs should discover available POs and handle communication according to supported protocols and data formats [5].\n*   **(R2)** DTs should be aware of the quality of reflection to promote adaptive behaviors [6].\n*   **Persistency:** DTs should be continuously available, exceeding the PO's existence, and organized into decoupled, independent components to avoid compromising the entire container due to localized faults [7].\n*   **(R3)** DTs must be resilient with independent components [7-9].\n*   **(R4)** DTs must be highly available, supporting replication in response to failures [7].\n*   **(R5)** DTs must support autonomous reconfiguration with remotely stored configurations [7].\n*   **Memorization:** DTs must store all status changes and events of the PO, acting as a cache and managing the entire history of states and events in a context-aware fashion [10, 11].\n*   **(R6)** DTs must maintain the current state of the PO internally [8, 10].\n*   **(R7)** DTs must manage the entire history of states and events [10, 12].\n*   **Augmentation:** DTs should extend PO functions via APIs, adding new functionalities and providing data access in specific formats through dynamic configuration and software updates [13, 14].\n*   **(R8)** DTs have to be expandable with dynamic configuration [13, 15].\n*   **(R9)** DTs must support software updates [13, 14, 16].\n*   **Composability:** DTs must support correlation of different elementary DTs into complex organizations, providing views on aggregated DTs and individual components [17].\n*   **(R10)** DTs must be able to manage other DTs as if they were POs [17, 18].\n*   **Replication:** DTs should support replication to serve different applications' needs, behaving consistently with peer or master-slave communication schemes [19].\n*   **(R11)** DTs, leveraging the container orchestrator, must support replication [19, 20].\n*   **Accountability/Manageability:** DTs must allow for determining their status and activities, providing information about PO usage by associated applications and making it available via standard interfaces [21].\n*   **(R12)** DTs have to be observable [15, 21].\n\n(3) **Relevant Use Cases:**\nThe paper includes an emulated industrial environment constructed around Kubernetes to demonstrate the feasibility of the proposals [22, 23]. The scenario includes the deployment of DTs for IIoT devices, a composed digital twin (CDT) aggregating information from other DTs, and industrial applications such as telemetry observers [24-26]. The use case demonstrates how DTs can be migrated to edge nodes to maintain entanglement with physical objects when network performance degrades [27].\n\n(4) **Technologies and Tools Used:**\n*   **Micro-services and Containerization:** DTs are implemented and managed using a micro-services approach with containerization for flexible management of software modules [4].\n*   **Kubernetes:** Used for orchestrating containerized DTs, enabling adaptive, autonomous, and context-aware behaviors [22, 23, 28].\n*   **Docker:** Employed as the container runtime [28].\n*   **Istio:** Utilized as the service mesh for traffic management, policy enforcement, and telemetry collection [28].\n*   **Prometheus, Grafana, Kiali, Jaeger:** Integrated with Istio for monitoring and visualization of performance metrics [29].\n*   **MQTT:** Used as the messaging protocol for communication between IIoT devices and DTs [24, 30].\n*   **SenML:** Data format used for standardizing sensor measurements [31].\n*   **Java DT Engine:** The core container that supports built-in modularity and a microkernel-oriented structure [30].\n\n(5) **Special Findings Related to Digital Twin Requirements or Challenges:**\n*   The paper emphasizes the importance of addressing adaptivity, autonomy, and context-awareness in DT design, as current implementations are often passive or platform-specific [32].\n*   It highlights the need for DTs to be active software components with independent behavior, capable of extending interoperability without changes on the PO [14].\n*   The research demonstrates that implementing DTs with microkernel patterns and containerization introduces negligible overhead, fostering the use of design patterns [33].\n*   The study shows that the proposed autonomous, adaptive, and context-aware DTs can handle context variation by forcing the cluster to move to a new configuration [34].",
        "keywords": ["Industry 4.0","Digital factory","Digital twin","Design patterns","Micro-services","Adaptivity","Autonomy","Context-awareness","Containerization","Kubernetes","IIoT","Edge Computing"]
    },
    {
        "title": "The development of standardized models of digital twin",
        "summary": "This paper addresses the lack of standardization in the emerging field of digital twins by proposing a universal architectural and ontological concept system, along with unified models to facilitate standardization [1-10]. The essence of digital twin technology lies in bridging the physical and virtual worlds to eliminate uncertainty in complex systems using digitalized and model-based approaches [11-17].\n\n**Definitions:** The paper emphasizes the need for a consistent definition of digital twin, advocating for the identification of the technology's essence to develop a universal concept system [2-4, 6, 11, 13, 18, 19]. It proposes a definition of Digital Twin Entity: a digital model of a physical entity analyzed and processed with measured data via algorithms to perceive, diagnose, predict the entity's state, synchronize states between the digital model and physical counterpart, and generate controlling information to optimize the physical entity’s behavior [20]. Also, an updated definition of Digital Thread is proposed: an extensible, configurable, componentized enterprise-level analytical communication framework, that constructs the integrated view of multi-viewpoints of Digital Twin Entity across the Life Cycle and value chain, Temporal Scales and Spatial Scales, of its counterpart Physical Entity, furthermore drive the Life Cycle activities of the Physical Entity with a unified model in order to provide support for Stakeholders [21, 22].\n\n**Characteristics and Requirements:** A digital twin system should eliminate uncertainty, building communication between physical and virtual worlds [11-17]. The concept system relies on inheritance, generalization, and attribute relationships [23-28]. A digital twin system comprises a user domain, a digital twin domain, a sensing and controlling domain, a physical domain, and cross-domain functionalities [29].\n\n**Relevant Use Cases:** The paper suggests using a three-dimensional space encompassing system purpose, system hierarchy/material scale, and system lifetime to define digital twin application scenarios [30-33]. Examples include fault diagnosis and health management [31, 33]. Digital twins can be applied to industrialization, urbanization, and globalization across various scales [34-37]. Specific examples include ICME, micro-nano manufacturing, intelligent manufacturing units, intelligent buildings, and supply chain management [36, 37].\n\n**Technologies and Tools Used:** The STEP EXPRESS-G language is used to model the concept system [23-26, 28]. The Internet of Things (IoT) is considered integral to digital twins for real-time dynamic interaction between digital and physical objects [38-40]. Simulation technology is used for dynamic prediction, incorporating physical laws and mechanisms [41, 42]. Industrial big data and machine learning are employed for future prediction based on incomplete information [42, 43]. Cloud computing facilitates the exchange and sharing of knowledge among different digital twins [43]. Blockchain provides a transaction mechanism for digital asset transactions during co-intelligence [44, 45].\n\n**Special Findings Related to Digital Twin Requirements or Challenges:** The paper highlights the absence of a consistent definition, concept system, reference architecture, application framework, and maturity model as a significant challenge [2-4, 6, 10]. It emphasizes the need for terminology work and a model-based concept system [5, 7, 46-52]. The maturity evolution of a digital twin involves five levels: modeling, interaction, foreknowing, prediction, and co-intelligence [53].",
        "keywords": ["Digital Twin","standardization","concept system","reference architecture","application framework","maturity model","ontology","industrial revolution","physical entities","virtual world","digital thread","STEP EXPRESS-G language","Internet of Things","simulation technology","cloud computing","blockchain"]
    },
    {
        "title": "The Role of AI in Warehouse Digital Twins: Literature Review",
        "summary": "This article reviews the synergies between Artificial Intelligence (AI) and Digital Twins (DTs) in warehouse management, examining use cases of Warehouse Digital Twins (WDTs) to assess the maturity of AI applications within them. It identifies inconsistencies and research gaps, providing insights for improving warehouse management, supply chain optimization, and operational efficiency [1]. The paper aims to evaluate the state-of-the-art by assessing the maturity of AI applications within the DT paradigm, addressing what AI techniques are mostly used for warehouse management under the DT paradigm, how AI is employed to ensure and elevate WDT functions, and what the challenges and barriers are to adopting WDT and AI in warehouses [2].\n\n(1) Definitions:\n\n*   Digital Twins (DTs): Virtual replicas of physical objects, machines, or systems, particularly in manufacturing, production, and operations [1]. They provide a fully connected and continuously evolving virtual replica of their physical counterparts, enabled by IoT technology that facilitates data analytics and simulation [3].\n*   Warehouse Digital Twins (WDTs): DTs applied to warehouse management [1].\n\n(2) Characteristics and Requirements:\n\n*   Context-awareness: The ability to distinguish incoming stimuli meaningfully, representing diverse situations in a virtual copy [4].\n*   Autonomy: The DT's ability to function independently without human intervention, streamlining the decision-making process [4].\n*   Continuous evolving: The ability of a DT system to grow and evolve with the real system throughout its lifecycle, adapting to new environmental conditions and changes [5].\n*   Full lifecycle management: Allows the model to cover different phases across the entire system lifecycle, including design, building, testing, operating, maintenance, disassembly, recycling, and remanufacturing [5].\n\n(3) Relevant Use Cases:\n\n*   Monitoring fruit freshness using convolutional neural networks to analyze thermal images [5, 6].\n*   Object detection for inventory and asset inspection using YOLOv2 [6, 7].\n*   Location estimation using deep learning techniques such as long short-term memory (LSTM) networks [6, 8].\n*   Forecasting stock keeping units (SKUs) arrivals using a neuro-fuzzy model [9, 10].\n*   Sales predictions using backpropagation neural networks [10, 11].\n*   Anomaly detection and maintenance monitoring using gradient-boosting decision tree (GDBT) [10, 12].\n*   Inventory predictions using proximal policy optimization (PPO) [10, 13].\n*   Process time prediction and optimal allocation of trolleys for material handling tasks using a combination of time-weighted linear regression method (TWMLR) and non-dominated sorting genetic algorithm (NSGA-II) [10, 14].\n\n(4) Technologies and Tools Used:\n\n*   ScienceDirect and SCOPUS: Scientific databases used for the literature review [15].\n*   VOSviewer 1.6.19: Software used for bibliometric analysis to visualize and identify concepts related to DTs [16].\n*   Warehouse Management Systems (WMS): Used to manage inventory and orders, facilitating real-time data sharing with DTs [17].\n*   Internet of Things (IoT) devices: Used to collect and transfer data to the virtual replica and then realize actions in the physical space [3].\n*   Radio frequency identification (RFID): Used to monitor storage locations and quantities [13].\n*   AI algorithms: Neural Networks (NNs), convolutional NNs, sparse autoencoder, YOLOv2, LSTM networks, black hole optimization-based clustering, neuro-fuzzy model, backpropagation NNs, gradient-boosting decision tree (GDBT), proximal policy optimization (PPO), time-weighted linear regression method (TWMLR), non-dominated sorting genetic algorithm (NSGA-II) [6, 10].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges:\n\n*   Data Dependency: AI and DTs are heavily reliant on data, and the use of data in warehousing is diverse and varies depending on several factors, such as availability, source, and application [18, 19].\n*   Need for Real-Time Data: Accessing information in real-time through IoT or IS is crucial for WDTs, but real-time monitoring is not always necessary, depending on the level of abstraction and the objective [20, 21].\n*   Human Involvement: Human involvement is still deemed essential when it comes to the modification of the physical system or the update of the digital twin, particularly in ensuring safety and preventing potential risks [22].\n*   Limited Research on Full Lifecycle Management: Most studies focus solely on the middle of life, with limited exploration of the entire lifecycle of warehouses when implementing DTs [23].\n*   Lack of Modeling of Intralogistics Processes: The literature is lacking in research regarding the modeling of intralogistics processes and facilities in their entirety, particularly in optimizing package preparation [24].\n*   Evolving and Dynamic Models: The utilization of evolving, dynamic, and traceable models is of the essence in order to accurately represent and predict the behavior of DTs in a constantly changing environment [25].",
        "keywords": ["digital twins","warehouse","material handling","artificial intelligence","machine learning","intralogistics","warehousing","supply chain optimization","operational efficiency","industry 4.0","internet of things","simulation"]
    },
    {
        "title": "The Sociotechnical Digital Twin: On the Gap Between Social and Technical Feasibility",
        "summary": "This paper addresses the emerging gap between social requirements and the technical capabilities of digital twins (DTs), particularly as their use expands from manufacturing to sociotechnical domains like smart cities and pandemic response [1, 2]. It explores the nature of this gap and suggests ways to bridge it, focusing on the concept of an 'Environment Digital Twin' [1, 2].\n\n(1) Definitions: A digital twin is defined as a virtual representation of a real-world system that allows for bidirectional communication [3]. The real-world system can be physical components, systems, processes, or even organizational units [3]. The paper distinguishes between different types of digital twins based on the level of seamless connection: Digital Blueprint, Digital Model, Digital Shadow, and Pure-Play [4-8]. A Sociotechnical Digital Twin is defined as a system-of-systems that includes a learning component and is characterized by a relationship between a real-world system and its partial virtual representation [9]. It emphasizes theory exploration and uses agent-based simulation [9]. A Pure-Play Digital Twin is defined as a self-adapting, self-regulating, self-monitoring, and self-diagnosing system-of-systems with a symbiotic relationship between a physical asset and its virtual representation [10].\n\n(2) Characteristics and Requirements: Key characteristics of DTs include seamless connection between the real entity and the virtual twin, continuous exchange of multi-dimensional data, comprehensive descriptions of constructs, and a safe simulation environment for testing and prediction [2, 11]. The use of AI/ML to support adaptation and prediction is also a crucial feature [11, 12]. Sociotechnical DTs must consider hardware, software, personal, and community aspects, requiring joint optimization of technical and social subsystems [13]. Important values such as privacy, security, transparency, and trust should be integrated into the design process, along with participatory design activities to include all stakeholders [13]. Fidelity, which describes the accuracy and level of abstraction, is also critical [14].\n\n(3) Relevant Use Cases: Applications of DTs span manufacturing, health, oil refinery management, supply chain, and physical infrastructure, including city planning [3]. The EU Destination Earth (DestinE) project aims to develop a high-precision digital model of the Earth for monitoring and simulating natural and human activity [3]. Sociotechnical DTs are used in smart-city planning and as response planning tools for managing events like the COVID-19 pandemic [2]. The paper also presents a hypothetical use case of an Environment Digital Twin (EDT) to assess risks to residents in a specific geographic area [15, 16].\n\n(4) Technologies and Tools Used and How They Were Used: Digital twins use computational modeling to represent and animate processes [3, 4]. Agent-based systems are used to reflect the increased uncertainty and emergent behavior of sociotechnical DTs [2, 17]. Machine learning (ML) is applied to automate complex analytical tasks, evaluate real-time data, adapt behavior, and support decision-making [12]. Knowledge representation languages such as Unified Modelling Language (UML), ESL, and Business Process Modelling Language are used to produce a foundational Knowledge Base/Domain Model [18]. Simulation environments integrate data, expert knowledge, informed judgments, and best guesses [19].\n\n(5) Special Findings Related to Digital Twin Requirements or Challenges: A significant challenge is the 'sociotechnical gap' that arises when DTs are applied to social systems [2]. This gap includes abstraction traps, epistemological concerns (validation and verification), and processes for domain understanding [17]. Abstraction traps include the framing trap (failure to model the entire system) and the solutionism trap (assuming a DT is always the best solution) [20, 21]. Ethical concerns arise from the use of machine learning algorithms, including inconclusive, inscrutable, and misguided evidence, and unfair outcomes [22]. Validation of sociotechnical DTs is difficult due to emergent behavior and the integration of social science theories [23]. The paper suggests addressing the gap through participatory design, value-sensitive design, and methodological advances, including the use of 'Theory of Change' approaches [24-26].",
        "keywords": ["Digital Twin", "Computational Model", "Socio-technical", "Abstraction", "Sociotechnical Systems", "Agent-Based Modeling", "Simulation", "Machine Learning", "Environment Digital Twin", "Value Sensitive Design", "Participatory Design"]
    },
    {
        "title": "When is a Simulation a Digital Twin? A Systematic Literature Review",
        "summary": "This paper systematically reviews the connection between Digital Twin (DT) capabilities and simulation, analyzing industrial applications, definitions, and challenges in the field [1, 2]. The research identifies a disconnection between DT concepts and their practical applications, noting that many implementations are essentially simulation models, utilizing only a fraction of DT's full potential [2-4]. The study uses a systematic literature review (SLR) of 120 academic journal publications to classify DT applications based on their implemented capabilities [2]. It employs a three-stage process: literature search, selection, and review [5].The paper uses the 4R framework (Representation, Replication, Reality, Relational) to classify DT capabilities and the 4S framework (Modeling, Analyzing, Predicting, Prescribing) for simulation capabilities [6, 7]. The review reveals that many papers claiming DT implementation lack the fundamental 4R capabilities, and the majority of DT applications are in the early stages (R1, R2) [8]. A significant portion of the literature uses the term 'Digital Twin' synonymously with simulation models, which contributes to misunderstandings [9].\\Key challenges identified include the absence of a unified DT definition, difficulties in collecting high-quality real-time data, and the need for self-evolving and autonomous DTs [10-12]. The authors suggest that a clearer understanding of DT benefits, business readiness for IoT implementation, and the development of metrics for DT progress are crucial for successful adoption [13]. They also emphasize the need for legal regulations to standardize data sharing across industries [14].The paper concludes by advocating for a consensus on distinguishing between simulation models and DTs and proposes future work on a framework to guide the development of DTs from fully capable simulations [4, 15]. The authors aim to clarify DT applications by comparing the 4R and 4S frameworks and highlighting the gap between DT concepts and actual implementations [4].",
        "keywords": ["Digital Twin", "Simulation", "Capability", "Manufacturing", "Industry 4.0", "Virtual representation", "Real-time data", "4R framework", "4S framework", "Systematic literature review", "Industrial applications", "Implementation challenges"]
    },
    {
        "title": "A digital supply chain twin for managing the disruption risks and resilience in the era of Industry 4.0",
        "summary": "Cet article théorise la notion de jumeau numérique de la chaîne d'approvisionnement (SC) – un modèle informatisé qui représente l'état du réseau à un moment donné en temps réel [1]. Il explore les conditions entourant la conception et la mise en œuvre des jumeaux numériques dans la gestion des risques de perturbation dans les SC [1]. Le cadre conceptuel proposé d'un jumeau numérique pour la gestion des perturbations de la SC est enraciné dans une combinaison d'approches basées sur des modèles et axées sur les données [1]. Cette combinaison permet de découvrir les interrelations entre les données de risque, la modélisation des perturbations et l'évaluation des performances [1, 2]. Le cadre développé conceptualise pour la première fois le jumeau numérique SC et fait progresser notre compréhension de quand et comment intégrer l'analyse des données dans la gestion des risques de perturbation de la SC afin d'élaborer une théorie d'une SC numérique [2]. Les résultats présentés peuvent également guider les entreprises dans le maintien adéquat des données pour la gestion des risques de perturbation et souligner les potentiels de transition d'un soutien à la décision hors ligne vers en ligne [2]. Les résultats de cette étude contribuent à la recherche et à la pratique de la gestion des risques de la SC en améliorant la compréhension des chercheurs et des décideurs pour les décisions prédictives et réactives en utilisant les avantages de la visualisation de la SC, de l'analyse des données historiques de perturbation et des données de perturbation en temps réel pour assurer une visibilité de bout en bout et la continuité des activités dans les entreprises mondiales [3]. L'objectif de cette étude conceptuelle est de développer davantage les fondements théoriques des théories de l'incertitude de la SC, de la dynamique structurelle et de l'analyse des risques [4]. L'étude dérive les principes méthodologiques de l'analyse numérique des risques de la SC et les combine dans un cadre de prise de décision de gestion utilisant les principes de l'Industrie 4.0 [4]. Ce cadre peut être utilisé pour concevoir un jumeau numérique de la chaîne d'approvisionnement (SC) pour la gestion des risques de perturbation [4].",
        "keywords": ["supply chain", "resilience", "Industry 4.0", "disruption risk", "data analytics", "digital twin", "SC risk management", "cyber-physical integration", "decision-making support", "real-time data", "SC visibility", "business continuity"
        ]
    },
    {
        "title": "Digital Twins along the product lifecycle: A systematic literature review of applications in manufacturing",
        "summary": "The concept of a digital twin was first introduced in 2002 by Dr. Michael Grieves from the University of Michigan as the “Conceptual Ideal for Product Lifecycle Management (PLM),” representing the linkage between real space and virtual space [1]. A digital twin is defined as a digital representation of a physical asset, linked with the physical counterpart by a flow of data enabling the real-time update of the digital model [1]. Digital twins play a role in monitoring, controlling, and predicting a product’s behavior at all stages of its lifecycle from design through to end-of-life [1]. Glaessgen and Stargel defined a digital twin as “an integrated multi-physics, multiscale, probabilistic simulation of a complex product and which uses the best available physical models, sensor updates, etc... to mirror the life of its corresponding twin” [2, 3]. This definition is widely used but also considered to have inaccuracies, leading to multiple definitions [3]. A more general definition of a digital twin includes three parts: 1. A model of an object. 2. An evolving set of data relating to the object, also called a digital thread. 3. A means of dynamically updating or adjusting the model in accordance with the data [4]. This paper also classifies digital twins into four subcategories based on three criteria: the presence of a physical system, the direction of data flow (from physical to digital, from digital to physical, or bidirectional), and the level of data integration. The subcategories are Pre-Digital Twin (PDT), Digital Model (DM), Digital Shadow (DS), and Digital Twin (DT) [5, 6]. Digital twins enable stakeholders (designers, manufacturers, users) to communicate around a common object, acquire and share information, and manage products more precisely during every phase of their lifecycles [1]. This digitization is seen as an opportunity to achieve higher levels of productivity and effectiveness [1]. The emergence of digital twins enriches the application of digital models in several areas and enhances traditional product design and development processes [1]. A key aspect of a digital twin is the flow of data between the physical asset and its digital representation, allowing for real-time updates [1]. Ideal digital twins in the manufacturing sector require reliable and precise models designed in parallel with the physical system, allowing direct data acquisition and considering the twin's presence from the initial design phase [7]. As digital twin applications become more integrated, there is an increasing need for real-time data acquisition from the physical counterpart, raising questions about the reliability and trustworthiness of the digital twin [8]. The paper presents a systematic literature review of digital twin applications in the manufacturing sector along the product lifecycle (Design, Production, Operational, and Disposal/End-of-life) [9-12]. Applications in the design phase include iterative optimization, providing data integrity, and virtual evaluation and verification [13, 14]. A majority of studies focus on the production phase, with applications in production control, production planning, process evaluation, and optimization [12, 15]. The operational phase also sees significant application, particularly in real-time monitoring, state monitoring, and predictive maintenance [15]. An emerging field of application is the disposal phase, where digital twins can serve as a database containing all product information to support end-of-life decisions like repair, reconditioning, remanufacturing, and recycling, particularly in the context of Waste from Electrical and Electronic Equipment (WEEE) [15, 16]. The research methodology involves a systematic literature review of 188 scientific papers with a focus on the manufacturing sector [11, 17]. The selection of publications was based on the presence of a case of application of a digital twin [11]. Data was extracted manually from the Web of Science database based on defined keywords and search equations [18, 19]. The reviewed papers were analyzed based on the type of digital twin (PDT, DM, DS, DT) and their applications along the product lifecycle [6, 11, 20]. The existing literature often focuses on the application of digital twins to improve a single phase of the product lifecycle, leading to isolated studies and contradictory definitions [21]. This research aims to address this by providing a holistic view across the entire lifecycle [20]. There is a diversity of application areas of digital twins within the literature [22, 23]. Most digital twin applications (58% in the reviewed literature) fall under the Digital Shadow (DS) subcategory, indicating a focus on data acquisition from the physical to the digital realm rather than a bidirectional command and control system (only 18% are actual DT) [24]. Digital twins are mostly used at a local scale for specific functions, often as add-on solutions after the physical system is built, which limits their potential [25]. A shift towards designing systems and their digital twins together from the beginning is recommended [7, 25]. A limitation of existing classifications of digital twin applications is the recent emergence of the disposal phase, which was not well-covered in earlier classifications [26]. This paper updates a previous classification to include 'Product End-of-Life Management' [16, 26]. Technological challenges include complex and sometimes indirect data acquisition and the trade-off between model accuracy, reliability, and computation cost/time [7]. Data integrity and the trustworthiness of digital twins are also important considerations as their applications become more integrated and influence decision-making [8].",
        "keywords": [ "Digital Twin", "Digital Shadow", "Product Lifecycle", "Literature review", "Manufacturing", "Design", "Production", "Operational phase", "Disposal/End-of-life", "Iterative optimization", "Virtual evaluation", "Real-time monitoring", "Predictive maintenance", "Digital Thread"]
    },
    {
        "title": "Digital twins for environmentally sustainable and circular manufacturing sector: visions from industry professionals",
        "summary": "This research paper delves into the potential of digital twins (DTs) in fostering environmentally sustainable business practices and the circular economy (CE) within the manufacturing sector [1, 2]. The study addresses a gap in existing literature by focusing on the business and sustainability aspects of DTs, which have traditionally been more technologically oriented [2, 3]. It explores the sustainability pressures faced by manufacturing companies and examines how DTs can be leveraged to promote environmentally sound operations and circularity [2, 4]. The findings are based on qualitative research involving interviews with industry professionals from manufacturing and software development companies [2, 4].\n\n(1) **Definitions:** The paper acknowledges the evolving nature of the digital twin concept [5, 6]. It traces the origins back to Dr. Michael Grieves' idea of a constantly updated virtual interpretation of a physical product or system [5]. The paper also mentions NASA's simulation-oriented definition, emphasizing an integrated, multiphysics, multiscale, probabilistic simulation mirroring the life of a physical twin [5]. A more recent definition highlights that DTs not only describe but also optimize physical objects based on models [5]. The research notes that conceptions of DTs vary across industries and companies, and solutions can be physics-based, data-based, or increasingly geometrical and image-based [6]. Despite ongoing debate about a definitive solution, the study proceeds to explore the practical applications and potential of these technologies as perceived by industry experts [6, 7].\n\n(2) **Characteristics and Requirements:** The research identifies key characteristics and requirements for effectively utilizing DTs for sustainability and circularity [8]. Interviewees emphasized the importance of data and measurement-based DTs that focus on collecting, maintaining, and combining product or process lifecycle data from various sources [9]. These DTs are seen as more than just 3D models, acting as repositories of general information from devices and machines [10]. Physics and computation-based DTs, focusing on design and simulation, also play a crucial role by enabling virtual prototypes and identifying potential issues early in the product development process [9, 11]. Both types benefit from functionalities like anomaly detection, estimations, reports, forecasts, and the visualization of data, leading to better control and decision-making [10]. A significant requirement is the seamless integration of DT solutions with existing systems, which is often hindered by incompatibility issues [12]. Furthermore, the vast amount of unstandardized data presents a challenge for effective utilization, necessitating solutions like asset hubs and linking interfaces [12]. Cybersecurity and reliability are paramount, as failures in these areas can severely damage customer trust and business continuity [13, 14]. The experts also highlighted the need for diverse resources, skills, and competences to leverage DTs for sustainability and CE purposes effectively [8]. The completeness and accuracy of the DT, often limited by data availability and the precision of simulation models, are critical for reliable predictions and informed decision-making in areas like predictive maintenance and lifetime extension [15-17].\n\n(3) **Relevant Use Cases:** The study reveals several key use cases where DTs can promote environmental sustainability and circularity across the product lifecycle [11, 18].\n    - **Product Development:** DTs enable virtual prototyping, leading to significant resource and cost savings and reduced emissions compared to physical prototypes [11, 19]. They facilitate smoother modifications, tests, and optimizations in the design phase, allowing for the exploration of less polluting and more energy-efficient solutions [19, 20]. DTs can collect and analyze data from physical devices to inform the development of improved product generations, optimize material usage by avoiding over-design, and tailor solutions like batteries in electric vehicles to actual needs [20, 21]. They can also assist in testing the feasibility and environmental impact of transitioning to cleaner energy sources [22].\n    - **Use and Operation:** DTs provide reports and comparisons to identify areas for reducing emissions, energy consumption, and resource usage during the operational phase [22]. They aid in scheduling maintenance and production stoppages, minimizing waste and preventing equipment breakdowns [22, 23]. DTs can also support the implementation of regenerative energy solutions by calculating the tipping point where the benefits outweigh the environmental costs of manufacturing the necessary components [23, 24]. Furthermore, simulation-based DTs are invaluable for training operators, reducing fuel consumption, wear and tear on equipment, and associated emissions, as well as improving operational efficiency and safety in production processes [24-26].\n    - **Decommissioning and Renewal:** DTs enhance traceability and control throughout a product's lifecycle, facilitating recyclability by providing precise information on components and materials [27]. They support the extension of solution lifetimes through modernization, where outdated components are replaced while viable parts are retained, reducing waste and the carbon footprint of manufacturing entirely new devices [28, 29]. DTs aid in assessing which parts need replacement and whether modernization is a feasible option by tracking and collecting equipment data [28].\n\n(4) **Technologies and Tools Used and How They Were Used:** This study employed a qualitative research approach, utilizing thematic semi-structured interviews with professionals from nine internationally operating companies in the manufacturing and software development sectors [30-32]. The interviewees were selected based on their connection to DTs, either through implementation or business development [32]. The interviews, conducted online and in-person between November 2023 and February 2024, focused on three thematic areas: (1) business aspects of product-service lifecycles, (2) environmental sustainability and circularity in manufacturing, and (3) the concepts and utilization of DTs in environmentally sustainable and circular manufacturing [33]. The interviews were recorded, transcribed, and analyzed using thematic analysis to identify recurring patterns and key insights related to sustainability pressures, DT concepts and applications, and DTs' potential in promoting sustainability and CE [34]. The sample size of nine companies was deemed sufficient to achieve data saturation [35]. The inclusion of both DT users and providers offered diverse perspectives [36]. Thematic analysis, chosen for its ability to highlight similarities and differences and generate unanticipated insights, resulted in three main categories of findings corresponding to the research themes [34]. The interviewees were also given the opportunity to review and comment on the manuscript before submission [34].\n\n(5) **Special Findings Related to Digital Twin Requirements or Challenges:** The study reveals several crucial requirements and challenges associated with the successful implementation of DTs for sustainability and CE [15, 37]. A key challenge is the incompleteness of DT solutions, often due to limitations in real-time data exchange, differences in data availability and format across markets, insufficient technological infrastructure, and inaccuracies in simulation models [15, 16]. This incompleteness hinders reliable predictions of wear and tear, impacting predictive maintenance and lifetime extension strategies [16, 17]. Ensuring the behavior and functionalities of the digital model accurately match the physical counterpart remains a significant hurdle [17]. While AI and machine learning offer potential solutions, the quality of initial data and understanding of training data are critical for their effectiveness [17, 38]. Inadequate depth and integration of DT offerings, particularly when maintenance is handled by parties unwilling to share data, can also limit their utility [38, 39]. The study underscores the importance of the benefit-cost ratio, emphasizing that sustainability improvements must be balanced with business competitiveness [39, 40]. The transition to incorporating digital features in traditionally mechanical products requires significant changes in manufacturing schemes and necessitates new skills and competences, which can be challenging for some companies to absorb and implement due to limited resources [40, 41]. Cybersecurity and reliability concerns pose significant risks to customer trust and can even have serious consequences for public infrastructure [13, 14]. The interviewees felt that these security issues currently restrict the potential extensiveness of DT solutions [18]."
        ,
        "keywords": ["Digital twin","Sustainability","Circular economy","Manufacturing","Industry professionals","Product design","Product use", "Decommissioning","Environmental pressures", "Qualitative research"]
    },
    {
        "title": "Implementation of digital twins in the food supply chain: a review and conceptual framework",
        "summary": "This research paper provides a comprehensive review of the existing literature on the implementation of Digital Twins (DTs) within food supply chains (FSCs) and proposes a novel conceptual framework for their adoption [1, 2]. The study addresses the significant challenges faced by global food industries, such as quality, waste, safety, and security, highlighting the unique complexities of FSCs due to the perishability of goods, specific storage and processing requirements, multiple transformations, and the critical need for end-to-end traceability [3]. The authors argue that DTs, as digital replicas of physical entities capturing real-time information for decision-making [4, 5], hold substantial promise in tackling these challenges [2, 6].\n\nThe paper begins by outlining a systematic literature review (SLR) process, detailing the identification of data sources (Web of Science, EBSCO, Scopus, ABI/ProQuest), the keywords used ('Digital Twin(s)' and 'food supply chain(s)' variations) [7, 8], and the rigorous screening and selection process that resulted in 81 peer-reviewed articles published between 2012 and 2023 [7-11]. Descriptive analysis of these papers reveals a growing interest in DTs for FSCs, particularly in recent years [5], with a significant portion of research originating from European countries, especially China, the UK, Germany, and Italy [12]. The research methods employed are predominantly qualitative (case studies, literature reviews, conceptual papers) and mixed methods, with the International Journal of Production Research being the leading publication venue [13-15]. The descriptive analysis also identifies the Internet of Things (IoT) as the most frequently integrated Industry 4.0 technology in DT applications within FSCs [16].\n\nThe core of the paper lies in its thematic analysis, which employs a text-mining approach to identify key themes: DT characteristics, FSC challenges, DT applications, and DT implementation barriers and drivers [17-19]. The identified FSC challenges include complexity and uncertainty, food safety and security, food losses and waste, information asymmetry, and the lack of traceability [20-25]. These challenges are elaborated upon with specific examples and supporting literature. For instance, the complexity arises from the multitude of stakeholders and the unique issues they face, while uncertainty stems from fragmented operations and external factors like climate and consumer behavior [20, 21]. Food safety is threatened by distribution uncertainties, improper handling, food fraud, and contamination [22], and food waste occurs due to inefficiencies in handling, storage, and infrastructure [23]. Information asymmetry hinders decision-making and contributes to safety incidents [24], and the lack of traceability impedes quality control and recall management [25].\n\nThe paper then delves into the characteristics of DTs that can address these challenges, including monitoring, real-time simulation, scenario analysis, data and technology integration, and visibility [26-33]. Monitoring capabilities allow for real-time tracking of food products and performance assessment [26, 27]. Real-time simulation enables the virtual duplication of physical systems, allowing for the testing of different actions without disrupting real-world operations [28, 29]. Scenario analysis facilitates the prediction of physical entity behavior and the assessment of disruption impacts, aiding in informed decision-making [30, 31]. Data and technology integration, the ability to combine data from diverse sources and technologies like IoT and Blockchain, is crucial for accurate simulation and decision support [32]. Enhanced visibility across the FSC, from farm to fork, improves traceability and helps identify potential safety issues [33].\n\nThe applications of DTs are explored across various stages of the FSC, from food farming and processing (e.g., virtual models for aquaponics, optimizing fruit harvest, improving food processing efficiency) to food logistics (e.g., tracking product journeys, monitoring temperature and humidity, optimizing warehouse operations) and food packaging and retail (e.g., supply and demand management, simulating packaging conditions, predictive equipment maintenance) [34-37].\n\nThe study identifies several drivers for DT implementation, categorized as internal (improving operational efficiency, enhancing FSC visibility and transparency) and external (competitive pressures related to cost, productivity, and quality, and wider technology support from Industry 4.0 advancements) [38-43]. Conversely, barriers to DT implementation include data security and storage issues, data processing limitations, lack of collaboration among stakeholders, lack of system synchronization and integration, and high implementation costs [44-49].\n\nTo address the gap in understanding the implementation process, the paper proposes a novel conceptual framework for implementing DTs within the FSC, drawing on the thematic analysis, Innovation Adoption Theory, and the Technology-Organization-Environment (TOE) framework [50-53]. This framework consists of three main stages: pre-adoption, adoption, and post-adoption, further divided into five steps: initiation, technology assessment, adoption decision, implementation, and performance evaluation [53]. The pre-adoption stage utilizes the TOE framework to analyze technological, organizational, and environmental factors influencing the decision to adopt [54-57]. The adoption stage includes technology assessment (an innovative step not typically found in Innovation Adoption Theory, emphasizing the evaluation of existing IT infrastructure and compatibility), adoption decision (resource allocation), and implementation (stakeholder acceptance and scaling) [58, 59]. The post-adoption stage includes performance evaluation to assess the effectiveness and benefits of the implemented DTs [60].\n\nFinally, the paper outlines five key future research directions: the need for DT evaluation metrics in FSCs, lack of clarity on technology relevance and integration capabilities, the need for SC inter-level applications in FSCs (moving beyond single-firm applications), the necessity of user acceptance analysis of DTs, and achieving digital transformation driven by DTs in FSCs by integrating other supporting technologies [61-67]. The authors conclude by reiterating the contributions of their study to theory (first SLR on DTs in FSCs, novel implementation framework) and practice (insights for managers and policymakers), while also acknowledging the limitations of the study (reliance on a specific set of papers, potential for subjectivity in the SLR process, limited empirical evidence) [68-74].",
        "keywords": ["Digital Twin","food supply chain","implementation framework","Industry 4.0","systematic literature review","FSC challenges","DT characteristics","DT applications","implementation drivers","implementation barriers","Innovation Adoption Theory","Technology-Organization-Environment (TOE)"]
    },
    {
        "title": "Industry 4.0: digital twins characteristics, applications, and challenges in-built environment",
        "summary": "This research paper explores the concept of Digital Twins (DT) within the context of the built environment, aiming to define their key characteristics, examine their relationship with Building Information Modeling (BIM), and evaluate their interactions with other Industry 4.0 technologies in the construction and maintenance of assets [1, 2]. The paper notes that while DT technology holds significant potential for enhancing the design, construction, and operation of built assets, it is still in its infancy and faces challenges related to integration, standardization, and real-world application [1, 3]. The study employs a literature review methodology to address questions regarding the definition of DTs in built environments, their relationship with BIM and other technologies, their applications and challenges, and how they can be generated and applied by the industry [4].\n\n(1) **Definitions:** The paper highlights that there is no universal consensus on the definition of a 'Digital Twin' in the built environment and AECO sector, presenting several definitions from various authors. Nochta et al. (2019) define a DT as an accurate digital replica of a physical object [5]. McCausland (2021) describes it as a precise duplicate of a physical process expressed simultaneously and usually corresponding with the actual operation in real time [5, 6]. Haag & Anderl (2018) expand this by defining a DT as a comprehensive digital representation of a product or asset that accurately reflects its attributes, condition, and behavior through digital models and data [7]. Grieves & Vickers (2016) characterize a DT as a collection of virtual information constructs providing insights similar to inspecting the physical product [7]. Madni et al. (2019) define the goal of a DT as regulating, monitoring, and enhancing the performance of a real-world system by combining a computer model with the real system, potentially becoming self-sufficient through data and feedback [8]. The paper emphasizes the commonality across these definitions, which is the dynamic connection between data, the physical model, and the digital model, with bidirectional integrated data flow often considered a defining characteristic [9]. However, Haag & Anderl (2018) caution that not all digital artifacts from the creation of a physical twin should be part of a DT, which should encompass only essential data for its specific goals [9].\n\n(2) **Characteristics and Requirements:** Key characteristics of a Digital Twin include acting as a representation or image of a physical asset and being linked to its physical counterpart to reflect changes [8, 10]. In the AECO industry, this often involves a 3D model with linked data, although not all definitions mandate a 3D representation [8]. The connection between a DT and its physical twin requires data synchronization at varying intervals and the integration of diverse data types and formats, particularly for facilities management [11]. Brilakis et al. (2019) state that the purpose and functionality of the DT determine the necessary data connection [8]. A Digital Twin can also be a collection of interconnected but physically distinct models or data instances, forming a federated Digital Twin [11]. Madni et al. (2019) identified five phases of DT development based on their characteristics and stages [9]. Furthermore, a common data environment is deemed necessary for the effective use of Digital Twins [12].\n\n(3) **Relevant Use Cases:** The paper discusses several potential applications of Digital Twins in the built environment. In **smart cities**, DTs can leverage IoT sensor data and AI algorithms to optimize city management, alleviate traffic congestion, boost energy efficiency, and reduce greenhouse gas emissions, aiding in renovation projects and lifecycle management [13]. In **design decision making**, DTs can provide a two-way data flow between design models and performance parameters, enabling continuous evaluation against metrics like thermal efficiency and energy consumption, streamlining the assessment of design options against compliance checks and objectives [14, 15]. In **product manufacturing**, DTs are used to automate processes, drive leaner operations, enable predictive analytics, continuous improvement, and the creation of high-fidelity virtual models for intelligent manufacturing and waste reduction [16]. For **real-time monitoring of construction progress**, DTs can digitize management by simulating site conditions, equipment, materials, and worker behavior, integrating real-time data from sensors, although the construction sector currently lacks fully integrated environments for this [17]. In **facility management**, DTs can improve data-driven decision-making for asset operation and maintenance, overcoming the limitations of BIM alone in automating FM operations due to interoperability issues and a focus on design and construction data [18].\n\n(4) **Technologies and Tools Used and How They Were Used:** The development of Digital Twins is closely linked to data-centric Industry 4.0 technologies such as cloud computing, big data, augmented reality, virtual reality, and the Internet of Things (IoT) [19, 20]. IoT-enabled devices and sensor-based data-capturing devices are identified as key enablers for DTs [20]. BIM provides a crucial foundation for constructing a Digital Twin, with data such as equipment specifications and operation and maintenance management within a 3D model serving as critical input [21]. AI algorithms are essential for enhancing city management within smart city DT applications [13]. While existing Building Management Systems (BMS) represent an integration of DT functionalities in Facility Management, they often lack full integration with contemporary FM 3D modeling techniques like DTs [22]. For successful integration, BMS needs to connect with a network capable of processing real-time instructions and delivering continuous feedback [23]. The paper also mentions the necessity of task-specific tools for information storage, access, and modification for the implementation of DT procedures [24].\n\n(5) **Special Findings Related to Digital Twin Requirements or Challenges:** Several challenges hinder the widespread adoption of DT technology in the built environment. **Data security and ownership** are significant concerns, particularly in web-based environments and for sensitive projects, requiring the specification of permissions and addressing legal and intellectual property rights [25]. The **lack of common data standards and interoperability** across different standards, technologies, and methods poses a major difficulty, delaying the development of useful common data environments and hindering the integration of various tools [24, 26]. **Source systems diversity**, including varying temporal scales and diverse spatial and parametric factors, makes it challenging to create impartial and accurate virtual representations, with standard databases struggling to handle the heterogeneity and volume of data from multiple sources [27]. These challenges are noted to be comparable to those faced during the implementation of BIM practices [27, 28]. Furthermore, **cultural shifts** at individual and organizational levels are necessary for adoption, as many specialists are more comfortable with traditional frameworks, and organizations lack incentives to overcome technological and financial obstacles for upgrading systems [29]. The need for **support from large customers, governments, and legislative agencies** to provide guidelines and path-finding projects is also highlighted [30]. Ultimately, demonstrating solid empirical evidence of the benefits of DTs from actual use cases is crucial for their widespread adoption [30].",
        "keywords": ["digital twin", "building information modeling", "digital build environment", "industry 4.0", "construction", "asset management", "smart cities", "facility management", "data security", "interoperability", "common data standards", "real-time monitoring"]
    },
    {
        "title": "Online validation of digital twins for manufacturing systems",
        "summary": "This paper addresses the problem of online validation of digital twins (DTs) for production planning and control in manufacturing systems, a crucial aspect for leveraging their optimization and decision-making functionalities [1, 2]. The research highlights the limitations of traditional offline validation techniques in dynamic contexts requiring rapid assessment with small datasets, often focusing on average system behavior [1, 3]. The authors propose a methodology for online validation by measuring the congruence between the physical system and its digital model through sequence comparison techniques applied to real-time data streams from the shop floor [1, 4]. This approach considers both logic validation (correctness of the model's layout and assumptions) using Trace-Driven Simulation (TDS) and input validation (correctness of input data distributions) using quasi Trace-Driven Simulation (qTDS) [5, 6]. The validation process involves comparing real and digital data sequences to obtain a similarity indicator, with acceptance thresholds defined by user requirements [6]. The paper explores performance-level validation by analyzing sequences of Key Performance Indicators (KPIs) and event-level validation for detailed analysis [7, 8]. Numerical experiments on a five-station closed system using Rockwell Arena Simulation Software and a Python implementation of the methodology demonstrate the applicability of the proposed approach, testing input and logic validation with different sequence comparison methods like a modified Longest Common Sub-sequence (LCSS) and Dynamic Time Warping (DTW) [8, 9]. The findings indicate that the proposed online validation methodology can effectively detect deviations in the digital model from the physical system, even with limited data, and monitor the whole trend of information, contributing to reliable short-term decision making in smart manufacturing systems [10]. Challenges include defining appropriate indifference thresholds for sequence comparison and the need for further research in real manufacturing environments and with different types of manufacturing system data [9, 11].",
        "keywords": ["digital twin", "online validation", "smart manufacturing", "discrete event simulation", "production systems", "decision making", "physical system", "digital model", "data sequences", "manufacturing systems", "trace-driven simulation", "quasi trace-driven simulation", "sequence comparison", "KPI", "LCSS", "DTW"]
    },
    {
        "title": "The role of digital twins in lean supply chain management: review and research directions",
        "summary": "This review paper investigates the role of digital twins (DTs) in lean supply chain management (SCM) within the context of Industry 4.0, addressing the understudied relationship between these concepts [12]. Through a systematic literature review of 33 selected papers, the study analyzes the applications of DTs in SCM using the supply-chain operations reference (SCOR) framework and their impact on lean principles and supply chain performance [12, 13]. The findings reveal that DTs are primarily applied in the plan, make, and deliver processes of the supply chain, with limited exploration in source and return processes [12, 14-16]. DTs enhance lean practices by improving information flow, eliminating waste, optimizing logistics, and enabling just-in-time (JIT) production [12, 17-19]. The review also identifies two additional areas where DTs contribute: enhancing supply chain coordination and bolstering supply chain resilience, particularly against disruptions [12, 20, 21]. Despite these advancements, the paper notes understudied areas such as top management commitment, supplier relationship management, and customer relationship management in the context of DTs for lean SCM [12, 17-19]. The paper proposes a framework for digital twin-driven smart lean supply chain management, built upon a four-layered digital twin reference architecture and a seven-element digital twin framework, highlighting future research directions in areas like SCDT mapping, convergence, interaction, cognition, and service [12, 22, 23]. The analysis indicates that most current studies combine digital twins with simulation methodologies, with some also incorporating optimization, big data, and AI techniques [24]. The study concludes that digital twins hold significant potential for advancing lean supply chain practices, promoting operational efficiency, and fostering strategic collaboration in a dynamic business environment [23].",
        "keywords": ["digital twin", "lean supply chain management", "Industry 4.0", "supply chain efficiency", "smart manufacturing", "lean manufacturing", "just-in-time", "SCOR framework", "supply chain resilience", "supply chain coordination", "simulation", "optimization", "information flow", "waste elimination", "logistics management", "supply chain integration"]
    }
]

  