{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a240da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "from glob import glob\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# Set your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96749c19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 14 PDF files: ['/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/applsci-13-06746-v2.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/1-s2.0-S0166361521001159-main-2.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/978-3-030-01614-2_19.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/1-s2.0-S1367578820300560-main.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/1605271035_1604658922_AMRC_Digital_Twin_AW.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/09640612.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/1-s2.0-S1877050921006694-main.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/IET Collab Intel Manufact - 2021 - Melesse - Digital Twin models in industrial operations  State%E2%80%90of%E2%80%90the%E2%80%90art and future-2.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/1-s2.0-S0166361523000684-main.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/1-s2.0-S2452414X22000516-main.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/applsci-12-00669-v2.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/Digital_Twin_Enabling_Technologies_Challenges_and_Open_Research-5.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/RISK-19-1039%20with%20cover%20form.pdf', '/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs/1-s2.0-S1364032123001363-main.pdf']\n",
      "Raw text loaded from all PDFs.\n"
     ]
    }
   ],
   "source": [
    "def load_pdfs_from_directory(directory_path):\n",
    "    \"\"\"\n",
    "    Load and combine text from all PDFs in a directory.\n",
    "    \"\"\"\n",
    "    raw_text = \"\"\n",
    "    pdf_files = glob(os.path.join(directory_path, \"*.pdf\"))  # List of PDF files in directory\n",
    "    print(f\"Found {len(pdf_files)} PDF files: {pdf_files}\")\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            reader = PdfReader(pdf_file)  # Open the PDF file\n",
    "            for page in reader.pages:\n",
    "                text = page.extract_text()  # Extract text from each page\n",
    "                if text:\n",
    "                    raw_text += text  # Append extracted text to the raw_text\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {pdf_file}: {e}\")\n",
    "    \n",
    "    return raw_text, pdf_files  # Return both the combined text and the list of file paths\n",
    "\n",
    "\n",
    "# Directory containing PDFs\n",
    "pdf_directory = \"/Users/adnanedrissielbouzidi/Library/CloudStorage/GoogleDrive-adnane.drissielbouzidi@square-management.com/Mon Drive/onboarding consultant/DT_PDFs\"\n",
    "\n",
    "# Step 1: Load and process PDFs\n",
    "raw_text, pdf_files = load_pdfs_from_directory(pdf_directory)  # Unpack raw_text and file paths\n",
    "print(\"Raw text loaded from all PDFs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "842157d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text split into 1422 chunks.\n",
      "\n",
      "Chunk 1:\n",
      "--------------------\n",
      "Citation: Drissi Elbouzidi, A.;\n",
      "Ait El Cadi, A.; Pellerin, R.;\n",
      "Lamouri, S.; Tobon Valencia, E.;\n",
      "Bélanger, M.-J. The Role of AI in\n",
      "Warehouse Digital Twins: Literature\n",
      "Review. Appl. Sci. 2023 ,13, 6746.\n",
      "https://doi.org/10.3390/\n",
      "app13116746\n",
      "Academic Editors: Francesco Longo,\n",
      "Antonio Padovano, Vittorio Solina\n",
      "and Giovanni Mirabelli\n",
      "Received: 30 April 2023\n",
      "Revised: 29 May 2023\n",
      "Accepted: 30 May 2023\n",
      "Published: 1 June 2023\n",
      "Copyright: © 2023 by the authors.\n",
      "Licensee MDPI, Basel, Switzerland.\n",
      "This article is an open access article\n",
      "distributed under the terms and\n",
      "conditions of the Creative Commons\n",
      "Attribution (CC BY) license (https://\n",
      "creativecommons.org/licenses/by/\n",
      "4.0/).\n",
      "applied  \n",
      "sciences \n",
      "Review\n",
      "The Role of AI in Warehouse Digital Twins: Literature Review†\n",
      "Adnane Drissi Elbouzidi1,2,*\n",
      ", Abdessamad Ait El Cadi3,4\n",
      ", Robert Pellerin5\n",
      ", Samir Lamouri1\n",
      ",\n",
      "Estefania Tobon Valencia2and Marie-Jane B élanger5\n",
      "\n",
      "\n",
      "Chunk 2:\n",
      "--------------------\n",
      "Adnane Drissi Elbouzidi1,2,*\n",
      ", Abdessamad Ait El Cadi3,4\n",
      ", Robert Pellerin5\n",
      ", Samir Lamouri1\n",
      ",\n",
      "Estefania Tobon Valencia2and Marie-Jane B élanger5\n",
      "1LAMIH, Arts et M étiers ParisTech, 51 Bd de l’H ôpital, 75013 Paris, France; samir.lamouri@ensam.eu\n",
      "2Groupe Square Management cabinet Flow&Co., Square Research Center, 173 Avenue Achille Peretti,\n",
      "92200 Neuilly-sur-Seine, France; e.tobonvalencia@ﬂowandco.fr\n",
      "3LAMIH, CNRS, UMR 8201, Universit éPolytechnique Hauts-de-France, 59313 Valenciennes, France;\n",
      "abdessamad.aitelcadi@uphf.fr\n",
      "4INSA Hauts-de-France, Universit éPolytechnique Hauts-de-France, 59313 Valenciennes, France\n",
      "5Polytechnique Montreal, 2500 Chemin de Polytechnique, Montr éal, QC H3T 1J4, Canada;\n",
      "robert.pellerin@polymtl.ca (R.P .); marie-jane.belanger@productique.quebec (M.-J.B.)\n",
      "*Correspondence: adnane.drissi_elbouzidi@ensam.eu\n",
      "†This paper is an extended version of the paper “The Role of AI in Warehouse Digital Twins” published in 34th\n",
      "\n",
      "\n",
      "Chunk 3:\n",
      "--------------------\n",
      "*Correspondence: adnane.drissi_elbouzidi@ensam.eu\n",
      "†This paper is an extended version of the paper “The Role of AI in Warehouse Digital Twins” published in 34th\n",
      "European Modeling & Simulation Symposium (EMSS), Rome, Italy, 19–21 September 2022.\n",
      "Abstract: In the era of industry 5.0, digital twins (DTs) play an increasingly pivotal role in contempo-\n",
      "rary society. Despite the literature’s lack of a consistent deﬁnition, DTs have been applied to numerous\n",
      "areas as virtual replicas of physical objects, machines, or systems, particularly in manufacturing,\n",
      "production, and operations. One of the major advantages of digital twins is their ability to supervise\n",
      "the system’s evolution and run simulations, making them connected and capable of supporting\n",
      "decision-making. Additionally, they are highly compatible with artiﬁcial intelligence (AI) as they can\n",
      "be mapped to all data types and intelligence associated with the physical system. Given their potential\n",
      "\n",
      "\n",
      "Chunk 4:\n",
      "--------------------\n",
      "be mapped to all data types and intelligence associated with the physical system. Given their potential\n",
      "beneﬁts, it is surprising that the utilization of DTs for warehouse management has been relatively\n",
      "neglected over the years, despite its importance in ensuring supply chain and production uptime.\n",
      "Effective warehouse management is crucial for ensuring supply chain and production continuity in\n",
      "both manufacturing and retail operations. It also involves uncertain material handling operations,\n",
      "making it challenging to control the activity. This paper aims to evaluate the synergies between\n",
      "AI and digital twins as state-of-the-art technologies and examines warehouse digital twins’ (WDT)\n",
      "use cases to assess the maturity of AI applications within WDT, including techniques, objectives,\n",
      "and challenges. We also identify inconsistencies and research gaps, which pave the way for future\n",
      "development and innovation. Ultimately, this research work’s ﬁndings can contribute to improving\n",
      "\n",
      "\n",
      "Chunk 5:\n",
      "--------------------\n",
      "and challenges. We also identify inconsistencies and research gaps, which pave the way for future\n",
      "development and innovation. Ultimately, this research work’s ﬁndings can contribute to improving\n",
      "warehouse management, supply chain optimization, and operational efﬁciency in various industries.\n",
      "Keywords: digital twins; warehouse; material handling; artiﬁcial intelligence; machine learning\n",
      "1. Introduction\n",
      "Intralogistics is undoubtedly a crucial component of both manufacturing efﬁciency\n",
      "and customer satisfaction. Material handling, in particular, can account for 15 to 70% of pro-\n",
      "duction costs, underscoring the need for optimized warehouse operations [ 1]. Additionally,\n",
      "order preparation costs are believed to make up as much as 55% of the overall expenses\n",
      "incurred in a warehouse [ 2]. Material handling is also one of the most hazardous industrial\n",
      "processes, accounting for up to 50% of all industrial injuries. Given the evolving market\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def split_text(raw_text, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"\n",
    "    Split raw text into smaller chunks for efficient processing.\n",
    "    \"\"\"\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        separator=\"\\n\",\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "    )\n",
    "    return text_splitter.split_text(raw_text)\n",
    "\n",
    "# Step 2: Split the text into chunks\n",
    "text_chunks = split_text(raw_text, chunk_size=1000, chunk_overlap=200)\n",
    "print(f\"Text split into {len(text_chunks)} chunks.\")\n",
    "\n",
    "# Display the first few chunks for review\n",
    "for i, chunk in enumerate(text_chunks[:5]):  # Adjust the number to display more chunks if needed\n",
    "    print(f\"\\nChunk {i+1}:\\n{'-'*20}\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dd3ac74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAISS vector store created successfully.\n",
      "FAISS vector store created.\n"
     ]
    }
   ],
   "source": [
    "def create_faiss_vectorstore(text_chunks):\n",
    "    \"\"\"\n",
    "    Create a FAISS vector store from text chunks.\n",
    "    \"\"\"\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_texts(text_chunks, embeddings)\n",
    "    print(\"FAISS vector store created successfully.\")\n",
    "    return vectorstore\n",
    "\n",
    "\n",
    "# Step 3: Create a FAISS vector store\n",
    "vectorstore = create_faiss_vectorstore(text_chunks)\n",
    "print(\"FAISS vector store created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e634d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query(vectorstore, query):\n",
    "    \"\"\"\n",
    "    Perform a similarity search on the vector store and answer the query.\n",
    "    \"\"\"\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=OpenAI(),\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    result = qa_chain.invoke({\"query\": query})\n",
    "    return result[\"result\"], result[\"source_documents\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a8df668",
   "metadata": {},
   "source": [
    "In its current form, your code successfully splits text into chunks, creates embeddings, and stores them in a FAISS vector store. However, the FAISS vector store constructed is based on the global text extracted from all the PDFs concatenated together, so it should theoretically have a \"global\" knowledge base of all the PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18347afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer:  Adnane Drissi Elbouzidi, Abdessamad Ait El Cadi, Robert Pellerin, Samir Lamouri, Estefania Tobon Valencia, and Marie-Jane Bélanger.\n",
      "\n",
      "Source Documents:\n",
      "- Unknown\n",
      "- Unknown\n",
      "- Unknown\n",
      "- Unknown\n",
      "\n",
      "Answer:  The requirements for a system to be considered a digital twin include the ability to collect data from physical entities, the use of cloud infrastructure and Internet of Things technology, and the ability to present data in an intuitive and automated manner. Additionally, the system should be able to aggregate data from other digital twins and use predictive and interactive capabilities.\n",
      "\n",
      "Source Documents:\n",
      "- Unknown\n",
      "- Unknown\n",
      "- Unknown\n",
      "- Unknown\n"
     ]
    }
   ],
   "source": [
    "# Answer queries\n",
    "queries = [\n",
    "    \"Who wrote the paper : The Role of AI in Warehouse Digital Twins: Literature Review\",\n",
    "    \"What are the requirements/conditions to say that a system is a digital twin?\",\n",
    "]\n",
    "    \n",
    "for query in queries:\n",
    "    answer, sources = answer_query(vectorstore, query)\n",
    "    print(f\"\\nAnswer: {answer}\\n\")\n",
    "    print(\"Source Documents:\")\n",
    "    for source in sources:\n",
    "        print(f\"- {source.metadata.get('source', 'Unknown')}\") # Print source metadata if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1516afdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Answer: \n",
      "Category: Understanding of Digital Twin concept\n",
      "Description: This category assesses the understanding of the Digital Twin concept by individuals or companies.\n",
      "\n",
      "1. Have you heard about the concept of Digital Twin? \n",
      "2. How would you define a Digital Twin? \n",
      "3. Can you explain the purpose of a Digital Twin in your own words? \n",
      "\n",
      "Category: Use of Digital Twins in processes\n",
      "Description: This category evaluates the extent to which Digital Twins are utilized in processes by companies.\n",
      "\n",
      "1. Do you currently use Digital Twins in your processes? \n",
      "2. If yes, in what capacity do you use Digital Twins (e.g. simulation, monitoring, etc.)? \n",
      "3. How long have you been using Digital Twins in your processes? \n",
      "\n",
      "Category: Requirements for implementation of Digital Twins\n",
      "Description: This category explores the main requirements that companies believe are necessary for the successful implementation of Digital Twins in processes.\n",
      "\n",
      "1. In your opinion, what are the main requirements for implementing Digital Twins in processes? \n",
      "2. What challenges do you foresee in implementing Digital Twins in processes? \n",
      "3. How do you think these challenges can be overcome? \n",
      "\n",
      "Category: Future plans for use of Digital Twins\n",
      "Description: This category examines the plans of companies regarding the future use of Digital Twins in their operations\n",
      "\n",
      "Source Documents:\n",
      "- Unknown\n",
      "- Unknown\n",
      "- Unknown\n",
      "- Unknown\n"
     ]
    }
   ],
   "source": [
    "# Answer queries\n",
    "queries = [\n",
    "    \"i want you to give me a digital twin questionnaire based on the documents you have. i want it to be composed of categories so as to allow phd students or other comanies to assesss if the systems they develope are digital twins: have it have categories, a descritpion and questions\"\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    answer, sources = answer_query(vectorstore, query)\n",
    "    print(f\"\\nAnswer: {answer}\\n\")\n",
    "    print(\"Source Documents:\")\n",
    "    for source in sources:\n",
    "        print(f\"- {source.metadata.get('source', 'Unknown')}\") # Print source metadata if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52946785",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423cf3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182bc10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b246c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
